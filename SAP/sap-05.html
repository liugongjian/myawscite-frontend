<!DOCTYPE html>
<!-- saved from url=(0112)https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222 -->
<html xmlns:fb="http://ogp.me/ns/fb#" lang="en-gb" dir="ltr" class="secondary-14px wf-proximanova-n7-active wf-proximanova-i7-active wf-proximanova-n4-active wf-raleway-n1-active wf-raleway-n7-active wf-raleway-n4-active wf-raleway-n5-active wf-raleway-n3-active wf-raleway-n8-active wf-raleway-n9-active wf-raleway-n2-active wf-raleway-n6-active wf-proximanova-i4-active wf-active"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><meta name="format-detection" content="telephone=no"><script type="text/javascript" src="./sap-05_files/pageload"></script><script type="text/javascript" src="./sap-05_files/display.js.下载"></script><script type="text/javascript" src="./sap-05_files/pro"></script><script type="text/javascript" src="./sap-05_files/l.js.下载"></script><script type="text/javascript" src="./sap-05_files/l.js(1).下载"></script><script type="text/javascript" src="./sap-05_files/l.js(2).下载"></script><script type="text/javascript" src="./sap-05_files/l.js(3).下载"></script><script type="text/javascript" async="" src="./sap-05_files/analytics.js.下载"></script><script type="text/javascript" async="" src="./sap-05_files/atatus.js.下载"></script><script src="./sap-05_files/fMy5LNtdDqis6adCpEbCXQHA47I.js.下载"></script><script src="./sap-05_files/js"></script><link rel="canonical" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222"><link rel="stylesheet" type="text/css" href="./sap-05_files/bc-course.min_092917.css"><link rel="stylesheet" type="text/css" href="./sap-05_files/bc-style-092917.css"><!--[if lt IE 9]> <script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script> <script src="//css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script> <![endif]--><link rel="shortcut icon" href="https://www.braincert.com/images/favicon.ico"> <script type="text/javascript" src="./sap-05_files/jquery-1.11.0.min.js.下载"></script> <script type="text/javascript">jQuery.noConflict();</script> <script type="application/javascript" src="./sap-05_files/fVBYAHUg.js.下载"></script> <script type="text/javascript">jwplayer.key="Kfk7MAHVl4Y33jPduQlHwUdmLu+1l6cvPHVklw==";</script> <script src="./sap-05_files/jdk4nqa.js.下载"></script> <style type="text/css">.tk-proxima-nova{font-family:"proxima-nova",sans-serif;}.tk-raleway{font-family:"raleway",sans-serif;}</style><style type="text/css">@font-face{font-family:tk-proxima-nova-n7;src:url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:tk-proxima-nova-i7;src:url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-weight:700;font-style:italic;}@font-face{font-family:tk-proxima-nova-n4;src:url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:tk-proxima-nova-i4;src:url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-weight:400;font-style:italic;}@font-face{font-family:tk-raleway-n1;src:url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff2"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("opentype");font-weight:100;font-style:normal;}@font-face{font-family:tk-raleway-n7;src:url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:tk-raleway-n4;src:url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:tk-raleway-n5;src:url(https://use.typekit.net/af/145edc/000000000000000000013289/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}@font-face{font-family:tk-raleway-n3;src:url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff2"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("opentype");font-weight:300;font-style:normal;}@font-face{font-family:tk-raleway-n8;src:url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff2"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("opentype");font-weight:800;font-style:normal;}@font-face{font-family:tk-raleway-n9;src:url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff2"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("opentype");font-weight:900;font-style:normal;}@font-face{font-family:tk-raleway-n2;src:url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff2"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("opentype");font-weight:200;font-style:normal;}@font-face{font-family:tk-raleway-n6;src:url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-weight:600;font-style:normal;}</style><script>try{Typekit.load({ async: true });}catch(e){}</script> <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="keywords" content="virtual classroom, online test, online course, MOOC,  SCORM, whiteboard, adaptive testing, e-learning, online education, learn online, teach online, live class, lms, monetize, sell course, online meetings, collaboration, webinar, how to, social, teach, learn"><meta name="description" content="Deliver live engaging classes using Virtual Classroom. Create and sell courses and tests online."><title>Review Answers | BrainCert</title><link href="https://www.braincert.com/templates/yoo_nano/favicon.ico" rel="shortcut icon" type="image/vnd.microsoft.icon"> <script type="text/javascript">
function keepAlive() {	var myAjax = new Request({method: "get", url: "index.php"}).send();} window.addEvent("domready", function(){ keepAlive.periodical(3540000); });
  </script> <script type="text/javascript">
				/*<![CDATA[*/
					var jax_live_site = 'https://www.braincert.com/index.php';
					var jax_token_var='925395911814f17127e11ea28577607f';
				/*]]>*/
				</script><script type="text/javascript" src="./sap-05_files/ajax_1.5.pack.js.下载"></script> <link rel="apple-touch-icon-precomposed" href="https://d9q55ve2f7k8m.cloudfront.net/images/apple_touch_icon.png"> <script>
        !function(window, document) {
            window._atatusConfig = {
                apikey: '8c2f3d535648489b9826fd95a6484c2b'
            };
            function _asyncAtatus(callback) {
                var script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.src = "https://dmc1acwvwny3.cloudfront.net/atatus.js";
                var node = document.getElementsByTagName("script")[0];
                script.addEventListener('load', function (e) {
                    callback(null, e);
                }, false);
                node.parentNode.insertBefore(script, node);
            }
            _asyncAtatus(function() {
                // Any atatus related calls.
                if (window.atatus) {
                    window.atatus.setUser('138600', 'liugongjianxin@163.com', 'gongjian liu');
                    console.log(window.atatus);
                }
            });
        }(window, document);
</script> <style type="text/css">@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-weight:700;font-style:italic;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-weight:400;font-style:italic;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff2"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("opentype");font-weight:100;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/145edc/000000000000000000013289/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff2"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("opentype");font-weight:300;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff2"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("opentype");font-weight:800;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff2"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("opentype");font-weight:900;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff2"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("opentype");font-weight:200;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-weight:600;font-style:normal;}</style><script type="text/javascript" src="./sap-05_files/ga.js.下载"></script><script async="" type="text/javascript" src="./sap-05_files/pops"></script><script async="" type="text/javascript" src="./sap-05_files/pops(1)"></script><script type="text/javascript" src="./sap-05_files/jquery.min.js.下载"></script></head><body id="page-top"><div id="page-wrap"><div id="preloader"> </div> <header id="header" class="header chapter-header"><div class="container"><div class="logo"><a href="https://www.braincert.com/"><img src="./sap-05_files/bc-logo-sm.png" alt="BrainCert" style="max-height:60px;"></a> </div><nav class="navigation"><div class="navbar-header"> <a class="navbar-brand" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222#"><span class="navbar-header-title"> AWS Certified Solutions Architect Professional SAP-C01 Practice </span></a> </div><ul class="menu"> <li><a href="https://www.braincert.com/">Home</a></li> </ul><div class="search-box"> <a href="https://www.braincert.com/test/11998-AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice-Exam-5" class="smoothScroll"><i class="fa fa-chevron-left"></i> Back</a> </div></nav> </div> </header><div class="main-container"> <script type="text/javascript">
  jQuery(document).ready(function (){
     
    jQuery( "html" ).addClass( "secondary-14px" );
    jQuery(document)[0].oncontextmenu = function() {return false;} 
    // code for preventing copy from keyboard
    var ambit = jQuery(document);
    // Disable Cut + Copy + Paste (input)
    ambit.on('copy paste cut', function (e) {
    e.preventDefault(); //disable cut,copy,paste
      return false;
    });
      });
</script> <div class="container"><div id="content-main" class="row-fluid"><div class="col-sm-12"><h2 style="margin-bottom:10px;margin-top:10px; float:left">Test Report</h2><div style="margin-top:10px;float:right"><a onclick="window.history.back();" class="btn btn-warning"><span><strong>Back</strong></span></a></div><div style="float:right;margin-top:10px;margin-right: 10px;"><a href="https://www.braincert.com/test/reviewtest/exportdata/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222" class="btn btn-primary"><span><strong><i class="fa fa-share-square-o"></i>&nbsp;Export to .CSV</strong></span></a></div><div style="border-bottom-width: 1px;border-bottom-style: dashed;border-bottom-color: #e0e0e0;margin-bottom: 10px; clear:both"></div><div style="clear:both;"></div><div class="col-md-6 pull-left row"><h3 style="margin-top: 0px;"><strong>Review questions</strong></h3></div><div class="col-md-6 pull-right row" style="font-size: 16px;text-align: right;"><strong>Student : </strong>gongjian liu
<br> <i class="fa fa-calendar"></i>&nbsp;Jun 17, 2019&nbsp;&nbsp;<i class="fa fa-clock-o"></i>&nbsp;12:56AM EDT<br> <br> </div><div id="test_results" style="padding-top: 80px;"><div id="quiz_specific"> <span id="select"></span> <div class="quiz_attempt_breakdown"><div class="percent_correct_bar col-sm-2"><div class="progress" style="margin-bottom: 2px;"><div class="progress-bar" role="progressbar" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100" style="width:16%"> </div> </div> <span id="percent"><strong>16% </strong>correct</span> </div><div><div class="questions_correct col-sm-2"><span class="inline_pipe">|</span>&nbsp;&nbsp; <img src="./sap-05_files/tick.webp" alt="you got this question right">&nbsp;<strong>8 correct</strong></div><div class="questions_incorrect col-sm-2"><span class="inline_pipe"> | </span>&nbsp;&nbsp; <img src="./sap-05_files/cross.webp" alt="you got this question wrong">&nbsp;<strong>43 incorrect</strong></div><div class="questions_incorrect col-sm-3" style="margin:0;"><span class="inline_pipe"> | </span>&nbsp;&nbsp;<img src="./sap-05_files/icon_un_answered.webp" alt="you got this question unanswer">&nbsp;<strong>0 Unanswered</strong></div><div class="total_questions col-sm-3"><span class="inline_pipe"> | </span>&nbsp;&nbsp;<strong>51 questions attempted out of 51</strong></div></div></div><br class="clear"><hr style="clear:both"><br> <br><div style="margin-bottom: 10px;"> <b style="font-size: 14.5px;">Filter by</b> : <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222" class="label-default label">All</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222?sort=1">correct</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222?sort=0">incorrect</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222?sort=-1">Unanswered</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145222?sort=2">Question feedback</a> </div><br><div class="" style="font-size: 18px;line-height: 25px;"><div class="question_info"><div class="question_no"><b>Question : 1 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249378"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You're consulting for a new customer, who is attempting to create a hybrid network between AWS and their on-premise data centers. Currently, they have internal databases running on-premise that, due to licensing reasons, cannot be migrated to AWS. The front end of the application has been migrated to AWS and uses the DB hostname "db.internalapp.local" to communicate with the on-premise database servers. Hostnames provide an easy method for updating IP addresses in event of failover instead of having to update the IP address in the code. Given the current architecture what is the best way to configure internal DNS for this hybrid application? Choose the 2 correct answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 15 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Configure the database to have a public-facing IP address and use Route 53 to create a domain name</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use an existing on-premise DNS server to configure hostnames for internal DNS records. Create a new Amazon VPC DHCP Option Set with the internal DNS server's IP address.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use an existing on-premise DNS server to configure hostnames for internal DNS records. Create a new Amazon VPC route tablee with the internal DNS server's IP address<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Create an EC2 instance DNS server to configure hostnames for internal DNS records, Create a new Amazon VPC DHCP option set with the internal DNS server's IP address. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Use an existing on-premise DNS server to configure hostnames for internal DNS records. Create a new Amazon VPC DHCP Option Set with the internal DNS server's IP address.<br><b>D</b>. Create an EC2 instance DNS server to configure hostnames for internal DNS records, Create a new Amazon VPC DHCP option set with the internal DNS server's IP address.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>B &amp; D</strong> as the best option is to use DHCP option sets and use either a existing on-premise DNS server or EC2 instance DNS server. </p><p>Refer AWS Blog <a href="https://aws.amazon.com/blogs/security/how-to-set-up-dns-resolution-between-on-premises-networks-and-aws-by-using-unbound/" target="_blank">DNS resolution between on-premises and AWS</a> </p><p>Option A is wrong as Internal Route 53 record sets would not work since Route 53 internal resource record sets only work for requests originating from within the VPC and currently cannot extend to on-premise. Also the application is an internal application. Using a public IP address would cause the application to route externally, which is not part of the desired architecture. </p><p>Option C is wrong as you need to create a DHCP option set and not a a VPC route tablee for host name resolution. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120520">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 2 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249379"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have been given the task of designing a backup strategy for your organization's AWS resources with the only caveat being that you must use the AWS Storage Gateway. Which of the following is the most correct statement surrounding the backup strategy on the AWS Storage Gateway? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;You should use the Gateway-Virtual Tape Library (VTL) as Gateway-Cached Volumes and Gateway-Stored Volumes cannot be used for backups.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;You should use Gateway-Cached Volumes. You will have quicker access to the data, and it is a more preferred backup solution than Gateway-Stored volumes.<br><b>C</b>. <input type="radio" disabled="">&nbsp;It doesn't matter whether you use Gateway-Cached volumes or Gateway-Stored volumes as long as you also combine either of these solutions with the Gateway-Virtual Tape Library (VTL).<br><b>D</b>. <input type="radio" disabled="">&nbsp;You should use Gateway-Stored Volumes as it is preferable to Gateway-Cached Volumes as a backup storage medium. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. You should use Gateway-Stored Volumes as it is preferable to Gateway-Cached Volumes as a backup storage medium.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D </strong>as the question mainly targets backup strategy, it would make sense to use Gateway Storage to have the backups in AWS while the data also resides on-premises. Gateway cached volume is mainly an actual storage option, where the entire data sits in AWS, which only the frequently accessed data on premises for low latency access. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html" target="_blank">Storage gateway</a> </p><ul> <li><em><strong>Cached Volumes</strong> – You store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Cached volumes offer a substantial cost savings on primary storage and minimize the need to scale your storage on-premises. You also retain low-latency access to your frequently accessed data.</em></li> <li><em><strong>Stored Volumes</strong> – If you need low-latency access to your entire data set, you can configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3. This configuration provides durable and inexpensive off-site backups that you can recover to your local data center or Amazon EC2. For example, if you need replacement capacity for disaster recovery, you can recover the backups to Amazon EC2.</em></li> </ul> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120436">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 3 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249380"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You run a media website which utilizes CloudFront for global content delivery. There are some pieces of content, which need to be blocked from underage visitors, and you want to ensure that happens at the edge. The user's age is stored in their application profile and your developers have said that they can if required add this to the application cookie to assist with any architectural changes. How would you accomplish this using AWS technologies?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure CloudFront to pass through the application-generated cookie (containing the user's age) and define an edge routing rule to block any adult objects when the age is below 18.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Add trusted signers to all behaviours on the CF distribution. Have the application generated signed URL's.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use WAF and enable the websockets option to allow communications with the application directly. WebACL's can then block content based on the user profile field.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Adjust the application to not show any images when the user age is below 18. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Add trusted signers to all behaviours on the CF distribution. Have the application generated signed URL's.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as trusted signers would make the distribution private and the sharing of data can be controlled using Signed urls, which can be generated only if the user is over 18 yrs old. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-trusted-signers.html" target="_blank">CloudFront Trusted Signers<em></em></a> </p><p><em>To create signed URLs or signed cookies, you need at least one AWS account that has an active CloudFront key pair. This account is known as a trusted signer. The trusted signer has two purposes:</em> </p><ul> <li><em>As soon as you add the AWS account ID for your trusted signer to your distribution, CloudFront starts to require that users use signed URLs or signed cookies to access your files.</em></li> <li><em>When you create signed URLs or signed cookies, you use the private key from the trusted signer's key pair to sign a portion of the URL or the cookie. When someone requests a restricted file, CloudFront compares the signed portion of the URL or cookie with the unsigned portion to verify that the URL or cookie hasn't been tampered with. CloudFront also verifies that the URL or cookie is valid, meaning, for example, that the expiration date and time hasn't passed.</em></li> </ul><p>Option A is wrong as CloudFront does not have this feature. </p><p>Option C is wrong as WAF does not have this feature. </p><p>Option D is wrong as the images can be accessed directly is url known. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121108">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 4 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249381"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A benefits enrollment company is hosting a 3-tier web application running in a VPC on AWS, which includes a NAT (Network Address Translation) instance in the public Web tier. There is enough provisioned capacity for the expected workload for the new fiscal year benefit enrollment period plus some extra overhead. Enrollment proceeds nicely for two days and then the web tier becomes unresponsive, upon investigation using CloudWatch and other monitoring tools it is discovered that there is an extremely large and unanticipated amount of inbound traffic coming from a set of 15 specific IP addresses over port 80 from a country where the benefits company has no customers. The web tier instances are so overloaded that benefit enrollment administrators cannot even SSH into them. Which activity would be useful in defending against this attack?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a custom route table associated with the web tier and block the attacking IP addresses from the IGW (internet Gateway)</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Change the EIP (Elastic IP Address) of the NAT instance in the web tier subnet and update the Main Route table with the new EIP<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create 15 Security Group rules to block the attacking IP addresses over port 80<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an inbound NACL (Network Access control list) associated with the web tier subnet with deny rules to block the attacking IP addresses <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Create an inbound NACL (Network Access control list) associated with the web tier subnet with deny rules to block the attacking IP addresses<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as NACL can be used to deny access to the attacking IP address. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html" target="_blank">VPC NACLs</a> </p><p>Option A is wrong as Route table cannot help block traffic but just define routes for traffic. </p><p>Option B is wrong as NAT is only for routing outgoing traffic and not incoming traffic.<br> </p><p>Option C is wrong as Security Groups cannot help block/deny access.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120602">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 5 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249382"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are the new IT architect in a company that operates a mobile sleep tracking application. When activated at night, the mobile app is sending collected data points of 1 kilobyte every 5 minutes to your backend. The backend takes care of authenticating the user and writing the data points into an Amazon DynamoDB table. Every morning, you scan the table to extract and aggregate last night’s data on a per user basis, and store the results in Amazon S3. Users are notified via Amazon SMS mobile push notifications that new data is available, which is parsed and visualized by the mobile app. Currently you have around 100k users who are mostly based out of North America. You have been tasked to optimize the architecture of the backend system to lower cost what would you recommend? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 3 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Create a new Amazon DynamoDB table each day and drop the one for the previous day after its data is on Amazon S3</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Have the mobile app access Amazon DynamoDB directly instead of JSON files stored on Amazon S3<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Introduce an Amazon SQS queue to buffer writes to the Amazon DynamoDB table and reduce provisioned write throughput.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Introduce Amazon ElastiCache to cache reads from the Amazon DynamoDB table and reduce provisioned read throughput<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Write data directly into an Amazon Redshift cluster replacing both Amazon DynamoDB and Amazon S3. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Create a new Amazon DynamoDB table each day and drop the one for the previous day after its data is on Amazon S3<br><b>C</b>. Introduce an Amazon SQS queue to buffer writes to the Amazon DynamoDB table and reduce provisioned write throughput.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A &amp; C</strong> </p><p>Option A as it would help save on DynamoDB per GB charge, by creating the table for each day and discarding old data. </p><p>Option C as DynamoDB pricing is per provisioning and charged per hour and using SQS to buffer writes would help keep the provisioned write throughput down. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/dynamodb/pricing/" target="_blank">DynamoDB Pricing</a> </p><p>Option B is wrong as the report once generated need not be generated again, it will introduce latency and if directly generated from DynamoDB, the cost would increase. </p><p>Option D is wrong as the reads are less as compared to writes, ElastiCache would not help cut cost down.<br> </p><p>Option E is wrong as Redshift does not provide http endpoints for data insertion and provide interface using jdbc/odbc and is not suitable for high frequency data insertion.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120549">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 6 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249383"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your application is using an ELB in front of an Auto Scaling group of web/application servers deployed across two AZs and a Multi-AZ RDS Instance for data persistence. The database CPU is often above 80% usage and 90% of I/O operations on the database are reads. To improve performance you recently added a single-node Memcached ElastiCache Cluster to cache frequent DB query results. In the next weeks the overall workload is expected to grow by 30%. Do you need to change anything in the architecture to maintain the high availability of the application with the anticipated additional load and Why?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Yes. You should deploy two Memcached ElastiCache Clusters in different AZs because the RDS Instance will not be able to handle the load if the cache node fails.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;No. If the cache node fails the automated ElastiCache node recovery feature will prevent any availability impact.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Yes you should deploy the Memcached ElastiCache Cluster with two nodes in the same AZ as the RDS DB master instance to handle the load if one cache node fails.<br><b>D</b>. <input type="radio" disabled="">&nbsp;No if the cache node fails you can always get the same data from the DB without having any availability impact. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Yes. You should deploy two Memcached ElastiCache Clusters in different AZs because the RDS Instance will not be able to handle the load if the cache node fails.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point is here providing HA on overloaded database with mainly read operations performed on it </p><p>Correct answer is <strong>A</strong><br> </p><p>Refer to <a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/BestPractices.html" target="_blank">ElastiCache Best Practices</a> </p><p><strong>Mitigating Node Failures</strong><br> </p><p><em>To mitigate the impact of a node failure, spread your cached data over more nodes. Because Memcached does not support replication, a node failure will always result in some data loss from your cluster.</em> </p><p><em>When you create your Memcached cluster you can create it with 1 to 20 nodes, or more by special request. Partitioning your data across a greater number of nodes means you’ll lose less data if a node fails. For example, if you partition your data across 10 nodes, any single node stores approximately 10% of your cached data. In this case, a node failure loses approximately 10% of your cache which needs to be replaced when a replacement node is created and provisioned.</em> </p><p><strong>Mitigating Availability Zone Failures</strong><br> </p><p><em>To mitigate the impact of an availability zone failure, locate your nodes in as many availability zones as possible. In the unlikely event of an AZ failure, you will lose only the data cached in that AZ, not the data cached in the other AZs.</em> </p><p>Option B is wrong as it does not provide high availability, as data is lost if a cluster is lost and all the load would be on DB </p><p>Option C is wrong as Single AZ affects availability as DB is Multi AZ and would be overloaded is the AZ goes down </p><p>Option D is wrong as will overload the database affecting availability due to existing and additional load </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120245">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 7 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249384"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing security inside your VPC. You are considering the options for establishing separate security zones and enforcing network traffic rules across different zone to limit Instances can communications. How would you accomplish these requirements? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 3 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Configure a security group for every zone. Configure a default allow all rule. Configure explicit deny rules for the zones that shouldn't be able to communicate with one another</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Configure your instances to use pre-set IP addresses with an IP address range every security zone. Configure NACL to explicitly allow or deny communication between the different IP address ranges, as required for interzone communication<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Configure a security group for every zone. Configure allow rules only between zone that need to be able to communicate with one another. Use implicit deny all rule to block any other traffic<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Configure multiple subnets in your VPC, one for each zone. Configure routing within your VPC in such a way that each subnet only has routes to other subnets with which it needs to communicate, and doesn't have routes to subnets with which it shouldn't be able to communicate. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Configure your instances to use pre-set IP addresses with an IP address range every security zone. Configure NACL to explicitly allow or deny communication between the different IP address ranges, as required for interzone communication<br><b>C</b>. Configure a security group for every zone. Configure allow rules only between zone that need to be able to communicate with one another. Use implicit deny all rule to block any other traffic<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>B &amp; C</strong> as the communication can be controlled either using security group for all the instances in the zone or NACLs at the zone level. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Security.html" target="_blank">VPC Security</a> </p><p>Option B as NACLs can be used to configure rules with IP address to allow or deny traffic. </p><p>Option C as Security group can take IP address or security group and can allow them. Default is implicit deny </p><p>Option A is wrong as Security group does not allow deny rules </p><p><strong></strong> </p><p>Option D is wrong as default routes are unmodifiable and cannot use routing table to determine routing between subnets in a VPC. in a VPC all subnets are reachable from all other subnets within the same VPC. That is the default behavior and cannot be changed. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120524">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 8 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249385"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Dynamic Host Configuration Protocol (DHCP) provides a standard for passing configuration information to hosts on a TCP/IP network. You can have multiple sets of DHCP options, but you can associate only one set of DHCP options with a VPC at a time. You have just created your first set of DHCP options, associated it with your VPC but now realize that you have made an error in setting them up and you need to change the options. Which of the following options do you need to take to achieve this?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;You need to stop all the instances in the VPC. You can then change the options, and they will take effect when you start the instances.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;You can modify the options from the console or the CLI.<br><b>C</b>. <input type="radio" disabled="">&nbsp;You must create a new set of DHCP options and associate them with your VPC.<br><b>D</b>. <input type="radio" disabled="">&nbsp;You can modify the options from the CLI only, not from the console. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. You must create a new set of DHCP options and associate them with your VPC.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Refer to <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_DHCP_Options.html#DHCPOptions" target="_blank">VPC DHCP Options</a> </p><p>Correct answer is <strong>C</strong> as DHCP cannot be modified. </p><pre>After you create a set of DHCP options, you can't modify them. 
If you want your VPC to use a different set of DHCP options, 
you must create a new set and associate them with your VPC. 
You can also set up your VPC to use no DHCP options at all.
</pre> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120414">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 9 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249386"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company has run a major auction platform where people buy and sell a wide range of products. The platform requires that transactions from buyers and sellers get processed in exactly the order received. At the moment, the platform is implemented using RabbitMQ, which is a light weighted queue system. The company consulted you to migrate the on-premise platform to AWS. How should you design the migration plan? (Select TWO)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 3 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;When the bids are received, send the bids to a SQS FIFO queue before they are processed.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;When the users have submitted the bids from frontend, the backend service delivers the messages to a SQS standard queue.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Add a message group ID to the messages before they are sent to the SQS queue so that the message processing is in a strict order.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use an EC2 or Lambda to add a deduplication ID to the messages before the messages are sent to the SQS queue to ensure that bids are processed in the right order. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. When the bids are received, send the bids to a SQS FIFO queue before they are processed.<br><b>C</b>. Add a message group ID to the messages before they are sent to the SQS queue so that the message processing is in a strict order.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A &amp; C </strong>as SQS FIFO Queues provide message ordering. Message Group Ids can be used for ordering with the same message group. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-message-order" target="_blank">SQS FIFO Message Ordering</a> </p><p><em>The FIFO queue improves upon and complements the <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html">standard queue</a>. The most important features of this queue type are <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-understanding-logic">FIFO (First-In-First-Out) delivery</a> and <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-exactly-once-processing">exactly-once processing</a>: </em> </p><ul> <li><em>The order in which messages are sent and received is strictly preserved and a message is delivered once and remains available until a consumer processes and deletes it.</em></li> <li><em>Duplicates aren't introduced into the queue.</em></li> </ul><p><em>In addition, FIFO queues support message groups that allow multiple ordered message groups within a single queue. </em> </p><p><em><strong>Message Group ID - </strong>The tag that specifies that a message belongs to a specific message group. Messages that belong to the same message group are always processed one by one, in a strict order relative to the message group (however, messages that belong to different message groups might be processed out of order).</em> </p><p>Option B is wrong as SQS standard queue does not guarantee message ordering. </p><p>Option D is wrong as deduplication ID is for preventing message to be processed duplicately but does not control ordering. <em><strong>Message Deduplication ID</strong> - </em><em>The token used for deduplication of sent messages. If a message with a particular message deduplication ID is sent successfully, any messages sent with the same message deduplication ID are accepted successfully but aren't delivered during the 5-minute deduplication interval.</em><em></em> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120838">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 10 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249387"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing a photo sharing mobile app the application will store all pictures in a single Amazon S3 bucket. Users will upload pictures from their mobile device directly to Amazon S3 and will be able to view and download their own pictures directly from Amazon S3. You want to configure security to handle potentially millions of users in the most secure manner possible. What should your server-side application do when a new user registers on the photo-sharing mobile application?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a set of long-term credentials using AWS Security Token Service with appropriate permissions Store these credentials in the mobile app and use them to access Amazon S3.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Record the user’s Information in Amazon RDS and create a role in IAM with appropriate permissions. When the user uses their mobile app create temporary credentials using the AWS Security Token Service ‘AssumeRole’ function. Store these credentials in the mobile app’s memory and use them to access Amazon S3 Generate new credentials the next time the user runs the mobile app<br><b>C</b>. <input type="radio" disabled="">&nbsp;Record the user’s Information In Amazon DynamoDB. When the user uses their mobile app create temporary credentials using AWS Security Token Service ‘AssumeRole’ function. Store these credentials in the mobile app’s memory and use them to access Amazon S3 Generate new credentials the next time the user runs the mobile app.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create IAM user. Assign appropriate permissions to the IAM user Generate an access key and secret key for the IAM user, store them in the mobile app and use these credentials to access Amazon S3.<br><b>E</b>. <input type="radio" disabled="">&nbsp;Create an IAM user. Update the bucket policy with appropriate permissions for the IAM user Generate an access Key and secret Key for the IAM user, store them In the mobile app and use these credentials to access Amazon S3. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Record the user’s Information In Amazon DynamoDB. When the user uses their mobile app create temporary credentials using AWS Security Token Service ‘AssumeRole’ function. Store these credentials in the mobile app’s memory and use them to access Amazon S3 Generate new credentials the next time the user runs the mobile app.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as you can maintain the info in DynamoDB and create a IAM role once with proper permissions. IAM role can be assumed by the application to access AWS service.<br> </p><p>User login Assume a IAM role -&gt; Call STS for temporary credentials -&gt; Access S3<span class="redactor-invisible-space"><br></span> </p><p>Key point here is to understand <a href="http://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html" target="_blank">IAM Assume Role</a> </p><p>Option B is wrong as although the option is similar to C and uses RDS. DynamoDB would be a better option as compared to RDS. </p><p>Option A, D &amp; E are wrong as using the long term credentials for an IAM user that is being stored in the mobile app is not recommended </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120210">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 11 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249388"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Due to cost-cutting measurements being implemented by your organization, you have been told that you need to migrate some of your existing resources to another region. The first task you have been given is to copy all of your Amazon Machine Images from Asia Pacific (Sydney) to US West (Oregon). One of the things that you are unsure of is how the PEM keys on your Amazon Machine Images need to be migrated. Which of the following best describes how your PEM keys are affected when AMIs are migrated between regions? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Neither the PEM key nor the authorized key is copied and consequently you need to create new keys when you launch the new instance.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;The PEM keys will not be copied to the new region but the authorization keys will still be in the operating system of the AMI. You need to ensure when the new AMI is launched that it is launched with the same PEM key name.<br><b>C</b>. <input type="radio" disabled="">&nbsp;The PEM keys will also be copied across; however, they will only work for users who have already accessed them in the old region. If you need new users to access the instances then new keys will need to be generated.<br><b>D</b>. <input type="radio" disabled="">&nbsp;The PEM keys will also be copied across so you don't need to do anything except launch the new instance. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. The PEM keys will not be copied to the new region but the authorization keys will still be in the operating system of the AMI. You need to ensure when the new AMI is launched that it is launched with the same PEM key name.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as AWS does not maintain or store the PEM i.e. private keys. However, AWS also does not exclude the authorized_keys when creating an image, so they are bundled with the image, unless explicitly excluded, and would be copied over to the other region. </p><p>Refer AWS <a href="https://media.amazonwebservices.com/AWS_Migrate_Resources_To_New_Region.pdf" target="_blank">Migration AWS Resources to a New Region</a> Whitepaper </p><p><em>SSH public keys are only stored per region; AWS does not copy or synchronize the configured customer SSH keys between regions. It is up to customers to determine if they will use separate SSH keys per region, or the same SSH keys in several regions. <strong>Note</strong>: You can log onto an existing Linux instance in the source region, obtain a copy of the public key (from ~/.ssh/authorized_keys), and import this into the destination region. </em> </p><p><em></em> </p><p><em>It is important to note that Auto Scaling launch configurations and AWS CloudFormation templates may refer to SSH keys using the key pair name. In this case, the user must take care to either update any Auto Scaling launch configuration or AWS CloudFormation template to use keys that are available in a new region, or deploy the public key with the same key pair name to the new region </em> </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/building-shared-amis.html#public-amis-protect-yourself" target="_blank">AMI</a> </p><p><em>We recommend using the <code>--exclude &lt;code&gt;directory</code> option on <code>ec2-bundle-vol</code> to skip any directories and subdirectories that contain secret information that you would not like to include in your bundle. In particular, exclude all user-owned SSH public/private key pairs and SSH <code>authorized_keys</code> files when bundling the image. The Amazon public AMIs store these in <code>/root/.ssh</code> for the root account, and <code>/home/&lt;code&gt;user_name</code>/.ssh/ for regular user accounts</em><br> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120534">AWS SAP-C01 Question feedback</a> </p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 12 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249389"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A startup deploys its photo-sharing site in a VPC. An elastic load balancer distributes web traffic across two subnets. The load balancer session stickiness is configured to use the AWS-generated session cookie, with a session TTL of 5 minutes. The web server Auto Scaling group is configured as min-size=4, max-size=4. The startup is preparing for a public launch, by running load-testing software installed on a single Amazon Elastic Compute Cloud (EC2) instance running in us-west-2a. After 60 minutes of load-testing, the web server logs show the following:+----------------------+-------------------------+WEBSERVER LOGS | # of HTTP requests from load-tester | # of HTTP requests from private beta users |+---------------------------------------|----------------------|-------------------------+| webserver #1 (subnet in us-west-2a): | 19,210 | 434 || webserver #2 (subnet in us-west-2a): | 21,790 | 490 || webserver #3 (subnet in us-west-2b): | 0 | 410 || webserver #4 (subnet in us-west-2b): | 0 | 428 |+---------------------------------------+----------------------+-------------------------+Which recommendations can help ensure that load-testing HTTP requests are evenly distributed across the four webservers? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 15 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Launch and run the load-tester Amazon EC2 instance from us-east-1 instead.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Configure Elastic Load Balancing session stickiness to use the app-specific session cookie.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Re-configure the load-testing software to re-resolve DNS for each web request.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Configure Elastic Load Balancing and Auto Scaling to distribute across us-west-2a and us-west-2b.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use a third-party load-testing service which offers globally distributed test clients. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Re-configure the load-testing software to re-resolve DNS for each web request.<br><b>E</b>. Use a third-party load-testing service which offers globally distributed test clients.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C &amp; E</strong> </p><p>When Elastic Load Balancing scales, it updates the DNS record with the new list of IP addresses. To ensure that clients are taking advantage of the increased capacity, Elastic Load Balancing uses a TTL setting on the DNS record of 60 seconds. It is critical that you factor this changing DNS record into your tests. If you do not ensure that DNS is re-resolved or use multiple test clients to simulate increased load, the test may continue to hit a single IP address when Elastic Load Balancing has actually allocated many more IP addresses. Because your end users will not all be resolving to that single IP address, your test will not be a realistic sampling of real-world behavior. </p><p>Option A would not have any impact change. </p><p>Option B - changing the session stickiness would not resolve the issue but cause the traffic for the user to go to the same instance again </p><p>Option D - ELB would automatically distribute the traffic to both the subnets registered with it </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120182">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 13 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249390"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing a service that aggregates clickstream data in batch and delivers reports to subscribers via email only once per week. Data is extremely spikey, geographically distributed, high-scale, and unpredictable. How should you design this system?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use a large Redshift cluster to perform the analysis, and a fleet of Lambdas to perform record inserts into the Redshift tables. Lambda will scale rapidly enough for the traffic spikes.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use a CloudFront distribution with access log delivery to S3. Clicks should be recorded as query string GETs to the distribution. Reports are built and sent by periodically running EMR jobs over the access logs in S3.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use API Gateway invoking Lambdas which PutRecords into Kinesis, and EMR running Spark performing GetRecords on Kinesis to scale with spikes. Spark on EMR outputs the analysis to S3, which are sent out via email.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use AWS Elasticsearch service and EC2 Auto Scaling groups. The Autoscaling groups scale based on click throughput and stream into the Elasticsearch domain, which is also scalable. Use Kibana to generate reports periodically. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Use a CloudFront distribution with access log delivery to S3. Clicks should be recorded as query string GETs to the distribution. Reports are built and sent by periodically running EMR jobs over the access logs in S3.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is clickstream batch analysis for large global data only once per week </p><p>Correct answer is <strong>B</strong> as CloudFront is a Gigabit-Scale HTTP(S) global request distribution service and works fine with peaks higher than 10 Gbps or 15,000 RPS. It can handle scale, geo-spread, spikes, and unpredictability. Access Logs will contain the GET data. EMR can be used for batch analysis </p><p>Other streaming options are expensive as not required as the need is to batch analyze </p><p>Option A is wrong as Redshift is more of Data Warehousing solution and with lambda not needed as it is more of an batch analytics solution </p><p>Option C is wrong as Lambdas with Kinesis is more for streaming real time data. </p><p>Option D is wrong as Elasticsearch is more of an search solution and not batch analytics </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120232">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 14 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249391"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are a software engineer and are creating a new web service in AWS. The service is about daily schedules where end users are able to configure and fetch. It contains an AngularJs front end that deals with the data in a DynamoDB table called UserScheduleData. You plan to use API gateway and Lambda to handle the backend service. During development, you also need to do integration testing frequently using curl for the API endpoints. You have created a role ScheduleRoleLambda for the lambda itself. What below options should you perform to make sure that the lambda contains the necessary permissions? (Select THREE) <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;AWSXrayWriteOnlyAccess policy is needed for ScheduleRoleLambda so that a segment record with details about the function invocation and execution can be saved for tracking and debug purpose. </span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;ScheduleRoleLambda should have a policy for CloudWatch Logs including CreateLogGroup, CreateLogStream and PutLogEvents. <br><b>C</b>. <input type="checkbox" disabled="">&nbsp;To grant invoke permission from the API gateway, a permission is needed to the permissions policy associated with your Lambda function<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;sns:publish allow inline policy should be added into ScheduleRoleLambda for error handlings. For example, when exception appears, the message can be put into a dead letter queue via SNS publish <br><b>E</b>. <input type="checkbox" disabled="">&nbsp;ScheduleRoleLambda should contain an inline policy to allow DynamoDB access. The resource should be "*" and the action should contain dynamodb:FetchItem, dynamodb:PutItem and dynamodb:Query. <br><b>F</b>. <input type="checkbox" disabled="">&nbsp;An inline policy to allow DynamoDB access is needed for ScheduleRoleLambda. The resource should be the ARN of UserScheduleData and the action should contain dynamodb:GetItem and dynamodb:PutItem. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. ScheduleRoleLambda should have a policy for CloudWatch Logs including CreateLogGroup, CreateLogStream and PutLogEvents. <br><b>C</b>. To grant invoke permission from the API gateway, a permission is needed to the permissions policy associated with your Lambda function<br><b>F</b>. An inline policy to allow DynamoDB access is needed for ScheduleRoleLambda. The resource should be the ARN of UserScheduleData and the action should contain dynamodb:GetItem and dynamodb:PutItem. <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B, C &amp; F</strong>. </p><p>Option B as it provides Lambda the permissions to integrate with CloudWatch for logs and metrics </p><p>Option C as it provides API Gateway the permission to call Lambda functions </p><p>Option F as it provides Lambda the permission to interact with DynamoDB. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/lambda/latest/dg/with-on-demand-https-example.html" target="_blank">API Gateway + Lambda + DynamoDB example</a> </p><pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1428341300017",
      "Action": [
        "dynamodb:DeleteItem",
        "dynamodb:GetItem",
        "dynamodb:PutItem",
        "dynamodb:Query",
        "dynamodb:Scan",
        "dynamodb:UpdateItem"
      ],
      "Effect": "Allow",
      "Resource": "*"
    },
    {
      "Sid": "",
      "Resource": "*",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Effect": "Allow"
    }
  ]
}
</pre><p>Option A is wrong as XRay is needed only if you want to trace the Lambda functions. </p><p>Option D is wrong as SNS is needed only if the Lambda function needs to publish any notifications. </p><p>Option E is wrong as the permission should be granted for GetItem and FetchItem does not exist. Also, inline with the principle of least privilege, the ARN should be specific and not to all i.e. *. <br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120580">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 15 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249392"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company has on-premises multi-tier PHP web application, which recently experienced downtime due to a large burst in web traffic due to a company announcement. Over the coming days, you are expecting similar announcements to drive similar unpredictable bursts, and are looking to find ways to quickly improve your infrastructures ability to handle unexpected increases in traffic. The application currently consists of 2 tiers a web tier, which consists of a load balancer, and several Linux Apache web servers as well as a database tier which hosts a Linux server hosting a MySQL database. Which scenario below will provide full site functionality, while helping to improve the ability of your application in the short timeframe required?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Offload traffic from on-premises environment Setup a CloudFront distribution and configure CloudFront to cache objects from a custom origin Choose to customize your object cache behavior, and select a TTL that objects should exist in cache.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Migrate to AWS Use VM Import/Export to quickly convert an on-premises web server to an AMI create an Auto Scaling group, which uses the imported AMI to scale the web tier based on incoming traffic Create an RDS read replica and setup replication between the RDS instance and on-premises MySQL server to migrate the database.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Failover environment: Create an S3 bucket and configure it tor website hosting Migrate your DNS to Route53 using zone (lie import and leverage Route53 DNS failover to failover to the S3 hosted website.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Hybrid environment Create an AMI which can be used of launch web servers in EC2 Create an Auto Scaling group which uses the * AMI to scale the web tier based on incoming traffic Leverage Elastic Load Balancing to balance traffic between on-premises web servers and those hosted in AWS. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Offload traffic from on-premises environment Setup a CloudFront distribution and configure CloudFront to cache objects from a custom origin Choose to customize your object cache behavior, and select a TTL that objects should exist in cache.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here to improve scaling within a short timeframe. </p><p>Correct answer is <strong>A</strong> as company announcement means users access the same data again and it would make sense to cache the data using CloudFront reducing load on the existing infrastructure. </p><p>Option B is wrong as a full migration is never short and would take time to replicate the environment on AWS, also doubling the cost. </p><p>Option C is wrong as S3 bucket won't be able to handle web application functionality </p><p>Option D is wrong as a replication of environment would take time </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120224">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 16 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249393"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are moving an existing traditional system to AWS, and during the migration discover that there is a master server, which is a single point of failure. Having examined the implementation of the master server you realize there is not enough time during migration to re-engineer it to be highly available, though you do discover that it stores its state in a local MySQL database. In order to minimize down-time you select RDS to replace the local database and configure master to use it, what steps would best allow you to create a self-healing architecture?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Migrate the local database into multi-AZ RDS database. Place master node into a multi-AZ auto-scaling group with a minimum of one and maximum of one with health checks.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Replicate the local database into a RDS read replica. Place master node into a Cross-Zone ELB with a minimum of one and maximum of one with health checks.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Migrate the local database into multi-AWS RDS database. Place master node into a Cross-Zone ELB with a minimum of one and maximum of one with health checks.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Replicate the local database into a RDS read replica. Place master node into a multi-AZ auto-scaling group with a minimum of one and maximum of one with health checks. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Migrate the local database into multi-AZ RDS database. Place master node into a multi-AZ auto-scaling group with a minimum of one and maximum of one with health checks.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as Multi-AZ RDS and auto scaling group with min and max of 1 would provide HA as the key point here is self healing architecture<br></p><p>Option B &amp; D are wrong as Read Replica does not provide HA and write capability </p><p>Option B &amp; C are wrong as ELB does not have feature for Min and Max 1 and Cross Zone allows just the equal distribution of load across instances </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120363">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 17 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249394"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company previously configured a heavily used, dynamically routed VPN connection between your on premises data center and AWS. You recently provisioned a Direct Connect connection and would like to start using the new connection. After configuring Direct Connect settings in the AWS Console, which of the following options will provide the most seamless transition for your users?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Delete your existing VPN connection to avoid routing loops, configure your Direct Connect router with the appropriate settings and verity network traffic is leveraging Direct Connect.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Configure your Direct Connect router with a higher BGP priority than your VPN router, verify network traffic is leveraging Direct Connect and then delete your existing VPN connection.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Update your VPC route tables to point to the Direct Connect connection configure your Direct Connect router with the appropriate settings verify network traffic is leveraging Direct Connect and then delete the VPN connection.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Configure your Direct Connect router, update your VPC route tables to point to the Direct Connect connection, configure your VPN connection with a higher BGP priority. And verify network traffic is leveraging the Direct Connect connection <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Update your VPC route tables to point to the Direct Connect connection configure your Direct Connect router with the appropriate settings verify network traffic is leveraging Direct Connect and then delete the VPN connection.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> </p><p>Refer to the <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#route-tables-priority" target="_blank">Route table priority</a> &amp; <a href="https://www.youtube.com/watch?v=SMvom9QjkPk" target="_blank">Direct Connect reinvent video</a> </p><pre>If you've attached a virtual private gateway to your VPC and enabled route propagation on your route table, 
routes representing your VPN connection automatically appear as propagated routes in your route table. The following applies:
- If any propagated routes from a VPN connection or AWS Direct Connect connection overlap with the local 
route for your VPC, the local route is most preferred even if the propagated routes are more specific.
- If any propagated routes from a VPN connection or AWS Direct Connect connection have the same destination 
CIDR block as other existing static routes (longest prefix match cannot be applied), we prioritize the static 
routes whose targets are an Internet gateway, a virtual private gateway, a network interface, an instance ID, 
a VPC peering connection, a NAT gateway, or a VPC endpoint.
If you have overlapping routes within a VPN connection and longest prefix match cannot be applied, 
then we prioritize the routes as follows in the VPN connection, from most preferred to least preferred:
- BGP propagated routes from an AWS Direct Connect connection
- Manually added static routes for a VPN connection
- BGP propagated routes from a VPN connection
</pre><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120240">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 18 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249395"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An AWS customer is deploying a web application that is composed of a front-end running on Amazon EC2 and of confidential data that is stored on Amazon S3. The customer security policy that all access operations to this sensitive data must be authenticated and authorized by a centralized access management system that is operated by a separate security team. In addition, the web application team that owns and administers the EC2 web front-end instances is prohibited from having any ability to access the data that circumvents this centralized access management system. Which of the following configurations will support these requirements:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Encrypt the data on Amazon S3 using a CloudHSM that is operated by the separate security team. Configure the web application to integrate with the CloudHSM for decrypting approved data access operations for trusted end-users.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Configure the web application to authenticate end-users against the centralized access management system. Have the web application provision trusted users STS tokens entitling the download of approved data directly from Amazon S3<br><b>C</b>. <input type="radio" disabled="">&nbsp;Have the separate security team create and IAM role that is entitled to access the data on Amazon S3. Have the web application team provision their instances with this role while denying their IAM users access to the data on Amazon S3<br><b>D</b>. <input type="radio" disabled="">&nbsp;Configure the web application to authenticate end-users against the centralized access management system using SAML. Have the end-users authenticate to IAM using their SAML token and download the approved data directly from S3. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Configure the web application to authenticate end-users against the centralized access management system. Have the web application provision trusted users STS tokens entitling the download of approved data directly from Amazon S3<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is knowing <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html" target="_blank">IAM Identity Providers and Federation</a> and Access separation - the access should be through centralized access management system controlled by separate team with application users not having access to the data </p><p>Correct answer is <strong>B</strong> as it meets the authentication requirement and as the application generates temporary credentials only upon authentication, the application team cannot access the data even if they have EC2 access. </p><p>Option A is wrong as S3 doesn’t integrate directly with CloudHSM, also there is no centralized access management system control. Integration with the HSM means that the HSM client is installed on the instance and is registered/trusted and authorized to perform cryptographic operations, so during the decryption process the data will be stored unencrypted on the instance for the user to download via the web app </p><p>Option C is wrong as the web team would still have access to the data and the EC2 instance is configured with the IAM role </p><p>Option D is wrong as this is not the way SAML auth works as authentication data should be exchanged between the IDP (access management system) and the SP (AWS), to achieve SSO without user intervention </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120217">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 19 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249396"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> For a 3-tier, customer facing, inclement weather site utilizing a MySQL database running in a Region which has two AZs which architecture provides fault tolerance within the region for the application that minimally requires 6 web tier servers and 6 application tier servers running in the web and application tiers and one MySQL database?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;A web tier deployed across 2 AZs with 6 EC2 (Elastic Compute Cloud) instances in each AZ inside an Auto Scaling Group behind an ELB (elastic load balancer), and an application tier deployed across 2 AZs with 6 EC2 instances in each AZ inside an Auto Scaling Group behind an ELB and a Multi-AZ RDS (Relational Database Service) deployment.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;A web tier deployed across 2 AZs with 3 EC2 (Elastic Compute Cloud) instances in each AZ inside an Auto Scaling Group behind an ELB (elastic load balancer) and an application tier deployed across 2 AZs with 3 EC2 instances in each AZ inside an Auto Scaling Group behind an ELB and a Multi-AZ RDS (Relational Database Service) deployment.<br><b>C</b>. <input type="radio" disabled="">&nbsp;A web tier deployed across 2 AZs with 3 EC2 (Elastic Compute Cloud) instances in each AZ inside an Auto Scaling Group behind an ELB (elastic load balancer) and an application tier deployed across 2 AZs with 6 EC2 instances in each AZ inside an Auto Scaling Group behind an ELB and one RDS (Relational Database Service) Instance deployed with read replicas in the other AZs.<br><b>D</b>. <input type="radio" disabled="">&nbsp;A web tier deployed across 1 AZs with 6 EC2 (Elastic Compute Cloud) instances in each AZ Inside an Auto Scaling Group behind an ELB (elastic load balancer). And an application tier deployed in the same AZs with 6 EC2 instances inside an Auto scaling group behind an ELB and a Multi-AZ RDS (Relational Database services) deployment, with 6 stopped web tier EC2 instances and 6 stopped application tier EC2 instances all in the other AZ ready to be started if any of the running instances in the first AZ fails. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. A web tier deployed across 2 AZs with 6 EC2 (Elastic Compute Cloud) instances in each AZ inside an Auto Scaling Group behind an ELB (elastic load balancer), and an application tier deployed across 2 AZs with 6 EC2 instances in each AZ inside an Auto Scaling Group behind an ELB and a Multi-AZ RDS (Relational Database Service) deployment.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to provide fault tolerance, and not HA, so minimal 6 servers should always be running, no cost constraints. </p><p>Correct answer is <strong>A</strong> as running 6 instances in two AZs would provide the fault tolerance even if a single AZ goes down </p><p>Option B, C &amp; D are wrong as when a single AZ goes down it would take some time for the instances to come up to maintain the minimal 6 instances. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120368">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 20 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249397"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An employee keeps terminating EC2 instances on the production environment. You've determined the best way to ensure this doesn't happen is to add an extra layer of defense against terminating the instances. What is the best method to ensure the employee does not terminate the production instances? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Tag the instance with a production-identifying tag and add resource-level permissions to the employee user with an explicit deny on the terminate API call to instances with the production tag.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Tag the instance with a production-identifying tag and modify the employees group to allow only start, stop, and reboot api calls and not the terminate instance call.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Modify the IAM policy on the user to require MFA before deleting EC2 instances and disable MFA access to the employee<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Modify the IAM policy on the user to require MFA before deleting EC2 instances <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Tag the instance with a production-identifying tag and add resource-level permissions to the employee user with an explicit deny on the terminate API call to instances with the production tag.<br><b>B</b>. Tag the instance with a production-identifying tag and modify the employees group to allow only start, stop, and reboot api calls and not the terminate instance call.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A &amp; </strong><strong>B</strong> as the restrictions can be added by tagging the instances and either explicitly allowing the user to start/stop but not terminate the instances or denying user to terminate the instance. </p><p>Option C &amp; D are wrong as MFA will not prevent the user from terminating the instance, but just adds and additional layer of security. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120419">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 21 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249398"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have a web application running on six Amazon EC2 instances, consuming about 45% of resources on each instance. You are using auto-scaling to make sure that six instances are running at all times. The number of requests this application processes is consistent and does not experience spikes. The application is critical to your business and you want high availability at all times. You want the load to be distributed evenly between all instances. You also want to use the same Amazon Machine Image (AMI) for all instances. Which of the following architectural choices should you make?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Deploy 6 EC2 instances in one availability zone and use Amazon Elastic Load Balancer.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Deploy 3 EC2 instances in one region and 3 in another region and use Amazon Elastic Load Balancer.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Deploy 3 EC2 instances in one availability zone and 3 in another availability zone and use Amazon Elastic Load Balancer.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Deploy 2 EC2 instances in three regions and use Amazon Elastic Load Balancer. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Deploy 3 EC2 instances in one availability zone and 3 in another availability zone and use Amazon Elastic Load Balancer.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C </strong>as auto scaling with 3 EC2 instances in 2 AZs will provide High Availability and ELB will provide equal distribution of traffic on all instances </p><p>Option A is wrong as single AZ will not provide High Availability </p><p>Option B &amp; D are wrong as the instances are in different region, AMI would not be available unless copied. Also ELB is a regional service and cannot distribute load to instances across region. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120424">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 22 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249399"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> For application development and testing purpose, your team has created several EFS volumes recently. You have been assigned a task to mount these EFS file systems to EC2 Linux instances with encryption enabled in transit. You have already installed the EFS mount helper in the instances. To use the mount helper properly to mount the EFS volumes, which actions should you perform? (Select THREE)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Get that EFS file system's ID from the console or programmatically through the Amazon EFS API.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Make sure that the security group of EC2 instances has opened the port 443 for SSL traffic.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Create mount targets for EFS volumes before mounting in the virtual private cloud (VPC) availability zones of EC2 instances<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Create mount targets for EFS volumes after mounting in the virtual private cloud (VPC) availability zones of EC2 instances<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;In the EC2’s subnets, create a rule in network ACL to allow HTTPS traffic so that encryption in transit between EC2 and EFS file system is allowed<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;When the mount helper utility is used, add the encryption option that is -o tls <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Get that EFS file system's ID from the console or programmatically through the Amazon EFS API.<br><b>C</b>. Create mount targets for EFS volumes before mounting in the virtual private cloud (VPC) availability zones of EC2 instances<br><b>F</b>. When the mount helper utility is used, add the encryption option that is -o tls <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A, C &amp; F </strong> </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/efs/latest/ug/mounting-fs.html#mounting-fs-mount-helper" target="_blank">EFS mounting using mount helper</a> </p><p><em>Mounting on Amazon EC2 with the EFS Mount Helper</em> </p><p><em>You can mount an Amazon EFS file system on an Amazon EC2 instance using the Amazon EFS mount helper. To use the mount helper, you need the following: </em> </p><ul> <li><em><strong>An Amazon EFS file system ID</strong> – After you create an Amazon EFS file system, you can get that file system's ID from the console or programmatically through the Amazon EFS API. This ID is in this format: <code>fs-12345678</code>.</em></li> <li><em><strong>An Amazon EFS mount target</strong> – You create mount targets in your virtual private cloud (VPC). If you create your file system in the console, you create your mount targets at the same time.</em></li> <li><em><strong>An Amazon EC2 instance running a supported distribution of Linux</strong> – The supported Linux distributions for mounting your file system with the mount helper are Amazon Linux 2, Amazon Linux 2017.09 and newer, Red Hat Enterprise Linux (and derivatives such as CentOS) version 7 and newer, and Ubuntu 16.04 LTS and newer.</em></li> <li><em><strong>The Amazon EFS mount helper installed</strong> – The mount helper is a tool in amazon-efs-utils.</em></li> </ul><p>Options B &amp; E are wrong as Security Groups and ACLs are not required for enabling encryption in transit. </p><p>Option D is wrong as the mount targets should be created before the mounting. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120827">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 23 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249400"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company wants to prohibit the use of unapproved services in production AWS accounts and minimize additional management overhead as the number of accounts increases. Which approach would meet these requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a new organization with consolidated billing enabled. Create two new organizational units (OUs): one for production accounts and one for non-production accounts. In the new organization, create an IAM role that is applied to each sub-account in production that will deny access to services that are not approved.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a new organization with all features enabled. Create two new organizational units (OUs): one for production accounts and one for non-production accounts. In the new organization, create an IAM role that is applied to each sub-account in production that will deny access to services that are not approved.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a new organization with all features enabled. Create two new organizational units (OUs): one for production accounts and one for non-production accounts. In the new organization, create an SCP that will deny access to services that are not approved and apply the SCP to the production OU.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a new organization with consolidated billing enabled. Create two new organizational units (OUs): one for production accounts and one for non-production accounts. In the new organization, create an SCP that will deny access to services that are not approved and apply the SCP to the production OU. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create a new organization with all features enabled. Create two new organizational units (OUs): one for production accounts and one for non-production accounts. In the new organization, create an SCP that will deny access to services that are not approved and apply the SCP to the production OU.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as you need to create an Organizations with All Features Enabled. SCP can be used to control the access. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_introduction.html" target="_blank">Organizations</a> </p><p><em>AWS Organizations is an account management service that enables you to consolidate multiple AWS accounts into an organization that you create and centrally manage. AWS Organizations includes account management and consolidated billing capabilities that enable you to better meet the budgetary, security, and compliance needs of your business. As an administrator of an organization, you can create accounts in your organization and invite existing accounts to join the organization.</em><em></em><br> </p><p><em>As an administrator of the master account of an organization, you can use service control policies (SCPs) to specify the maximum permissions for member accounts in the organization. In SCPs, you can restrict which AWS services, resources, and individual API actions the users and roles in each member account can access. You can also define conditions for when to restrict access to AWS services, resources, and API actions. These restrictions even override the administrators of member accounts in the organization. When AWS Organizations blocks access to a service, resource, or API action for a member account, a user or role in that account can't access it, even if an administrator of a member account explicitly grants such permissions in an IAM policy.</em><br> </p><p>Options A &amp; D are wrong as you need to use All Features to use SCP. </p><p>Options A &amp; B are wrong as IAM role cannot be used to control access centrally. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121084">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 24 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249401"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Due to a lot of your EC2 services going off line at least once a week for no apparent reason your security officer has told you that you need to tighten up the logging of all events that occur on your AWS account. He wants to be able to access all events that occur on the account across all regions quickly and in the simplest way possible. He also wants to make sure he is the only person that has access to these events in the most secure way possible. Which of the following would be the best possible solution to assure the requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use CloudTrail to log all events to a separate S3 bucket in each region as CloudTrail cannot write to a bucket in a different region. Use MFA and bucket policies on all different buckets.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use CloudTrail to send all API calls to CloudWatch and send an email to the security officer every time an API call is made. Make sure the emails are encrypted<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use CloudTrail to log all events to one S3 bucket. Make this S3 bucket only accessible by your security officer with a bucket policy that restricts access to his user only and also add MFA to the policy for a further level of security<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use CloudTrail to log all events to an Amazon Glacier Vault. Make sure the vault access policy only grants access to the security officer's IP address. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use CloudTrail to log all events to one S3 bucket. Make this S3 bucket only accessible by your security officer with a bucket policy that restricts access to his user only and also add MFA to the policy for a further level of security<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here consolidated API activity tracking </p><p>Correct answer is <strong>C</strong> as APIs can be logged into a single access controlled S3 bucket with additional MFA security </p><p>Option A is wrong as not an ideal solution to create 3 different buckets </p><p>Option B is wrong as CloudTrail is used for tracking and not sending API calls to CloudWatch </p><p>Option D is wrong as Glacier is not an ideal storage solution here, as it is more of an archival solution. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120388">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 25 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249402"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A gaming company adopted AWS CloudFormation to automate load-testing of their games. They have created an AWS CloudFormation template for each gaming environment and one for the load-testing stack. The load-testing stack creates an Amazon Relational Database Service (RDS) PostgreSQL database and two web servers running on Amazon Elastic Compute Cloud (EC2) that send HTTP requests, measure response times, and write the results into the database. A test run usually takes between 15 and 30 minutes. Once the tests are done, the AWS CloudFormation stacks are torn down immediately. The test results written to the Amazon RDS database must remain accessible for visualization and analysis. Select possible solutions that allow access to the test results after the AWS CloudFormation load-testing stack is deleted. Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Define a deletion policy of type Retain for the Amazon RDS resource to assure that the RDS database is not deleted with the AWS CloudFormation stack.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Define a deletion policy of type Snapshot for the Amazon RDS resource to assure that the RDS database can be restored after the AWS CloudFormation stack is deleted.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Define automated backups with a backup retention period of 30 days for the Amazon RDS database and perform point-in-time recovery of the database after the AWS CloudFormation stack is deleted.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Define an Amazon RDS Read-Replica in the load-testing AWS CloudFormation stack and define a dependency relation between master and replica via the DependsOn attribute.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Define an update policy to prevent deletion of the Amazon RDS database after the AWS CloudFormation stack is deleted <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Define a deletion policy of type Retain for the Amazon RDS resource to assure that the RDS database is not deleted with the AWS CloudFormation stack.<br><b>B</b>. Define a deletion policy of type Snapshot for the Amazon RDS resource to assure that the RDS database can be restored after the AWS CloudFormation stack is deleted.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A &amp; B </strong>as with Deletion policy you can specify either Retain, to prevent the resource from getting deleted OR snapshot to create a snapshot before the resource is deleted, so that it can be restored. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-product-attribute-reference.html" target="_blank">CloudFormation Resource Attribute Reference</a><span class="redactor-invisible-space"><br></span> </p><p><em>With the DeletionPolicy attribute you can preserve or (in some cases) backup a resource when its stack is deleted. You specify a DeletionPolicy attribute for each resource that you want to control. If a resource has no DeletionPolicy attribute, AWS CloudFormation deletes the resource by default.</em> </p><p><em></em> </p><p><em>To keep a resource when its stack is deleted, specify <code>Retain</code> for that resource. You can use retain for any resource. For example, you can retain a nested stack, S3 bucket, or EC2 instance so that you can continue to use or modify those resources after you delete their stacks.</em> </p><p><em>For resources that support snapshots, such as <code>AWS::RDS::DBInstance</code> and <code>AWS::EC2::Volume</code>, you can specify <code>Snapshot</code> to have AWS CloudFormation create a snapshot before deleting the resource.</em> </p><p>Option C is wrong as the environment is required for limited time the automated backup will not serve the purpose and they would be deleted when the resource is deleted. </p><p>Option D is wrong as read replica not needed and will be deleted when the stack is deleted </p><p>Option E is wrong as UpdatePolicy does not apply to RDS </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120559">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 26 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249403"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company hosts an on-premises legacy engineering application with 900GB of data shared via a central file server. The engineering data consists of thousands of individual files ranging in size from megabytes to multiple gigabytes. Engineers typically modify 5-10 percent of the files a day. Your CTO would like to migrate this application to AWS, but only if the application can be migrated over the weekend to minimize user downtime. You calculate that it will take a minimum of 48 hours to transfer 900GB of data using your company’s existing 45-Mbps Internet connection. After replicating the application’s environment in AWS, which option will allow you to move the application’s data to AWS without losing any data and within the given timeframe?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Copy the data to Amazon S3 using multiple threads and multi-part upload for large files over the weekend, and work in parallel with your developers to reconfigure the replicated application environment to leverage Amazon S3 to serve the engineering files.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Sync the application data to Amazon S3 starting a week before the migration, on Friday morning perform a final sync, and copy the entire data set to your AWS file server after the sync completes.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Copy the application data to a 1-TB USB drive on Friday and immediately send overnight, with Saturday delivery, the USB drive to AWS Import/Export to be imported as an EBS volume, mount the resulting EBS volume to your AWS file server on Sunday.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Leverage the AWS Storage Gateway to create a Gateway-Stored volume. On Friday copy the application data to the Storage Gateway volume. After the data has been copied, perform a snapshot of the volume and restore the volume as an EBS volume to be attached to your AWS file server on Sunday. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Sync the application data to Amazon S3 starting a week before the migration, on Friday morning perform a final sync, and copy the entire data set to your AWS file server after the sync completes.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point is migration needs to happen within weekend - 48 hrs to minimize user downtime and only 5-10 % files are modified per day </p><p>Correct answer is <strong>B</strong> as it works best as the data changes can be propagated over the week and are fractional and downtime would be know </p><p>Option A is wrong as S3 multipart upload will still use the internet and as it does not start before would not be completed in time. </p><p>Option C is wrong as downtime is not known when the data upload would be done, although Amazon says the data will be upload next business day. Would work best if the import/export is done for initial data upload beforehand and the changes are handle incrementally. </p><p>Option D is wrong as Storage Gateway will still use the internet and as it does not start before would not be completed in time. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120260">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 27 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249404"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your team has a tomcat-based Java application you need to deploy into development, test and production environments. After some research, you opt to use Elastic Beanstalk due to its tight integration with your developer tools and RDS due to its ease of management. Your QA team lead points out that you need to roll a sanitized set of production data into your environment on a nightly basis. Similarly, other software teams in your org want access to that same restored data via their EC2 instances in your VPC. The optimal setup for persistence and security that meets the above requirements would be the following.<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 3 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create your RDS instance as part of your Elastic Beanstalk definition and alter its security group to allow access to it from hosts in your application subnets.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create your RDS instance separately and add its IP address to your application’s DB connection strings in your code. Alter its security group to allow access to it from hosts within your VPC’s IP address block. <br><b>C</b>. <input type="radio" disabled="">&nbsp;Create your RDS instance separately and pass its DNS name to your app’s DB connection string as an environment variable. Create a security group for client machines and add it as a valid source for DB traffic to the security group of the RDS instance itself.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create your RDS instance separately and pass its DNS name to your DB connection string as an environment variable. Alter its security group to allow access to it from hosts in your application subnets. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create your RDS instance separately and pass its DNS name to your app’s DB connection string as an environment variable. Create a security group for client machines and add it as a valid source for DB traffic to the security group of the RDS instance itself.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is optimal setup for persistence and security </p><p>Correct answer is <strong>C</strong> as security group to the client machines allows instances to access the RDS with new instances launched without any changes </p><p>Refer to AWS documentation for <a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.managing.db.html" target="_blank">Elastic Beanstalk managing DB</a> </p><p><em>A database instance that is part of your environment is tied to the lifecycle of your environment. If you terminate the environment, the database instance is terminated as well. An integrated database instance also cannot be removed from your environment once added.</em> </p><p>Option A is wrong as it is not optimal for persistence as the RDS is associated with the Elastic Beanstalk lifecycle and would not live independently </p><p>Option B is wrong as RDS can only be connected using DNS endpoint only and not IP address </p><p>Option D is wrong as the solution is not optimal for security as it needs adding individual hosts everytime </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120382">AWS SAP-C01 Question feedback</a> </p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 28 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249405"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You've been tasked with creating file level restore on your EC2 instances in case the files are corrupted. You need to be able to restore an individual lost file on an EC2 instance within 15 minutes of a reported loss of information. The acceptable RPO is several hours. How would you perform this on an EC2 instance? Choose an answer from the options below <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Setup a cron job that runs AWS S3 copy on the files and copy the files from the EBS volume to S3</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Take frequent snapshots of EBS volumes, create a volume from an EBS snapshot, attach the EBS volume to the EC2 instance at a different mount location, copy the file from the backup and cutover the application to look at the new backup volume and remove the old volume<br><b>C</b>. <input type="radio" disabled="">&nbsp;Take frequent snapshots of EBS volumes, create a volume from an EBS snapshot, attach the EBS volume to the EC2 instance at a different mount Location, browse the file system to the file that needs to be restored on the new mount, copy from the backup volume<br><b>D</b>. <input type="radio" disabled="">&nbsp;Enable auto snapshots on Amazon EC2 and restore the EC2 instance upon single file failure <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Take frequent snapshots of EBS volumes, create a volume from an EBS snapshot, attach the EBS volume to the EC2 instance at a different mount Location, browse the file system to the file that needs to be restored on the new mount, copy from the backup volume<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is the RTO of 15 mins and RPO is several hours, which means it is fine to lose changes to the individual file for several hours but the recovery needs to be fast </p><p>Correct answer is <strong>C</strong> as you can take periodic EBS snapshots can help backup the files. It can be mounted as a new volume and the file copied over to the actual volume. </p><p>Option A is wrong as storing and retrieving the files in S3 is cumbersome and depending upon file size and count might not match the RTO. </p><p>Option B is wrong as a complete cut over to the backup volume will cause the other files to lose the data as well.<br> </p><p>Option D is wrong as the snapshots are taken for EBS volumes<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120409">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 29 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249406"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are running a news website in the eu-west-1 region that updates every 15 minutes. The website has a worldwide audience it uses an Auto Scaling group behind an Elastic Load Balancer and an Amazon RDS database. Static content resides on Amazon S3, and is distributed through Amazon CloudFront. Your Auto Scaling group is set to trigger a scale up event at 60% CPU utilization; you use an Amazon RDS extra large DB instance with 10.000 Provisioned IOPS its CPU utilization is around 80%. While freeable memory is in the 2 GB range. Web analytics reports show that the average load time of your web pages is around 1.5 to 2 seconds, but your SEO consultant wants to bring down the average load time to under 0.5 seconds. How would you improve page load times for your users? Choose 3 correct answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 15 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Lower the scale up trigger of your Auto Scaling group to 30% so it scales more aggressively.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Add an Amazon ElastiCache caching layer to your application for storing sessions and frequent DB queries<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Configure Amazon CloudFront dynamic content support to enable caching of re-usable content from your site<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Switch Amazon RDS database to the high memory extra large Instance type<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Set up a second installation in another region, and use the Amazon Route 53 latency-based routing feature to select the right region. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Add an Amazon ElastiCache caching layer to your application for storing sessions and frequent DB queries<br><b>C</b>. Configure Amazon CloudFront dynamic content support to enable caching of re-usable content from your site<br><b>D</b>. Switch Amazon RDS database to the high memory extra large Instance type<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point is to improve page load times, and its a read only site with updates every 15 minutes. </p><p>Correct answer is <strong>B, C and D</strong> implements caching using ElastiCache for DB, CloudFront for dynamic content and Scale out the RDS database. CloudFront would be better with its Global Edge locations </p><p>Option A is wrong as auto scaling will increase the instances but not help reduce load on DB and nor serve requests faster. </p><p>Option E is wrong as second installation would increase cost and would not help worldwide audience as it is still latency based. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120199">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 30 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249407"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are building a large, multi-tenant SaaS (software-as-a-service) application with a component that fetches data to process from a customer-specific Amazon S3 bucket in their account. How should you ensure that your application follows security best practices and limits risk when fetching data from customer-owned Amazon S3 buckets?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Have users create an IAM user with a policy that grants read-only access to the Amazon S3 bucket required by your application, and store the corresponding access keys in an encrypted database that holds their account data.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Have users create a cross-account lAM role with a policy that grants read-only access to the Amazon S3 bucket required by your application to the AWS account ID running your production Sass application. <br><b>C</b>. <input type="radio" disabled="">&nbsp;Have users create an Amazon S3 bucket policy that grants read-only access to the Amazon S3 bucket required by your application, and securely store the corresponding access keys in the database holding their account data. <br><b>D</b>. <input type="radio" disabled="">&nbsp;Have users create an Amazon S3 bucket policy that grants read-only access to the Amazon S3 bucket required by your application and limits access to the public IP address of the SaaS application. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Have users create a cross-account lAM role with a policy that grants read-only access to the Amazon S3 bucket required by your application to the AWS account ID running your production Sass application. <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as an Cross Account access using IAM role helps provides secure access to the application hosting SaaS application to the account hosting the customer data. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html" target="_blank">Cross Account with IAM Roles</a> </p><p>Option A is wrong as creating a single IAM user and storing keys is not a best practice. </p><p>Option C is wrong as storing access keys is not a best practice </p><p>Option D is wrong as limiting the access to public IP address would increase risk as it might change. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120554">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 31 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249408"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have an existing application, which runs on your premise and currently uses a non-relational database. Your team has decided to migrate the database to DynamoDB to use some of its features like scaling and data streaming. As per the management outline, post migration, all the communication between the application and the DynamoDB must be secure and scalable, as the load will increase in the near future. What combination can be best used to design the migration? (Select TWO)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 24 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Migrate the on-premise application to the AWS EC2</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use the HTTPS endpoint of the DynamoDB to make sure all the communication is secure<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Connect your on-premise network to AWS using the VPN to access the DynamoDB via the VPC endpoints<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Run your application using auto-scaling and provision higher read/write capacity to the DynamoDB tables<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use the VPC gateway endpoint to connect with your DynamoDB, provide the endpoint to your application configuration<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Enable the encryption at rest option to make sure all the data stored in the DynamoDB is secure <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Migrate the on-premise application to the AWS EC2<br><b>E</b>. Use the VPC gateway endpoint to connect with your DynamoDB, provide the endpoint to your application configuration<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A &amp; E</strong> as to keep the application and integration secure and scalable<span class="redactor-invisible-space">, the application can be moved to EC2 (and then to Auto Scaling for scalability) and a VPC Gateway Endpoint would provide a secure and private communication channel.</span> </p><p><span class="redactor-invisible-space">Refer AWS documentation - <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html" target="_blank">VPC Endpoints</a></span> </p><p><em>A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network.</em> </p><p><em><span class="redactor-invisible-space"></span></em> </p><p><em>Endpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components that allow communication between instances in your VPC and services without imposing availability risks or bandwidth constraints on your network traffic.</em> </p><p><em>A gateway endpoint is a gateway that is a target for a specified route in your route table, used for traffic destined to a supported AWS service. The following AWS services are supported:</em> </p><ul> <li><em>Amazon S3</em></li> <li><em>DynamoDB</em></li> </ul><p>Option B is wrong as HTTPS would not provide a E2E security as compared to VPC endpoints. </p><p>Option C is wrong as VPC Endpoints work with resources accessing from with a VPC. </p><p>Option D is wrong as provisioning higher throughput would increase the cost. </p><p>Option F is wrong as encryption at rest does not make the communication between application and DynamoDB secure. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120630">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 32 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249409"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your website is serving on-demand training videos to your workforce. Videos are uploaded monthly in high resolution MP4 format. Your workforce is distributed globally often on the move and using company-provided tablets that require the HTTP Live Streaming (HLS) protocol to watch a video. Your company has no video transcoding expertise and it required you might need to pay for a consultant. How do you implement the most cost-efficient architecture without compromising high availability and quality of video delivery?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Elastic Transcoder to transcode original high-resolution MP4 videos to HLS. S3 to host videos with lifecycle Management to archive original flies to Glacier after a few days. CloudFront to serve HLS transcoded videos from S3</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;A video transcoding pipeline running on EC2 using SQS to distribute tasks and Auto Scaling to adjust the number or nodes depending on the length of the queue S3 to host videos with Lifecycle Management to archive all files to Glacier after a few days CloudFront to serve HLS transcoding videos from Glacier<br><b>C</b>. <input type="radio" disabled="">&nbsp;Elastic Transcoder to transcode original high-resolution MP4 videos to HLS EBS volumes to host videos and EBS snapshots to incrementally backup original rues after a few days. CloudFront to serve HLS transcoded videos from EC2.<br><b>D</b>. <input type="radio" disabled="">&nbsp;A video transcoding pipeline running on EC2 using SQS to distribute tasks and Auto Scaling to adjust the number of nodes depending on the length of the queue. EBS volumes to host videos and EBS snapshots to incrementally backup original files after a few days. CloudFront to serve HLS transcoded videos from EC2 <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Elastic Transcoder to transcode original high-resolution MP4 videos to HLS. S3 to host videos with lifecycle Management to archive original flies to Glacier after a few days. CloudFront to serve HLS transcoded videos from S3<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key here the cost efficient solution with company needing video transcoding expertise and needing to hire a consultant with global distribution. </p><p>Correct answer is <strong>A</strong> as <a href="https://aws.amazon.com/elastictranscoder/" target="_blank">Elastic Transcoder</a> provides and out of box option to transcode videos into any format without any expertise. S3 to host videos and <a href="https://aws.amazon.com/cloudfront/streaming/" target="_blank">CloudFront to serve HLS transcoded videos</a> for global distribution while being cost efficient </p><p>Option B &amp; D are wrong as a video transcoding pipeline with instances would increae the cost needing expertise as well as infrastructure </p><p>Option C &amp; D are wrong as EBS volumes to host data with snapshots would increase the cost. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120204">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 33 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249410"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You require the ability to analyze a large amount of data, which is stored on Amazon S3 using Amazon Elastic Map Reduce. You are using the cc2.8xlarge instance type, who’s CPUs are mostly idle during processing. Which of the below would be the most cost efficient way to reduce the runtime of the job?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create smaller files on Amazon S3.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Add additional cc2.8xlarge instances by introducing a task group.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use smaller instances that have higher aggregate I/O performance.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create fewer, larger files on Amazon S3. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use smaller instances that have higher aggregate I/O performance.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to reduce cost and CPU are mostly idle during processing which means they are oversized. </p><p>Correct answer is <strong>C</strong> as smaller instances can provide higher aggregate I/O performance and be utilized as well and help reduce cost. </p><p>Refer to <a href="https://aws.amazon.com/elasticmapreduce/faqs/" target="_blank">EMR FAQs</a> </p><pre>As a general guideline, we recommend that you limit 60% of your disk space to 
storing the data you will be processing, leaving the rest for intermediate output. 
Hence, given 3x replication on HDFS, if you were looking to process 5 TB on m1.xlarge 
instances, which have 1,690 GB of disk space, we recommend your cluster contains at 
least (5 TB * 3) / (1,690 GB * .6) = 15 m1.xlarge core nodes. You may want to increase 
this number if your job generates a high amount of intermediate data or has 
significant I/O requirements.
</pre><p>Option A &amp; D does not reduce utilization </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120252">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 34 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249411"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You've been working on a CloudFront whole site CDN for A Company client. After configuring the whole site CDN with a custom CNAME and supported HTTPS custom domain (i.e., https://example.com) you open example.com and are receiving the following error: CloudFront wasn't able to connect to the origin. What might be the most likely cause of this error and how would you fix it?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;The Origin Protocol Policy is set to Match Viewer and HTTPS isn't configured on the origin.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;The HTTPS certificate is expired or missing a third party signer. To resolve this purchase and add a new SSL certificate.<br><b>C</b>. <input type="radio" disabled="">&nbsp;The origin on the CloudFront distribution is the wrong origin.<br><b>D</b>. <input type="radio" disabled="">&nbsp;TCP HTTPS isn't configured on the CloudFront distribution but is configured on the CloudFront origin. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. The Origin Protocol Policy is set to Match Viewer and HTTPS isn't configured on the origin.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as the error usually happens when the Origin Protocol Policy is set to Match Viewer and HTTPS isn't configured on the origin.<span class="redactor-invisible-space"></span> </p><p>Refer AWS <a href="https://forums.aws.amazon.com/thread.jspa?threadID=170712" target="_blank">Forum entry</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120441">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 35 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249412"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are an AWS solutions architect and are in charge of the maintenance of a RDS on VMware database, which is deployed on-premise. You have created a read replica in ap-south-1 region to share some read traffic. The system has run smoothly for a while then the company decides to migrate all the products to AWS including the on-premise RDS instance. Other than that, the instance needs to have another replica in another region ap-southeast-1. What actions should you take to fulfill this requirement?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use Data Migration Service to migrate the on-premise database to a RDS instance in AWS. Create a read replica in ap-southeast-1 region afterwards.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;In RDS console, click “migrating the instance” to create a new RDS instance. Then create a new read replica in the ap-southeast-1 region<br><b>C</b>. <input type="radio" disabled="">&nbsp;Promote the RDS read replica in ap-south-1 to be the new RDS instance. Create another read replica in ap-southeast-1 for this new instance<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create another read replica in ap-southeast-1 region to share the read traffic for the RDS instance on VMware. Promote the RDS read replica in ap-south-1 to be the new RDS instance so that the original on-premise database is migrated in AWS with a replica in ap-southeast-1. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Promote the RDS read replica in ap-south-1 to be the new RDS instance. Create another read replica in ap-southeast-1 for this new instance<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as RDS VMware allows for one-click migration using replica promotion. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/rds/vmware/" target="_blank">RDS VMware</a> </p><p><em>Through simple one-click replication, your Amazon RDS on VMware database instances can be migrated to Amazon RDS database instances in AWS. Databases can be migrated with no impact to uptime, giving you the ability to rapidly deploy databases in all AWS regions without interrupting your customer experience.</em><br> </p><p><img src="./sap-05_files/product-page-diagram-AWS-Bourne-Launch_Use-Case-3-Migrate-On-Premises.86f83f0d29329fd8f804a2f4e271b3ce8ded3605.png"><br><br> </p><p>Option A is wrong as Data Migration Service is not needed </p><p>Option B is wrong as migrating the instance is not needed and it can be achieved using replication promotion. </p><p>Option D is wrong as the Read replica must be created after the database is migrated to AWS and from the instance which is promoted to primary. <br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120771">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 36 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249413"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> After a team design meeting, it has been decided that you need to configure a CloudWatch Logs log group to stream data to a soon-to-be-created Amazon Elasticsearch Service (Amazon ES) cluster in near real-time through a CloudWatch Logs subscription. Your team knows what it needs to do on the CloudWatch side but has never used Elasticsearch. What is the first thing you need to do on the Elasticsearch side?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Subscribe the CloudWatch Log Group to Elasticsearch.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create an ES Domain<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an IAM Role for Elasticsearch.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a metric for Elasticsearch that CloudWatch can use. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create an ES Domain<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as before you begin you need to create ES domain. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_ES_Stream.html" target="_blank">CloudWatch logs Elasticsearch Stream</a> </p><p><em>You can configure a CloudWatch Logs log group to stream data it receives to your Amazon Elasticsearch Service (Amazon ES) cluster in near real-time through a CloudWatch Logs subscription. <br></em> </p><p><em>Before you begin, create an Amazon ES domain. The Amazon ES domain can have either public access or VPC access, but you cannot then modify the type of access after the domain is created. You might want to review your Amazon ES domain settings later, and modify your cluster configuration based on the amount of data your cluster will be processing.</em><br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121103">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 37 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249414"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are implementing a URL whitelisting system for a company that wants to restrict outbound HTTP’S connections to specific domains from their EC2-hosted applications you deploy a single EC2 instance running proxy software and configure It to accept traffic from all subnets and EC2 instances in the VPC. You configure the proxy to only pass through traffic to domains that you define in its whitelist configuration You have a nightly maintenance window or 10 minutes where ail instances fetch new software updates. Each update Is about 200MB in size and there are 500 instances In the VPC that routinely fetch updates After a few days you notice that some machines are failing to successfully download some, but not all of their updates within the maintenance window. The download URLs used for these updates are correctly listed in the proxy’s whitelist configuration and you are able to access them manually using a web browser on the instances. What might be happening? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;You are running the proxy on an undersized EC2 instance type so network throughput is not sufficient for all instances to download their updates in time.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;You have not allocated enough storage to the EC2 instance running me proxy so the network buffer is filling up causing some requests to fall<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;You are running the proxy in a public subnet but have not allocated enough EIPs lo support the needed network throughput through the Internet Gateway (IGW)<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;You are running the proxy on a affluently-sized EC2 instance in a private subnet and its network throughput is being throttled by a NAT running on an undersized EC2 instance<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;The route table for the subnets containing the affected EC2 instances is not configured to direct network traffic for the software update locations to the proxy. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. You are running the proxy on an undersized EC2 instance type so network throughput is not sufficient for all instances to download their updates in time.<br><b>D</b>. You are running the proxy on a affluently-sized EC2 instance in a private subnet and its network throughput is being throttled by a NAT running on an undersized EC2 instance<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A &amp; D</strong> - as the network is the bottleneck as all the instances are trying to download the patch at the same time, the only reasons can be either the proxy does not have enough capacity to handle all the request or either the instances are hosted in the private subnet with the traffic being routed through the NAT instance which does not have enough capacity </p><p>Option B is wrong as storage does not impact the network performance </p><p>Option C is wrong as EIPs are not needed for network throughput </p><p>Option E is wrong as the configuration would cause those instances to always fail </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120187">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 38 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249415"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You need a persistent and durable storage to trace call activity of an IVR (Interactive Voice Response) system. Call duration is mostly in the 2-3 minutes timeframe. Each traced call can be either active or terminated. An external application needs to know each minute the list of currently active calls, which are usually a few calls/second. Put once per month there is a periodic peak up to 1000 calls/second for a few hours The system is open 24/7 and any downtime should be avoided. Historical data is periodically archived to files. Cost saving is a priority for this project. What database implementation would better fit this scenario, keeping costs as low as possible?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use RDS Multi-AZ with two tables, one for -Active calls” and one for -Terminated calls”. In this way the “Active calls_ table is always small and effective to access.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use DynamoDB with a “Calls” table and a Global Secondary Index on a “IsActive'” attribute that is present for active calls only In this way the Global Secondary index is sparse and more effective.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use DynamoDB with a ‘Calls” table and a Global secondary index on a ‘State” attribute that can equal to “active” or “terminated” in this way the Global Secondary index can be used for all Items in the table.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use RDS Multi-AZ with a “CALLS” table and an Indexed “STATE* field that can be equal to ‘ACTIVE” or – TERMINATED” In this way the SOL query Is optimized by the use of the Index <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Use DynamoDB with a “Calls” table and a Global Secondary Index on a “IsActive'” attribute that is present for active calls only In this way the Global Secondary index is sparse and more effective.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point is to minimize cost. </p><p>Correct answer is <strong>B</strong> as it is more cost effective than C, since the Global Secondary Index only contains active calls. </p><p>GSI index does not require the indexed attributes to be unique and are <a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GuidelinesForGSI.html#GuidelinesForGSI.SparseIndexes" target="_blank">sparse indexes</a>, so it would hold only active calls as the value does not exist for inactive calls </p><p>Options A and D are wrong as RDS would cost more as well as would not be a durable option. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120193">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 39 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249416"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> What are some of the best practices when managing permissions for OpsWorks? Choose 3 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Create IAM User for each of your users and attach policies that provide appropriate access.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use the root account for managing the resources attached to OpsWorks.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Application developers need to access only the stacks that run their applications.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Users should only have access permission to the resources they need as part of the OpsWorks stack.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Create single IAM user for all the users with all the permissions except billing <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Create IAM User for each of your users and attach policies that provide appropriate access.<br><b>C</b>. Application developers need to access only the stacks that run their applications.<br><b>D</b>. Users should only have access permission to the resources they need as part of the OpsWorks stack.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A, C &amp; D</strong> </p><p>Option A as root credentials should never be used as they have all permissions, it is a better practice is to create an IAM User with appropriate policies attached to it. </p><p>Option C as developers should not have access to stacks pertaining to any other applications than the ones they should be working on. </p><p>Option D as users should have access to only those resources that pertain to the application they are working on. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html" target="_blank">IAM Best Practices</a> </p><p>Option B is wrong because using the root account credentials is not a secure and recommended practice. </p><p>Option E is wrong as it is ideal to create different IAM users with proper permissions </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120565">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 40 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249417"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is storing data on Amazon Simple Storage Service (S3). The company’s security policy mandates that data be encrypted at rest. Which of the following methods can achieve this? Choose 3 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use Amazon S3 server-side encryption with customer-provided keys<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use Amazon S3 server-side encryption with EC2 key pair.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use Amazon S3 bucket policies to restrict access to the data at rest.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Use SSL to encrypt the data while in transit to Amazon S3. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.<br><b>B</b>. Use Amazon S3 server-side encryption with customer-provided keys<br><b>E</b>. Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A, B &amp; E</strong> </p><p>Refer to the AWS <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html" target="_blank">S3 Protecting Data using Encryption</a><span class="redactor-invisible-space"></span> </p><p>Data at rest encryption using S3 can be implemented using either Server Side or Client Side encryption. SSE can be implemented using either KMS provided keys (SSE-KMS) or Customer provided keys (SSE-C). CSE can be implemented by encrypting the data before uploading it to S3 and then decrypting the data after downloading it from S3 at client side. </p><p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html" target="_blank"></a> </p><p>Option C is wrong as server side encryption does't work with EC2 key pair<br> </p><p>Option D is wrong as bucket policies are just to restrict access to S3 </p><p>Option F is wrong as it targets the data in transit only. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120529">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 41 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249418"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company hosts a social media site supporting users in multiple countries. You have been asked to provide a highly available design for the application that leverages multiple regions for the most recently accessed content and latency sensitive portions of the web site. The most latency sensitive component of the application involves reading user preferences to support web site personalization and ad selection. In addition to running your application in multiple regions, which option will support this application’s requirements?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Serve user content from S3, CloudFront and use Route53 latency-based routing between ELBs in each region. Retrieve user preferences from a local DynamoDB table in each region and leverage SQS to capture changes to user preferences with SQS workers for propagating updates to each table</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use the S3 Copy API to copy recently accessed content to multiple regions and serve user content from S3, CloudFront with dynamic content and an ELB in each region Retrieve user preferences from an ElastiCache cluster in each region and leverage SNS notifications to propagate user preference changes to a worker node in each region.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use the S3 Copy API to copy recently accessed content to multiple regions and serve user content from S3, CloudFront and Route53 latency-based routing between ELBs in each region. Retrieve user preferences from a DynamoDB table and leverage SQS to capture changes to user preferences with SQS workers for propagating DynamoDB updates.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Serve user content from S3, CloudFront with dynamic content, and an ELB in each region Retrieve user preferences from an ElastiCache cluster in each region and leverage Simple Workflow (SWF) to manage the propagation of user preferences from a centralized DB to each ElastiCache cluster. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Serve user content from S3, CloudFront and use Route53 latency-based routing between ELBs in each region. Retrieve user preferences from a local DynamoDB table in each region and leverage SQS to capture changes to user preferences with SQS workers for propagating updates to each table<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is running application in multiple regions and propagate user preferences across region with low latency </p><p>Correct answer is <strong>A</strong> as most recently accessed content can be served through S3, CloudFront and Route 53 with latency based routing. SQS can be used to propagate changes across region and update </p><p>Option B and C are wrong as using the S3 copy api would need to query S3 for the recently accessed content which would be slower. </p><p>Option D is wrong as using a centrailzed DB would be a bottleneck. SWF is not an ideal choice, AWS data pipeline would make as it can work with resources across region. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120356">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 42 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249419"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing a connectivity solution between on-premises infrastructure and Amazon VPC. Your server’s on-premises will be communicating with your VPC instances. You will be establishing IPSec tunnels over the internet. You will be using VPN gateways and terminating the IPsec tunnels on AWS-supported customer gateways. Which of the following objectives would you achieve by implementing an IPSec tunnel as outlined above? (Choose 4 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;End-to-end protection of data in transit</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;End-to-end Identity authentication<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Data encryption across the Internet<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Protection of data in transit over the Internet<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Peer identity authentication between VPN gateway and customer gateway<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Data integrity protection across the Internet <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Data encryption across the Internet<br><b>D</b>. Protection of data in transit over the Internet<br><b>E</b>. Peer identity authentication between VPN gateway and customer gateway<br><b>F</b>. Data integrity protection across the Internet<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C, D, E &amp; F</strong> </p><p>Option C, D and F as by establishing a VPN tunnel between VPC and your on-perm gateway does not achieve that, the traffic before entering and after exiting the VPN tunnel will not be encrypted. </p><p>Option E as the two gateway will authenticate each other prior to form the VPN tunnel. </p><p>Option A &amp; B are wrong as IPSec tunnels to do not provide anything End-to-End and the service is between gateways only. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120384">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 43 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249420"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company runs a web application in us-west-2. The application runs on Amazon EC2 instances behind an ELB Network Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones. Static content is distributed from Amazon S3 and transactional data is stored in an Amazon RDS MySQL DB instance. Amazon Route 53 is used for the DNS. Configuration information, such as the S3 bucket name and database connection string, are store in the AWS Systems Manager Parameter Store. In a steady state, the Auto Scaling group has four EC2 instances. The application is deployed with an AWS CloudFormation template. A Solutions Architect must design an automated disaster recovery plan for the application. The plan must allow the application to fail over to a second Region with an RTO of 30 minutes and an RPO of 15 minutes. The Solutions Architect does not have the ability to change the application source code. The Solutions Architect has already implemented the following steps: Configured S3 cross-region replication to replicate static content in the second Region Copied all pre-existing static content from the S3 bucket in the first Region to the S3 bucket in the second Region Created a read replica of the RDS MySQL DB instance in the second Region Added the S3 bucket and database connection string to the AWS Systems Manager Parameter Store in the second Region Updated the Mappings section of the CloudFormation template with mappings of the Region to the appropriate AMIs Used the CloudFormation template to launch an application stack in the second Region Updated the minimum and desired capacity of the Auto Scaling group in the second Region to one Set up a failover routing policy in the Amazon Route 53 hosted zone Added a secondary record set to the Route 53 hosted zone that points to the Network Load Balancer in the second Region Configured a health check alarm that publishes an SNS notification if the application fails in the first Region Which combination of additional steps are required to complete the plan? (Select TWO.) <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Add a parameter to the CloudFormation template indicating the Region of the deployment.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Copy any required AMIs from the first Region to the second Region.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Write an AWS Lambda function in the second Region that increases the desired capacity of the Auto Scaling group to four. Subscribe the function to the health check alarm SNS topic.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Write an AWS Lambda function in the second Region that promotes the read replica RDS DB instance to a standalone DB instance. Subscribe the function to the health check alarm SNS topic.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Change the permissions on any required AMIs in the first Region to allow them to be accessed from the second Region. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Write an AWS Lambda function in the second Region that increases the desired capacity of the Auto Scaling group to four. Subscribe the function to the health check alarm SNS topic.<br><b>D</b>. Write an AWS Lambda function in the second Region that promotes the read replica RDS DB instance to a standalone DB instance. Subscribe the function to the health check alarm SNS topic.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>C &amp; D</strong> </p><p>Option C as the Auto Scaling desired capacity should be increased to 4 to target steady traffic, in case of an failure </p><p>Option D to promote the Read Replica to Primary instance, in case of an failure <br> </p><p>Option A as the CloudFormation template has already been used to create a stack in the second region. </p><p>Option B is wrong as the SA has already updated the CloudFormation template with AMIs mapping. </p><p>Option E is wrong as AMI are regional and need to be copied across regions. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121068">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 44 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249421"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You're working as a Consultant for a Company that has a three tier application. The application layer of this architecture sends over 20Gbps of data per seconds during peak hours to and from Amazon S3. Currently, you're running two NAT gateways in two subnets to transfer the data from your private application layer to Amazon S3. You will also need to ensure that the instances receive software patches from a third party repository. What architecture changes should be made, if any? Choose the correct answer from the options below.<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;NAT gateways support 10Gbps and two are running: Add a third to a third subnet to allow for any increase in demand.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Keep the NAT gateway and create a VPC S3 endpoint which allows for higher bandwidth throughput as well as tighter security<br><b>C</b>. <input type="radio" disabled="">&nbsp;NAT gateways support 10Gbps and two are running: No changes are required to improve this architecture.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Remove the NAT gateway and create a VPC S3 endpoint which allows for higher bandwidth throughput as well as tighter security. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Keep the NAT gateway and create a VPC S3 endpoint which allows for higher bandwidth throughput as well as tighter security<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html" target="_blank">VPC S3 endpoint</a> can be used for direct S3 interaction </p><pre>A VPC endpoint enables you to create a private connection between 
your VPC and another AWS service without requiring access over 
the Internet, through a NAT device, a VPN connection, or AWS 
Direct Connect. Endpoints are virtual devices. They are horizontally 
scaled, redundant, and highly available VPC components that allow 
communication between instances in your VPC and AWS services without 
imposing availability risks or bandwidth constraints on your network traffic.
</pre><p>Option A &amp; C are wrong as NAT gateway can be relieved of the S3 traffic using VPC S3 endpoint. </p><p><span class="redactor-invisible-space">Option D is wrong as <span class="redactor-invisible-space">NAT gateway would still be required to download software patches from the third party repository.<br></span></span> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120404">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 45 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249422"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company has many employees who need to run internal applications that access the company's AWS resources. These employees already have user credentials in the company's current identity authentication system, which does not support SAML 2.0. The company does not want to create a separate IAM user for each company employee. How should the SSO setup be designed? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Create an IAM user to share based off of employee roles in the company.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Create a custom identity broker application which authenticates the employees using the existing system, uses the GetFederationToken API call and passes a permission policy to gain temporary access Credentials from STS.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Create a custom identity broker application which authenticates employees using the existing system and uses the AssumeRole API call to gain temporary, role-based access to AWS.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Configure an AD server which synchronizes from the company's current identity Provide and configures SAML-based single sign-on which will then use the AssumeRoleWithSAML API calls to generate credentials for the employees. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create a custom identity broker application which authenticates the employees using the existing system, uses the GetFederationToken API call and passes a permission policy to gain temporary access Credentials from STS.<br><b>C</b>. Create a custom identity broker application which authenticates employees using the existing system and uses the AssumeRole API call to gain temporary, role-based access to AWS.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>B &amp; C</strong>. </p><p>Refer to AWS documentation for <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html" target="_blank">Request Temporary Security Credentials</a> which has two options GetFederationToken and AssumeRole. </p><p><em>Assume Role - Returns a set of temporary security Credentials (consisting of an </em><em>access key ID, a secret access key, and a security token) that you can use to </em><em>access AWS resources that you might not normally have access to. Typically, </em><em>you use AssumeRole for Cross-account access or federation </em><em>GetFederationToken - Returns a set of temporary security Credentials (Consisting </em><em>of an access key ID, a secret access key, and a security token) for a federated </em><em>user. A typical use is in a proxy application that gets temporary security </em><em>Credentials on behalf of distributed applications inside a Corporate network</em></p><p>Option A is wrong as creating IAM user is not a best practice and never recommended </p><p>Option D is wrong as AssumeRoleWithSAML works only with SAML complaint identity providers. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120394">AWS SAP-C01 Question feedback</a> </p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 46 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249423"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are building a system to distribute confidential training videos to employees. Using CloudFront, what method could be used to serve content that is stored in S3, but not publicly accessible from S3 directly?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an Origin Access Identity (OAI) for CloudFront and grant access to the objects in your S3 bucket to that OAI.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Add the CloudFront account security group “amazon-cu/amazon-cf-sg” to the appropriate S3 bucket policy.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an Identity and Access Management (IAM) User for CloudFront and grant access to the objects in your S3 bucket to that IAM User.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a S3 bucket policy that lists the CloudFront distribution ID as the Principal and the target bucket as the Amazon Resource Name (ARN). <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Create an Origin Access Identity (OAI) for CloudFront and grant access to the objects in your S3 bucket to that OAI.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as CloudFront OAI can be used to keep the S3 contents private and accessible only through CloudFront. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html" target="_blank">Private Content Restricting Access to S3</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120429">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 47 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249424"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A new client may use your company to move all their existing Data Center applications and infrastructure to AWS. This is going to be a huge contract for your company, and you have been handed the entire contract and need to provide an initial scope to this possible new client. One of the things you notice concerning the existing infrastructure is that it has a small amount of legacy applications that you are almost certain will not work on AWS. Which of the following would be the best strategy to employ regarding the migration of these Legacy applications?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create two VPCs. One containing all the legacy applications and the other containing all the other applications. Make a connection between them with VPC peering.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Move the legacy applications onto AWS first, before you build any infrastructure. There is sure to be an AWS Machine Image (AMI) that can run this legacy application.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a hybrid cloud by configuring a VPN tunnel to the on-premises location of the Data Center.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Convince the client to look for another solution by de-commissioning these applications and seeking out new ones that will run on AWS. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create a hybrid cloud by configuring a VPN tunnel to the on-premises location of the Data Center.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as the legacy application cannot be migrated, the best architecture would be to have a VPN connection between the VPC and the on-premises services. </p><p>Option A &amp; B are wrong as the legacy application cannot be moved to AWS </p><p>Option D is wrong as de-commissioning application would require time, effort and cost to the client.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120399">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 48 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249425"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A Company is running Oracle DB workloads on AWS. Currently, they are running the Oracle RAC configuration on the AWS public cloud. You've been tasked with configuring backups on the RAC cluster to enable durability. What is the best method for configuring backups? Choose the correct answer<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create manual snapshots of the RDS backup and write a script that runs the manual snapshot.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Enable Multi-AZ failover on the RDS RAC cluster to reduce the RPO and RTO in the event of disaster or failure.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a script that runs snapshots against the EBS volumes to create backups and durability.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Enable automated backups on the RDS RAC cluster; enable auto snapshot copy to a backup region to reduce RPO and RTO. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create a script that runs snapshots against the EBS volumes to create backups and durability.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as RDS does not support Oracle RAC, the RAC configurations need to be on an EC2 instance and you can create scripts to create snapshots against the EBS volumes for backups and durability. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Oracle.html" target="_blank">RDS Oracle</a> </p><p><em>The following features are not supported for Oracle 12c on Amazon RDS:</em> </p><p><em></em> </p><ul> <li><em>Automated Storage Management</em></li> <li><em>Data Guard / Active Data Guard</em></li> <li><em>Database Vault</em></li> <li><em>Java Support</em></li> <li><em>Locator</em></li> <li><em>Multitenant Database</em></li> <li><em><strong>R</strong><strong>eal Application Clusters (RAC)</strong></em></li> <li><em>Spatial</em></li> <li><em>Unified Auditing</em></li> </ul> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120539">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 49 of 51 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249426"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> To meet regulatory requirements, a pharmaceuticals company needs to archive data after a drug trial test is concluded. Each drug trial test may generate up to several thousands of files, with compressed file sizes ranging from 1 byte to 100MB. Once archived, data rarely needs to be restored, and on the rare occasion when restoration is needed, the company has 24 hours to restore specific files that match certain metadata. Searches must be possible by numeric file ID, drug name, participant names, date ranges, and other metadata. Which is the most cost-effective architectural approach that can meet the requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Store individual files in Amazon Glacier, using the file ID as the archive name. When restoring data, query the Amazon Glacier vault for files matching the search criteria.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Store individual files in Amazon S3, and store search metadata in an Amazon Relational Database Service (RDS) multi - AZ database. Create a lifecycle rule to move the data to Amazon Glacier after a certain number of days. When restoring data, query the Amazon RDS database for files matching the search criteria, and move the files matching the search criteria back to S3 Standard class.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Store individual files in Amazon Glacier, and store the search metadata in an Amazon RDS Multi-AZ database. When restoring data, query the Amazon RDS database for files matching the search criteria, and retrieve the archive name that matches the file ID returned from the database query.<br><b>D</b>. <input type="radio" disabled="">&nbsp;First, compress and then concatenate all files for a completed drug trial test into a single Amazon Glacier archive. Store the associated byte ranges for the compressed files along with other search metadata in an Amazon RDS database with regular snapshotting. When restoring data, query the database for files that match the search criteria, and create restored files from the retrieved byte ranges.<br><b>E</b>. <input type="radio" disabled="">&nbsp;Store individual compressed files and search metadata in Amazon Simple Storage Service (S3). Create a lifecycle rule to move the data to Amazon Glacier, after a certain number of days. When restoring data, query the Amazon S3 bucket for files matching the search criteria, and retrieve the file to S3 reduced redundancy in order to move it back to S3 Standard class. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. First, compress and then concatenate all files for a completed drug trial test into a single Amazon Glacier archive. Store the associated byte ranges for the compressed files along with other search metadata in an Amazon RDS database with regular snapshotting. When restoring data, query the database for files that match the search criteria, and create restored files from the retrieved byte ranges.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point is cost effective solution with requiring archival solution with 24 hours RTO and Allowing searches on attributes. </p><p>Correct answer is <strong>D</strong> as ideal solution would be to compress files and store in Glacier. Store metadata in RDS with byte range to effective retrieval with regular snapshots </p><p><a href="https://aws.amazon.com/blogs/aws/new-range-retrieval-for-amazon-glacier/" target="_blank">Glacier Range Retrievals</a> can be used to fetch only data you need from a larger file or to spread the retrieval of a large archive over a longer period of time </p><p>Option B &amp; C are wrong as Glacier charges for storage, and puts so storing individual files </p><p>Option B &amp; E are wrong as need only archiving solution and S3 would be expensive. </p><p>Option C is wrong as Multi-AZ RDS increases cost. </p><p>Option E is wrong as the data once moved from S3 to Glacier the metadata is lost, as Glacier does not have metadata and must be maintained externally. Also S3 not efficient for search operations on metadata. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120373">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 50 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249427"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are tasked with implementing a cost effective and self-healing architecture for a CPU-intensive application. You need to be able to add or subtract an instance based on CPU usage. You also want to be able to spin up new instances as quickly as possible. How are going to go about this? Choose 3. Choose the 3 correct answers:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Create a launch configuration based off your custom AMI and create an Auto Scaling group.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Pre-bake an AMI, install software on an EC2 instance, create an AMI out of it, and use that AMI to launch into your launch config, which will save time when spinning up instances<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Create an Auto Scaling group policy with a CloudWatch alarm to scale in and scale out, keeping the application cost-effective by eliminating unnecessary resources.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Create an Auto Scaling group policy with an Elastic Load Balancer alarm to scale in and scale out, keeping the application cost-effective by eliminating unnecessary resources.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Create an Auto Scaling group based off your custom AMI and create a launch configuration. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Create a launch configuration based off your custom AMI and create an Auto Scaling group.<br><b>B</b>. Pre-bake an AMI, install software on an EC2 instance, create an AMI out of it, and use that AMI to launch into your launch config, which will save time when spinning up instances<br><b>C</b>. Create an Auto Scaling group policy with a CloudWatch alarm to scale in and scale out, keeping the application cost-effective by eliminating unnecessary resources.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A, B &amp; C</strong> as the requirement is to launch the new instances quickly, you can use pre-baked AMIs which will help launch an instance quickly with not much bootstrapping needed. An Auto Scaling launch configuration can be created with this Custom AMI and associated with Auto Scaling Group with policies defined to scale in and out as per the demand. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/policy_creating.html" target="_blank">Auto Scaling Scaling on Metrics</a> </p><p><em>You can create a scaling policy that uses CloudWatch alarms to determine when your Auto Scaling group should scale out or scale in. Each CloudWatch alarm watches a single metric and sends messages to Auto Scaling when the metric breaches a threshold that you specify in your policy. You can use alarms to monitor any of the metrics that the services in AWS that you're using send to CloudWatch, or you can create and monitor your own custom metrics.</em> </p><p>Option D is wrong as Auto Scaling policy needs to be created with CloudWatch alarm to change scaling</p><p>Option E is wrong as the launch configuration needs to be created with custom AMI and attached to Auto Scaling group</p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120515">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 51 of 51 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249428"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are responsible for a web application that consists of an Elastic Load Balancing (ELB) load balancer in front of an Auto Scaling group of Amazon Elastic Compute Cloud (EC2) instances. For a recent deployment of a new version of the application, a new Amazon Machine Image (AMI) was created, and the Auto Scaling group was updated with a new launch configuration that refers to this new AMI. During the deployment, you received complaints from users that the website was responding with errors. All instances passed the ELB health checks. What should you do in order to avoid errors for future deployments? (Choose 2 answer)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Add an Elastic Load Balancing health check to the Auto Scaling group. Set a short period for the health checks to operate as soon as possible in order to prevent premature registration of the instance to the load balancer.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Enable EC2 instance CloudWatch alerts to change the launch configuration’s AMI to the previous one. Gradually terminate instances that are using the new AMI.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Set the Elastic Load Balancing health check configuration to target a part of the application that fully tests application health and returns an error if the tests fail.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Create a new launch configuration that refers to the new AMI, and associate it with the group. Double the size of the group, wait for the new instances to become healthy, and reduce back to the original size. If new instances do not become healthy, associate the previous launch configuration.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Increase the Elastic Load Balancing Unhealthy Threshold to a higher value to prevent an unhealthy instance from going into service behind the load balancer. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Add an Elastic Load Balancing health check to the Auto Scaling group. Set a short period for the health checks to operate as soon as possible in order to prevent premature registration of the instance to the load balancer.<br><b>C</b>. Set the Elastic Load Balancing health check configuration to target a part of the application that fully tests application health and returns an error if the tests fail.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A &amp; C </strong>as ELB health checks are passing the issue is will the new AMI Only. </p><p>Answer is a combination of two steps :- </p><p>First - Option C as although the ELB health checks are passing, it might be it is checking only a default page and the rest of the pages are failing. So it would be better to include more tests and then return a pass for the instance. </p><p>Second - Option A as the Auto Scaling might not be using the ELB health checks and hence the instances are not terminated by Auto Scaling. </p><p>Option B is wrong as you cannot configure CloudWatch alerts to update launch config AMI as well as the health checks are passing, if the instances go into service the users will still receive an error.<br> </p><p>Option D is wrong as it is kind of rolling deployment, where new services would still be serving users and prone to errors. </p><p>Option E is wrong as the ELB health checks are passing, even if the unhealthy threshold is increased it does not prevent the instance from serving user requests. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120544">AWS SAP-C01 Question feedback</a></div></div></div><div class="col-sm-12 well"><h4 class="sm" style="color:#333;">8/51 Questions right</h4></div></div><style type="text/css">
span.label.label-danger,span.label.label-success {
    padding: .2em .6em .3em;
}
.saved{color:red; }
.question_info{
  margin-bottom: 40px;
  border: solid 1px #ccc;
  border-radius: 5px;
  overflow: hidden;
}
.question_no {
    background: #f4f4f4;
    padding: 0 15px;
    line-height: 40px;
    border-bottom: solid 1px #ccc;
}

.question_detail {
    padding: 10px;
}
.hide{
  display: none;
}
input[type="radio"]{
  -webkit-appearance: radio;
}
input[type="checkbox"]{
  -webkit-appearance: checkbox;
}
span.bgcolor {
    background: yellow;
    padding: 5px;
    margin-left: -5px;
}
</style><link href="./sap-05_files/mcoursestyle.css" rel="stylesheet"></div> <script type="text/javascript" src="./sap-05_files/bc-course.min_031117.js.下载"></script> <div class="overlayForm" style=""></div></div></div></div></div></div><div class="overlayForm"></div></div><iframe style="position:absolute;left:-999px;top:-999px;visibility:hidden" src="./sap-05_files/saved_resource.html"></iframe><iframe style="display: none; visibility: hidden;" src="./sap-05_files/saved_resource(1).html"></iframe><iframe style="display: none; visibility: hidden;" src="./sap-05_files/saved_resource(2).html"></iframe></body></html>