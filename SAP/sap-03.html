<!DOCTYPE html>
<!-- saved from url=(0112)https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217 -->
<html xmlns:fb="http://ogp.me/ns/fb#" lang="en-gb" dir="ltr" class="secondary-14px wf-proximanova-n7-active wf-proximanova-i7-active wf-proximanova-n4-active wf-raleway-n1-active wf-raleway-n7-active wf-raleway-n4-active wf-raleway-n5-active wf-raleway-n3-active wf-raleway-n8-active wf-raleway-n9-active wf-raleway-n2-active wf-raleway-n6-active wf-proximanova-i4-active wf-active"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><meta name="format-detection" content="telephone=no"><script type="text/javascript" src="./sap-03_files/display.js.下载"></script><script type="text/javascript" src="./sap-03_files/pro"></script><script type="text/javascript" src="./sap-03_files/l.js.下载"></script><script type="text/javascript" src="./sap-03_files/l.js(1).下载"></script><script type="text/javascript" src="./sap-03_files/l.js(2).下载"></script><script type="text/javascript" src="./sap-03_files/l.js(3).下载"></script><script type="text/javascript" async="" src="./sap-03_files/analytics.js.下载"></script><script type="text/javascript" async="" src="./sap-03_files/atatus.js.下载"></script><script src="./sap-03_files/fMy5LNtdDqis6adCpEbCXQHA47I.js.下载"></script><script src="./sap-03_files/js"></script><link rel="canonical" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217"><link rel="stylesheet" type="text/css" href="./sap-03_files/bc-course.min_092917.css"><link rel="stylesheet" type="text/css" href="./sap-03_files/bc-style-092917.css"><!--[if lt IE 9]> <script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script> <script src="//css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script> <![endif]--><link rel="shortcut icon" href="https://www.braincert.com/images/favicon.ico"> <script type="text/javascript" src="./sap-03_files/jquery-1.11.0.min.js.下载"></script> <script type="text/javascript">jQuery.noConflict();</script> <script type="application/javascript" src="./sap-03_files/fVBYAHUg.js.下载"></script> <script type="text/javascript">jwplayer.key="Kfk7MAHVl4Y33jPduQlHwUdmLu+1l6cvPHVklw==";</script> <script src="./sap-03_files/jdk4nqa.js.下载"></script> <style type="text/css">.tk-proxima-nova{font-family:"proxima-nova",sans-serif;}.tk-raleway{font-family:"raleway",sans-serif;}</style><style type="text/css">@font-face{font-family:tk-proxima-nova-n7;src:url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:tk-proxima-nova-i7;src:url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-weight:700;font-style:italic;}@font-face{font-family:tk-proxima-nova-n4;src:url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:tk-proxima-nova-i4;src:url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-weight:400;font-style:italic;}@font-face{font-family:tk-raleway-n1;src:url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff2"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("opentype");font-weight:100;font-style:normal;}@font-face{font-family:tk-raleway-n7;src:url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:tk-raleway-n4;src:url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:tk-raleway-n5;src:url(https://use.typekit.net/af/145edc/000000000000000000013289/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}@font-face{font-family:tk-raleway-n3;src:url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff2"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("opentype");font-weight:300;font-style:normal;}@font-face{font-family:tk-raleway-n8;src:url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff2"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("opentype");font-weight:800;font-style:normal;}@font-face{font-family:tk-raleway-n9;src:url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff2"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("opentype");font-weight:900;font-style:normal;}@font-face{font-family:tk-raleway-n2;src:url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff2"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("opentype");font-weight:200;font-style:normal;}@font-face{font-family:tk-raleway-n6;src:url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-weight:600;font-style:normal;}</style><script>try{Typekit.load({ async: true });}catch(e){}</script> <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="keywords" content="virtual classroom, online test, online course, MOOC,  SCORM, whiteboard, adaptive testing, e-learning, online education, learn online, teach online, live class, lms, monetize, sell course, online meetings, collaboration, webinar, how to, social, teach, learn"><meta name="description" content="Deliver live engaging classes using Virtual Classroom. Create and sell courses and tests online."><title>Review Answers | BrainCert</title><link href="https://www.braincert.com/templates/yoo_nano/favicon.ico" rel="shortcut icon" type="image/vnd.microsoft.icon"> <script type="text/javascript">
function keepAlive() {	var myAjax = new Request({method: "get", url: "index.php"}).send();} window.addEvent("domready", function(){ keepAlive.periodical(3540000); });
  </script> <script type="text/javascript">
				/*<![CDATA[*/
					var jax_live_site = 'https://www.braincert.com/index.php';
					var jax_token_var='925395911814f17127e11ea28577607f';
				/*]]>*/
				</script><script type="text/javascript" src="./sap-03_files/ajax_1.5.pack.js.下载"></script> <link rel="apple-touch-icon-precomposed" href="https://d9q55ve2f7k8m.cloudfront.net/images/apple_touch_icon.png"> <script>
        !function(window, document) {
            window._atatusConfig = {
                apikey: '8c2f3d535648489b9826fd95a6484c2b'
            };
            function _asyncAtatus(callback) {
                var script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.src = "https://dmc1acwvwny3.cloudfront.net/atatus.js";
                var node = document.getElementsByTagName("script")[0];
                script.addEventListener('load', function (e) {
                    callback(null, e);
                }, false);
                node.parentNode.insertBefore(script, node);
            }
            _asyncAtatus(function() {
                // Any atatus related calls.
                if (window.atatus) {
                    window.atatus.setUser('138600', 'liugongjianxin@163.com', 'gongjian liu');
                    console.log(window.atatus);
                }
            });
        }(window, document);
</script> <style type="text/css">@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-weight:700;font-style:italic;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-weight:400;font-style:italic;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff2"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("opentype");font-weight:100;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/145edc/000000000000000000013289/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff2"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("opentype");font-weight:300;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff2"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("opentype");font-weight:800;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff2"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("opentype");font-weight:900;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff2"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("opentype");font-weight:200;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-weight:600;font-style:normal;}</style><script type="text/javascript" src="./sap-03_files/ga.js.下载"></script><script src="./sap-03_files/l.js(4).下载"></script><script src="./sap-03_files/l.js(5).下载"></script><script src="./sap-03_files/l.js(6).下载"></script><script async="" type="text/javascript" src="./sap-03_files/pops"></script><script async="" type="text/javascript" src="./sap-03_files/pops(1)"></script></head><body id="page-top"><div id="page-wrap"><div id="preloader"> </div> <header id="header" class="header chapter-header"><div class="container"><div class="logo"><a href="https://www.braincert.com/"><img src="./sap-03_files/bc-logo-sm.png" alt="BrainCert" style="max-height:60px;"></a> </div><nav class="navigation"><div class="navbar-header"> <a class="navbar-brand" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217#"><span class="navbar-header-title"> AWS Certified Solutions Architect Professional SAP-C01 Practice </span></a> </div><ul class="menu"> <li><a href="https://www.braincert.com/">Home</a></li> </ul><div class="search-box"> <a href="https://www.braincert.com/test/11996-AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice-Exam-3" class="smoothScroll"><i class="fa fa-chevron-left"></i> Back</a> </div></nav> </div> </header><div class="main-container"> <script type="text/javascript">
  jQuery(document).ready(function (){
     
    jQuery( "html" ).addClass( "secondary-14px" );
    jQuery(document)[0].oncontextmenu = function() {return false;} 
    // code for preventing copy from keyboard
    var ambit = jQuery(document);
    // Disable Cut + Copy + Paste (input)
    ambit.on('copy paste cut', function (e) {
    e.preventDefault(); //disable cut,copy,paste
      return false;
    });
      });
</script> <div class="container"><div id="content-main" class="row-fluid"><div class="col-sm-12"><h2 style="margin-bottom:10px;margin-top:10px; float:left">Test Report</h2><div style="margin-top:10px;float:right"><a onclick="window.history.back();" class="btn btn-warning"><span><strong>Back</strong></span></a></div><div style="float:right;margin-top:10px;margin-right: 10px;"><a href="https://www.braincert.com/test/reviewtest/exportdata/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217" class="btn btn-primary"><span><strong><i class="fa fa-share-square-o"></i>&nbsp;Export to .CSV</strong></span></a></div><div style="border-bottom-width: 1px;border-bottom-style: dashed;border-bottom-color: #e0e0e0;margin-bottom: 10px; clear:both"></div><div style="clear:both;"></div><div class="col-md-6 pull-left row"><h3 style="margin-top: 0px;"><strong>Review questions</strong></h3></div><div class="col-md-6 pull-right row" style="font-size: 16px;text-align: right;"><strong>Student : </strong>gongjian liu
<br> <i class="fa fa-calendar"></i>&nbsp;Jun 17, 2019&nbsp;&nbsp;<i class="fa fa-clock-o"></i>&nbsp;12:17AM EDT<br> <br> </div><div id="test_results" style="padding-top: 80px;"><div id="quiz_specific"> <span id="select"></span> <div class="quiz_attempt_breakdown"><div class="percent_correct_bar col-sm-2"><div class="progress" style="margin-bottom: 2px;"><div class="progress-bar" role="progressbar" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100" style="width:25%"> </div> </div> <span id="percent"><strong>25% </strong>correct</span> </div><div><div class="questions_correct col-sm-2"><span class="inline_pipe">|</span>&nbsp;&nbsp; <img src="./sap-03_files/tick.webp" alt="you got this question right">&nbsp;<strong>14 correct</strong></div><div class="questions_incorrect col-sm-2"><span class="inline_pipe"> | </span>&nbsp;&nbsp; <img src="./sap-03_files/cross.webp" alt="you got this question wrong">&nbsp;<strong>41 incorrect</strong></div><div class="questions_incorrect col-sm-3" style="margin:0;"><span class="inline_pipe"> | </span>&nbsp;&nbsp;<img src="./sap-03_files/icon_un_answered.webp" alt="you got this question unanswer">&nbsp;<strong>0 Unanswered</strong></div><div class="total_questions col-sm-3"><span class="inline_pipe"> | </span>&nbsp;&nbsp;<strong>55 questions attempted out of 55</strong></div></div></div><br class="clear"><hr style="clear:both"><br> <br><div style="margin-bottom: 10px;"> <b style="font-size: 14.5px;">Filter by</b> : <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217" class="label-default label">All</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217?sort=1">correct</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217?sort=0">incorrect</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217?sort=-1">Unanswered</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145217?sort=2">Question feedback</a> </div><br><div class="" style="font-size: 18px;line-height: 25px;"><div class="question_info"><div class="question_no"><b>Question : 1 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249153"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An audit of your company's operations has revealed that too much time and money is being spent on deploying software for end users. The decision has been made to allow users to deploy approved products themselves. What steps can you take to best configure this in AWS?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 18 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a product catalogue on an EC2 instance; use AWS Config to flag non-compliant products and remove them as necessary.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a product catalogue on an EC2 instance; use 3rd party tools to allow end users to deploy approved products themselves.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use AWS Config. Give end users appropriate IAM access to Config to allow them to deploy approved products themselves.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use AWS Service Catalog. Give end users appropriate IAM access to Service Catalog to allow them to deploy approved products themselves. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Use AWS Service Catalog. Give end users appropriate IAM access to Service Catalog to allow them to deploy approved products themselves.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as AWS Service Catalog allows you to control what users can deploy, while providing the users the ability to deploy themselves reducing the time and money is being spent on deploying software for end users </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/servicecatalog/" target="_blank">AWS Service Catalog</a> </p><p><em>AWS Service Catalog allows organizations to create and manage catalogs of IT services that are approved for use on AWS. These IT services can include everything from virtual machine images, servers, software, and databases to complete multi-tier application architectures. AWS Service Catalog allows you to centrally manage commonly deployed IT services, and helps you achieve consistent governance and meet your compliance requirements, while enabling users to quickly deploy only the approved IT services they need.</em><br> </p><p><em>AWS Service Catalog provides a single location where organizations can centrally manage catalogs of IT services. With AWS Service Catalog you can control which IT services and versions are available, the configuration of the available services, and permission access by individual, group, department, or cost center.<br></em> </p><p><em>With AWS Service Catalog, you define your own catalog of AWS services and AWS Marketplace software, and make them available for your organization. Then, end users can quickly discover and deploy IT services using a self-service portal.<br></em> </p><p>Options A &amp; B are wrong as product catalogue cannot be created on an EC2 instance. </p><p>Options A &amp; C are wrong AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. It would not enable create Product Catalog. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%203%20-%20%23121202">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 2 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249154"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company is in the process of developing a next generation pet collar that collects biometric information to assist families with promoting healthy lifestyles for their pets. Each collar will push 30kb of biometric data In JSON format every 2 seconds to a collection platform that will process and analyze the data providing health trending information back to the pet owners and veterinarians via a web portal Management has tasked you to architect the collection platform ensuring the following requirements are met. Provide the ability for real-time analytics of the inbound biometric data to ensure processing of the biometric data is highly durable, Elastic and parallel. The results of the analytic processing should be persisted for data mining. Which architecture outlined below will meet the initial requirements for the collection platform? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Utilize S3 to collect the inbound sensor data analyze the data from S3 with a daily scheduled Data Pipeline and save the results to a Redshift Cluster.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Utilize Amazon Kinesis to collect the inbound sensor data, analyze the data with Kinesis clients and save the results to a Redshift cluster using EMR.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Utilize SQS to collect the inbound sensor data analyze the data from SQS with Amazon Kinesis and save the results to a Microsoft SQL Server RDS instance.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Utilize EMR to collect the inbound sensor data, analyze the data from EMR with Amazon Kinesis and save the results to DynamoDB. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Utilize Amazon Kinesis to collect the inbound sensor data, analyze the data with Kinesis clients and save the results to a Redshift cluster using EMR.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here to architect durable collection platform with real time analytics, data mining storage. </p><p>Correct answer is <strong>B</strong> to use Kinesis to capture the data in a elastic, durable and parallel manner. Analyze data with Kinesis clients and store data to Redshift for data mining using EMR. </p><p>Option A is wrong as S3 would not be ideal to capture data with that frequency and daily job will not provide real time analytics </p><p>Option C is wrong as SQS is not an ideal solution to capture this data and Kinesis clients are required to analyze the data. SQL server might not be a scalable option </p><p>Option D is wrong as EMR alone is not ideal to capture data and would need specific frameworks like Kafka to capture data for processing. Also real time analytics needs to done using Spark Streaming and not EMR alone. DynamoDB is not for data mining. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120376">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 3 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249155"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You manage a three-tier web application consisting of an autoscaled web proxy tier, an autoscaled application tier, and an Amazon RDS database tier. You use a load balancer to distribute requests from end users to the web proxy tier and another, internal load balancer to distribute requests between the web tier and the application tier. After deploying a small database schema update, you notice that all of your web and application instances have been terminated. What may have caused this?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Your load balancers use an HTTP health check, and the page relies on retrieving data from your database. </span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Your load balancer use TCP health checks to provide application-level health checks. <br><b>C</b>. <input type="radio" disabled="">&nbsp;The cooldown period of the Auto Scaling group is too short, so the instances don't have enough time to recover from an issue. <br><b>D</b>. <input type="radio" disabled="">&nbsp;Your Auto Scaling group health check type is set to "EC2" to check that the instances themselves are healthy. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Your load balancers use an HTTP health check, and the page relies on retrieving data from your database. <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as the autoscaling would have been configured for both the EC2 and ELB health checks. Load balancers would have be configured to check on an http status health check, which refers to the database schema. Because of the change in schema the health check might have failed causing autoscaling to makr the instances as unhealthy and terminate them. </p><p>Refer <a href="https://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-termination/" target="_blank">Auto Scaling Termination article</a> &amp; <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-elb-healthcheck.html" target="_blank">Autoscale ELB Health Check</a> </p><p><em>Load Balancer (ELB) Health Check Failure - If you have created a load balancer health check, your instances must generate an HTTP 200 response within the timeout period specified for the health check. If the timeout period elaspes without generating an HTTP 200 response, the load balancer is designated as unhealthy, and Auto Scaling terminates the instance</em><em></em><br> </p><p>Answer B is wrong as its an web application you would need HTTP health checks. </p><p>Answer C is wrong as there has been no scale up activity. </p><p>Answer D is wrong as the question does not mention anything of the actual instances being unhealthy. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120552">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 4 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249156"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You need the absolute highest possible network performance for a cluster computing application. You already selected homogeneous instance types supporting 10 gigabit enhanced networking, made sure that your workload was network bound, and put the instances in a placement group. What is the last optimization you can make?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use 9001 MTU instead of 1500 for Jumbo Frames, to raise packet body to packet overhead ratios.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Segregate the instances into different peered VPCs while keeping them all in a placement group, so each one has its own Internet Gateway.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Bake an AMI for the instances and relaunch, so the instances are fresh in the placement group and do not have noisy neighbors<br><b>D</b>. <input type="radio" disabled="">&nbsp;Turn off SYN/ACK on your TCP stack or begin using UDP for higher throughput. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Use 9001 MTU instead of 1500 for Jumbo Frames, to raise packet body to packet overhead ratios.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as <em>Jumbo frames allow more than 1500 bytes of data by increasing the payload size per packet, and thus increasing the percentage of the packet that is not packet overhead. Fewer packets are needed to send the same amount of usable data.</em><em></em> </p><p><em>For instances that are collocated inside a placement group, jumbo frames help to achieve the maximum network throughput possible, and they are recommended in this case. For more information, see <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">Placement Groups</a>.</em><em></em> </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/network_mtu.html#jumbo_frame_instances" target="_blank">Jumbo Frames</a> </p><p>Option B is wrong as for VPC peering the maximum MTU is still 1500 </p><p><em>However, outside of a given AWS region (EC2-Classic), a single VPC, or a VPC peering connection, you will experience a maximum path of 1500 MTU. VPN connections and traffic sent over an Internet gateway are limited to 1500 MTU</em><br> </p><p>Option C is wrong as baking an AMI would only result is faster boot time for the application, it does not improve network performance. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120542">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 5 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249157"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You deployed your company website using Elastic Beanstalk and you enabled log file rotation to S3. An Elastic Map Reduce job is periodically analyzing the logs on S3 to build a usage dashboard that you share with your CIO. You recently improved overall performance of the website using Cloud Front for dynamic content delivery and your website as the origin. After this architectural change, the usage dashboard shows that the traffic on your website dropped by an order of magnitude. How do you fix your usage dashboard'?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Enable CloudFront to deliver access logs to S3 and use them as input of the Elastic Map Reduce job</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Turn on Cloud Trail and use trail log tiles on S3 as input of the Elastic Map Reduce job <br><b>C</b>. <input type="radio" disabled="">&nbsp;Change your log collection process to use Cloud Watch ELB metrics as input of the Elastic Map Reduce job <br><b>D</b>. <input type="radio" disabled="">&nbsp;Use Elastic Beanstalk "Rebuild Environment" option to update log delivery to the Elastic Map Reduce job. <br><b>E</b>. <input type="radio" disabled="">&nbsp;Use Elastic Beanstalk 'Restart App server(s)" option to update log delivery to the Elastic Map Reduce job. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Enable CloudFront to deliver access logs to S3 and use them as input of the Elastic Map Reduce job<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is with CloudFront caching the request there are fewer requests served by the ELB and hence the drop. </p><p>Correct answer is <strong>A</strong> as the traffic is now served by CloudFront you can deliver the CloudFront access logs which would have all the access information and have EMR analyze the same </p><p>Refer AWS documentation for <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html" target="_blank">CloudFront Access logs</a> </p><p>Other options are wrong as they would not receive the request they cannot provide the info. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120222">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 6 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249158"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your job at a large scientific institution is moving along nicely. It is at the forefront of the latest research on nano-technology, of which you have become very passionate. You have been put in charge of scaling up some existing infrastructure which currently has 9 EC2 instances running in a Cluster Placement Group. All these 9 instances were initially launched at the same time and seem to be performing as expected. You decide that you need to add 2 new instances to the group; however, when you attempt to do this you receive a 'capacity error'. Which of the following actions will most likely fix this problem? Choose the correct answer:<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Stop and restart the instances in the Cluster Placement Group and then try the launch again.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Make a new Cluster Placement Group and launch the new instances in the new group. Make sure the Placement Groups are in the same subnet.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Request a capacity increase from AWS as you are initially limited to 10 instances per Cluster Placement Group.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Make sure all the instances are the same size and then try the launch again. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Stop and restart the instances in the Cluster Placement Group and then try the launch again.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as the capacity error would be cause of AWS inability to launch the instance and the option would be to stopping and starting the servers so that they are launched on a hardware which has the capacity for all the requested instances. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html" target="_blank">EC2 Placement Group</a> </p><p><em></em></p><p><em>A cluster placement group is a logical grouping of instances within a single Availability Zone. A placement group can span peered VPCs in the same Region. The chief benefit of a cluster placement group, in addition to a 10 Gbps flow limit, is the non-blocking, non-oversubscribed, fully bi-sectional nature of the connectivity. In other words, all nodes within the placement group can talk to all other nodes within the placement group at the full line rate of 10 Gbps flows and 25 aggregate without any slowing due to over-subscription.<br> </em></p><p><em>Cluster placement groups are recommended for applications that benefit from low network latency, high network throughput, or both, and if the majority of the network traffic is between the instances in the group. To provide the lowest latency and the highest packet-per-second network performance for your placement group, choose an instance type that supports enhanced networking. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html">Enhanced Networking</a>. </em></p><p><em>We recommend that you launch the number of instances that you need in the placement group in a single launch request and that you use the same instance type for all instances in the placement group. If you try to add more instances to the placement group later, or if you try to launch more than one instance type in the placement group, you increase your chances of getting an insufficient capacity error. </em></p><p><em>If you stop an instance in a placement group and then start it again, it still runs in the placement group. However, the start fails if there isn't enough capacity for the instance. </em></p><p><em>If you receive a capacity error when launching an instance in a placement group that already has running instances, stop and start all of the instances in the placement group, and try the launch again. Restarting the instances may migrate them to hardware that has capacity for all the requested instances. </em></p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120444">AWS SAP-C01 Question feedback</a> </p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 7 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249159"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> After the Government organization you work for suffers it's 3rd DDOS attack of the year you have been handed one part of a strategy to try and stop this from happening again. You have been told that your job is to minimize the attack surface area. You do have a vague idea of some of the things you need to put in place to achieve this. Which of the following is NOT one of the ways to minimize the attack surface area as a DDOS minimization strategy? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Eliminate non-critical Internet entry points.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Configure services such as Elastic Load Balancing and Auto Scaling to automatically scale.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Reduce the number of necessary Internet entry points.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Separate end user traffic from management traffic. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Configure services such as Elastic Load Balancing and Auto Scaling to automatically scale.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as the configure services such as Elastic Load Balancing and Auto Scaling to automatically scale targets the ability to Be Ready to Scale to Absorb the Attack<span class="redactor-invisible-space"></span> </p><p>Strategy to minimize the Attack surface area includes </p><ul> <li>reduce the number of necessary Internet entry points,</li> <li>don’t expose back end servers,</li> <li>eliminate non-critical Internet entry points,</li> <li>separate end user traffic from management traffic,</li> <li>obfuscate necessary Internet entry points to the level that untrusted end users cannot access them, and</li> <li>decouple Internet entry points to minimize the effects of attacks.</li> </ul><p>Refer AWS <a href="https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf" target="_blank">DDOS Whitepaper</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120417">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 8 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249160"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have been asked to cost optimize a business critical and long-running EMR cluster. The EMR cluster is currently on-demand for the master nodes, core nodes and task nodes. The costs for running the cluster have been steadily increasing as nodes have been added and resized. What would you suggest the business does to reduce the costs without requiring any long-term commitment?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Recreate the cluster using spot instances for the master, core and task nodes.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Leave the master node to use on-demand and change the core and task nodes to spot<br><b>C</b>. <input type="radio" disabled="">&nbsp;Leave all nodes running on-demand instances, the cluster is already cost optimized.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Leave the master and core nodes as on-demand and use spot instances for the task nodes <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Leave the master and core nodes as on-demand and use spot instances for the task nodes<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as AWS recommends using reserved or on-demand instances for Master and Core nodes. Task nodes can use spot instances to improve performance and reduce cost. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html" target="_blank">EMR Plan Instances</a> </p><p><em>The master node controls and directs the cluster. When it terminates, the cluster ends, so you should only launch the master node as a Spot Instance if you are running a cluster where sudden termination is acceptable. This might be the case if you are testing a new application, have a cluster that periodically persists data to an external store such as Amazon S3, or are running a cluster where cost is more important than ensuring the cluster’s completion.<br></em> </p><p><em>Core nodes process data and store information using HDFS. Terminating a core instance risks data loss. For this reason, you should only run core nodes on Spot Instances when partial HDFS data loss is tolerable.<br></em> </p><p><em>The task nodes process data but do not hold persistent data in HDFS. If they terminate because the Spot price has risen above your maximum Spot price, no data is lost and the effect on your cluster is minimal.</em><em></em><br> </p><p>Option A is wrong as running all on spot instances would result in data loss and cluster availability issues. </p><p>Option B is wrong as Core nodes should not be run on spot instances as there is a data loss issue.<br> </p><p>Option C is wrong as On-demand nodes for all would not provide the best cost optimization.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%203%20-%20%23121200">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 9 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249161"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company plans to host a large donation website on Amazon Web Services (AWS). You anticipate a large and undetermined amount of traffic that will create many database writes. To be certain that you do not drop any writes to a database hosted on AWS. Which service should you use?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Amazon RDS with provisioned IOPS up to the anticipated peak write throughput.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Amazon Simple Queue Service (SQS) for capturing the writes and draining the queue to write to the database.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Amazon ElastiCache to store the writes until the writes are committed to the database.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Amazon DynamoDB with provisioned write throughput up to the anticipated peak write throughput. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Amazon Simple Queue Service (SQS) for capturing the writes and draining the queue to write to the database.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as SQS can be used to provide the durability with at least once delivery of the message and buffer the writes to DynamoDB. </p><p>Option A is wrong as RDS is not ideal solution cause it cannot scale horizontally to handle the writes. </p><p>Option C is wrong as ElastiCache is for caching and not ideal for storing the writes.<br> </p><p>Option D is wrong as there is large and undetermined amount of traffic the write throughput cannot be provisioned.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120562">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 10 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249162"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A team is developing a feature that needs to recognize Celebrities. By using the APP, clients are able to upload photos and search celebrities among the photos by clicking a button. Or they can upload a bunch of photos and search the times that a given celebrity has appeared. The team wants to run the APP in AWS with a lower cost. Which option is the most efficient one to implement while still ensuring the availability and stability?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create the frontend and backend in a T2 medium EC2 instances to use its burstable capability. Call Rekognition API "RecognizeCelebrities" to fetch the information in a JSON format. Process the JSON result in the backend service and return the result to the frontend UI.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Develop the APP in serverless lambda to use Rekognition API "SearchFaces" to search a Celebrity. The input image can be base64-encoded bytes or an S3 object. After the API has been returned, present the result to clients.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use AWS Rekognition service. Implement the APP in lambda to call Rekognition API "RecognizeCelebrities" to fetch the information required in a JSON format. Process the information in Lambda and return the result to end-users. Use S3 for clients to upload photos.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Implement the APP in a M4 large EC2 instances with Auto Scaling and Elastic Load Balancer. Build the application via a CloudFormation template. Use the APP to call Rekognition API "SearchFaces" to get the information. Process the JSON result in the backend service and return the result to the frontend with a CloudFront CDN. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use AWS Rekognition service. Implement the APP in lambda to call Rekognition API "RecognizeCelebrities" to fetch the information required in a JSON format. Process the information in Lambda and return the result to end-users. Use S3 for clients to upload photos.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as using AWS Rekognition<span class="redactor-invisible-space"> would provide an Out of the Box celebrities recognition and using Lambda would provide a scalable and cost efficient application layer.</span> </p><p><span class="redactor-invisible-space">Refer AWS documentation - <a href="https://docs.aws.amazon.com/rekognition/latest/dg/celebrities.html">Rekognition Celebrities</a></span> </p><p><em>Amazon Rekognition can recognize thousands of celebrities in a wide range of categories, such as entertainment and media, sports, business, and politics. With Amazon Rekognition, you can recognize celebrities in images and in stored videos. You can also get additional information for recognized celebrities.</em> </p><p><em></em> </p><p><em>The Amazon Rekognition celebrity recognition API is tuned to detect as many celebrities as possible in different settings, cosmetic makeup, and other conditions. Social, media, and entertainment customers can build apps that use celebrity recognition. For example, an entertainment app that identifies celebrity lookalikes or an app that identifies celebrities as part of automated footage tagging. Amazon Rekognition celebrity recognition is designed to be exclusively used in cases where you expect there may be a known celebrity in an image or a video.</em> </p><p>Option A is wrong as using EC2 is not cost efficient as compared to Lambda. </p><p>Option B is wrong as Rekognition API “RecognizeCelebrities” should be used instead of "SearchFaces". </p><p>Option D is wrong as using EC2 with ELB and Auto Scaling would be expensive compared to Lambda. Secondly, “RecognizeCelebrities” API should be used instead of "SearchFaces". </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120604">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 11 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249163"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have migrated a legacy stock image site into AWS and it's costing much more than expected. The site uses an Application load balancer in front of a fleet of EC2 instances managed by an ASG. The instances process login requests and allow customers to download huge images files. The EC2 instances hosted on large M4 instances are running apache and are generally running with a low average CPU but are transferring huge quantities of data serving the images to customers. What options should you suggest to the client? (Select THREE)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Change the EC2 instances to a larger instance type with higher bandwidth network instances</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Create an IAM role - allocate it to the instance and adjust the application to create signed URL's<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Create a bucket policy allowing all users to read the images<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Create a lambda function and enable managed identify federation. Use it to serve images using application cookies.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Create a CloudFront distribution and set to private<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Create an S3 bucket, migrate data and enable static web hosting <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create an IAM role - allocate it to the instance and adjust the application to create signed URL's<br><b>E</b>. Create a CloudFront distribution and set to private<br><b>F</b>. Create an S3 bucket, migrate data and enable static web hosting<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B, E &amp; F</strong> </p><p>Option F as the data can be migrated to low cost static hosting in S3. </p><p>Option E as the CloudFront distribution can be used to secure, expose and cache the data for low latency access </p><p>Option B as the application can generate pre-signed urls which can allow direct access to users to download from S3 without the traffic being routed by the EC2 instances. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html" target="_blank">CloudFront Serving Private Content</a> </p><p><em>Many companies that distribute content over the internet want to restrict access to documents, business data, media streams, or content that is intended for selected users, for example, users who have paid a fee. To securely serve this private content by using CloudFront, you can do the following:</em> </p><ul> <li><em>Require that your users access your private content by using special CloudFront signed URLs or signed cookies.</em></li> <li><em>Require that your users access your Amazon S3 content by using CloudFront URLs, not Amazon S3 URLs. Requiring CloudFront URLs isn't necessary, but we recommend it to prevent users from bypassing the restrictions that you specify in signed URLs or signed cookies.</em></li> </ul><p><em>Important - </em><em>If you use an Amazon S3 bucket configured as a website endpoint, you must set it up with CloudFront as a custom origin and you can't use the origin access identity feature described in this topic. You can restrict access to content on a custom origin by using custom headers.</em> </p><p><em>Option A is wrong as larger instance type does not improve performance much and does not utilize the server capacity. It also increases cost.<br></em> </p><p>Option C is wrong as the images should be secure and not exposed to all or made public.<br> </p><p>Option D is wrong as Lambda does not handle authentication and serving images from Lambda is not an ideal solution.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%203%20-%20%23121201">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 12 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249164"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing network connectivity for your fat client application. The application is designed for business travelers who must be able to connect to it from their hotel rooms, cafes, public Wi-Fi hotspots, and elsewhere on the Internet. You do not want to publish the application on the Internet. Which network design meets the above requirements while minimizing deployment and operational costs?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Implement AWS Direct Connect, and create a private interface to your VPC. Create a public subnet and place your application servers in it.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Implement Elastic Load Balancing with an SSL listener that terminates the back-end connection to the application.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Configure an IPsec VPN connection, and provide the users with the configuration details. Create a public subnet in your VPC, and place your application servers in it.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Configure an SSL VPN solution in a public subnet of your VPC, then install and configure SSL VPN client software on all user computers. Create a private subnet in your VPC and place your application servers in it. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Configure an SSL VPN solution in a public subnet of your VPC, then install and configure SSL VPN client software on all user computers. Create a private subnet in your VPC and place your application servers in it.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point is keep the application private while minimizing deployment and operational costs </p><p>Correct answer is <strong>D</strong> as VPN will help keep the connection private, is cost effective and can be in private subnet as well </p><p>Refer AWS documentation for <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario4.html" target="_blank">VPC with VPN</a> </p><p>Option A is wrong as Direct Connect would increase cost, does not minimize deployment. Also instances are in public subnet and exposed. </p><p>Option B is wrong as it is still exposed to Internet </p><p>Option C is wrong as instances still in public subnet are internet accessible </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120386">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 13 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249165"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An agile team just starts using AWS and the team leader wants them to move the legacy Java-based software to the AWS platform in 2 weeks. The requirement is that the new environment must be highly available and the infrastructure is managed as code and version controlled. Besides, the team has good experiences of Chef so they want to use that knowledge during the migration. Which actions should the team perform to meet the needs? (Select TWO)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Use several CloudFormation templates to build up infrastructure such as VPC, NAT Gateway, Bastion, and Route53. Version control it using CodeCommit.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;As CloudFormation does not support OpsWorks service, use Chef in EC2 to build up the web services. Existing cookbooks can be used. Add an Auto Scaling group with a proper auto scaling configuration to ensure high availability<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use a nested CloudFormation template to create an OpsWorks stack. The resource type is “AWS::OpsWorks::Stack”. Add a Java layer in the stack. Make sure that the Scaling configuration is turned on<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use various CloudFormation templates to set up infrastructure such as VPC, NAT Gateway, Bastion host, Security Groups and EC2 instances. Version control it using GitHub.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use OpsWorks to build up the Java web services. Existing cookbooks can be used. However OpsWorks cannot be put into CloudFormation template, as CloudFormation does not support it. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Use several CloudFormation templates to build up infrastructure such as VPC, NAT Gateway, Bastion, and Route53. Version control it using CodeCommit.<br><b>C</b>. Use a nested CloudFormation template to create an OpsWorks stack. The resource type is “AWS::OpsWorks::Stack”. Add a Java layer in the stack. Make sure that the Scaling configuration is turned on<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A &amp; C</strong> </p><p>Option A as CloudFormation provides infrastructure as code with templates being version controlled using CodeCommit. </p><p>Option C as OpsWorks help reuse Chef cookbooks and recipes and application deployment. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-stack.html" target="_blank">CloudFormation OpsWorks</a> </p><p><em><a href="https://aws.amazon.com/aws.amazon.com/cloudformation.html">AWS CloudFormation</a> enables modeling, provisioning and version-controlling of a <a href="https://aws.amazon.com/aws.amazon.com/cloudformation/aws-cloudformation-templates.html">wide range</a> of AWS resources. <a href="https://aws.amazon.com/aws.amazon.com/opsworks.html">AWS OpsWorks</a> is an application management service that simplifies software configuration, application deployment, scaling, and monitoring.</em> </p><p><em>You can now model OpsWorks components (stacks, layers, instances, and applications) inside CloudFormation templates, and provision them as CloudFormation stacks. This enables you to document, version control, and share your OpsWorks configuration. You have the flexibility to provision OpsWorks components and other related AWS resources such as Amazon VPC and AWS Elastic Load Balancer with a unified CloudFormation template or separate CloudFormation templates.</em> </p><p>Options B &amp; E are wrong as CloudFormation can be used with OpsWorks. </p><p>Option D is wrong as the EC2 instances management must be performed using OpsWorks stack. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120571">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 14 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249166"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> To enable end-to-end HTTPS connections from the user‘s browser to the origin via CloudFront, which of the following options are valid? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Use self signed certificate in the origin and CloudFront default certificate in CloudFront.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use the CloudFront default certificate in both origin and CloudFront<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use 3rd-party CA certificate in the origin and CloudFront default certificate in CloudFront<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use 3rd-party CA certificate in both origin and CloudFront<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use a self signed certificate in both the origin and CloudFront <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use 3rd-party CA certificate in the origin and CloudFront default certificate in CloudFront<br><b>D</b>. Use 3rd-party CA certificate in both origin and CloudFront<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C &amp; D</strong>. Refer AWS documentation for CloudFront HTTPs </p><p>For End-to-End HTTPS connections certificate needs to be applied both between the Viewers and CloudFront &amp; CloudFront and Origin, with the following requirements </p><ol> <li>HTTPS between viewers and CloudFront <ol> <li>Certificate that was issued by a trusted certificate authority (CA) such as Comodo, DigiCert, or Symantec;</li> </ol><ol> <li>Certificate provided by AWS Certificate Manager (ACM);</li> </ol><ol> <li>Self-signed certificate.</li> </ol></li> <li> HTTPS between CloudFront and a custom origin <ol> <li>If the origin is not an ELB load balancer, the certificate must be issued by a trusted CA such as Comodo, DigiCert, or Symantec.</li> </ol><ol> <li>For ELB load balancer, certificate provided by ACM can be used</li> </ol></li> </ol><p>Option A is wrong as Origin cannot be self signed<br> </p><p>Option B is wrong as CloudFront cert cannot be applied to origin </p><p>Option E is wrong as Origin cannot be self signed </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120228">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 15 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249167"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your system recently experienced down time during the troubleshooting process. You found that a new administrator mistakenly terminated several production EC2 instances. Which of the following strategies will help prevent a similar situation in the future? The administrator still must be able to:- launch, start stop, and terminate development resources. - launch and start production instances.<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an IAM user, which is not allowed to terminate instances by leveraging production EC2 termination protection.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Leverage resource based tagging along with an IAM user, which can prevent specific users from terminating production EC2 resources.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Leverage EC2 termination protection and multi-factor authentication, which together require users to authenticate before terminating EC2 instances.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an IAM user and apply an IAM role, which prevents users from terminating production EC2 instances. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Leverage resource based tagging along with an IAM user, which can prevent specific users from terminating production EC2 resources.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to identify production resources and be able prevent termination. </p><p>Correct answer is <strong>B</strong> as <a href="https://aws.amazon.com/blogs/security/resource-level-permissions-for-ec2-controlling-management-access-on-specific-instances/" target="_blank">tagging will help identify production instances and explicitly deny access using resource level permissions</a> </p><p>Option A is wrong as EC2 termination protection is enabled on EC2 instance </p><p>Option C is wrong as it does not still prevent user from terminating instance </p><p>Option D is wrong as Role is not applied to User but assumed by the User also need a way to identify production EC2 instances </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120236">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 16 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249168"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is managing a customer's application which currently includes a three-tier application configuration. The first tier manages the web instances and is configured in a public subnet. The second layer is the application layer. As part of the application code, the application instances upload large amounts of data to Amazon S3. Currently, the private subnets that the application instances are running for on have a route to a single NAT t2.micro NAT instance. The application, during peak loads, becomes slow and customer uploads from the application to S3 are not completing and taking a long time. Which steps might you take to solve the issue using the most cost efficient method? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure Auto Scaling for the NAT instance in order to handle increase in load</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a VPC S3 endpoint<br><b>C</b>. <input type="radio" disabled="">&nbsp;Increase the NAT instance size; network throughput increases with an increase in instance size<br><b>D</b>. <input type="radio" disabled="">&nbsp;Launch an additional NAT instance in another subnet and replace one of the routes in a subnet to the new instance <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create a VPC S3 endpoint<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as VPC S3 endpoint would help the instances to connect to S3 without having to route the traffic through NAT and IGW. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html" target="_blank">VPC Endpoints</a> </p><p><em>A VPC endpoint enables you to create a private connection between your VPC and another AWS service without requiring access over the Internet, through a NAT device, a VPN connection, or AWS Direct Connect. Endpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components that allow communication between instances in your VPC and AWS services without imposing availability risks or bandwidth constraints on your network traffic.</em> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120422">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 17 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249169"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are setting up a website for a small startup company. You have built them what you believe to be a great solution on AWS for the money they wanted to spend. It is a very image intensive site, so you have utilized CloudFront to help with the serving of images. The client complains to you, however, that he requires a custom domain name when serving up this content that should work with https from for CloudFront. What would you need to do to accomplish what the customer is asking? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 12 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;You must provision and configure your own SSL certificate in Route 53 and associate it to your CloudFront distribution.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;You must provision and configure your own SSL certificate in IAM and associate it to your CloudFront distribution.<br><b>C</b>. <input type="radio" disabled="">&nbsp;You must provision and configure an ALIAS in Route 53 and associate it to your CloudFront distribution<br><b>D</b>. <input type="radio" disabled="">&nbsp;You must create an Origin Access identity(OAI) for CloudFront and grant access to the objects in your S3 bucket where the images are stored. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. You must provision and configure your own SSL certificate in IAM and associate it to your CloudFront distribution.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as per <a href="https://aws.amazon.com/cloudfront/faqs/" target="_blank">FAQs</a> a third party certificate can be associated with CloudFront using IAM or ACM<br></p><p>Refer to <a href="https://aws.amazon.com/cloudfront/custom-ssl-domains/" target="_blank">CloudFront Custom SSL Domains</a><br> </p><p><em>Yes, you can now provision SSL/TLS certificates and associate them with CloudFront </em><em>distributions within minutes. Simply provision a certificate using the new AWS </em><em>Certificate Manager (ACM) and deploy it to your CloudFront distribution with a </em><em>couple of clicks, and let ACM manage certificate renewals for you. </em><em>ACM allows you to provision, deploy, and manage the certificate with no additional charges. </em><em>Note that CloudFront still supports using certificates that you obtained from a </em><em>third-party certificate authority and uploaded to the IAM certificate store.</em></p><p>Option A is wrong as the certificate needs to be associated with CloudFront. </p><p>Option C is wrong as ALIAS is just to configure Route 53 and does not handle the custom domain and custom ssl certificate aspect </p><p>Option D is wrong as OAI is mainly to protect S3 contents not being directly accessible.</p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120397">AWS SAP-C01 Question feedback</a> </p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 18 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249170"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An IT company has a big data analytics application that is deployed in EC2 in multiple availability zones. These EC2 instances simultaneously access a shared Amazon EFS file system using a traditional file permissions model. A recent internal security audit has found that there is a potential security risk as the EFS file system is not encrypted for either at rest or in transit. What actions could be taken to address the potential security threat posed by non-encryption of the EFS volume?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;The encryption of data at rest has to be enabled when the Amazon EFS file system is created. The encryption of data in transit can be enabled when the file system is mounted in EC2 instance</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;The encryption of data at rest and in transit can be enabled when the Amazon EFS file system is created.<br><b>C</b>. <input type="radio" disabled="">&nbsp;The encryption of data at rest and in transit can only be enabled when the Amazon EFS file system is mounted in EC2 instance.<br><b>D</b>. <input type="radio" disabled="">&nbsp;The encryption of data at rest can be enabled when the Amazon EFS file system is mounted in EC2 instance. The encryption of data in transit is enabled when the EFS file system is created using AWS console or CLI. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. The encryption of data at rest has to be enabled when the Amazon EFS file system is created. The encryption of data in transit can be enabled when the file system is mounted in EC2 instance<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as EFS supports both Encryption at Rest and Transit. <em>Amazon EFS supports two forms of encryption for file systems, encryption of data in transit and encryption at rest. You can enable encryption of data at rest when creating an Amazon EFS file system. You can enable encryption of data in transit when you mount the file system.</em> </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/efs/latest/ug/encryption.html" target="_blank">EFS</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120825">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 19 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249171"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Once again your security officer is on your case and this time is asking you to make sure the AWS Key Management Service (AWS KMS) is working as it is supposed to. You are initially not too sure how KMS even works, however after some intense late night reading you think you have come up with a reasonable definition. Which of the following best describes how the AWS Key Management Service works? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;AWS KMS supports two kinds of keys — master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to decrypt the customer data, and the master keys are used to encrypt the customer data.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;AWS KMS supports two kinds of keys — master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt the customer data and the master keys are used to decrypt the customer data.<br><b>C</b>. <input type="radio" disabled="">&nbsp;AWS KMS supports two kinds of keys — master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The master keys are then used to encrypt and decrypt customer data.<br><b>D</b>. <input type="radio" disabled="">&nbsp;AWS KMS supports two kinds of keys — master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt and decrypt customer data. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. AWS KMS supports two kinds of keys — master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt and decrypt customer data.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p><em></em>Correct answer is <strong>D</strong> as KMS has 2 keys, master and data. Master can be used to encrypt/decrypt data key as well as small data set. While data is used to encrypt/decrypt large data. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html" target="_blank">KMS Concepts</a> </p><p><em>The primary resources in AWS KMS are customer master keys (CMKs). CMKs are either customer-managed or AWS-managed. You can use either type of CMK to protect up to 4 kibibytes (KiB) of data directly. Typically you use CMKs to protect data encryption keys (or data keys) which are then used to encrypt or decrypt larger amounts of data outside of the service. CMKs never leave AWS KMS unencrypted, but data keys can. AWS KMS does not store, manage, or track your data keys.</em> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120434">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 20 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249172"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your application provides data transformation services. Files containing data to be transformed are first uploaded to Amazon S3 and then transformed by a fleet of spot EC2 instances. Files submitted by your premium customers must be transformed with the highest priority. How should you implement such a system?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use a DynamoDB table with an attribute defining the priority level. Transformation instances will scan the table for tasks, sorting the results by priority level.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use Route 53 latency based-routing to send high priority tasks to the closest transformation instances.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use two SQS queues, one for high priority messages, and the other for default priority. Transformation instances first poll the high priority queue; if there is no message, they poll the default priority queue<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use a single SQS queue. Each message contains the priority level. Transformation instances poll high-priority messages first. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use two SQS queues, one for high priority messages, and the other for default priority. Transformation instances first poll the high priority queue; if there is no message, they poll the default priority queue<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as this can be implemented using <a href="http://en.clouddesignpattern.org/index.php/CDP:Priority_Queue_Pattern" target="_blank">SQS Priority Queue Pattern</a> </p><p><img src="./sap-03_files/2XNdewVsgellO3x8-96155.png"><br><br> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120527">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 21 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249173"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A third party auditor is being brought in to review security processes and configurations for all of a company's AWS accounts. Currently, the company does not use any on-premise identity provider. Instead, they rely on IAM accounts in each of their AWS accounts. The auditor needs read-only access to all AWS resources for each AWS account. Given the requirements, what is the best security method for architecting access for the security auditor? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an IAM user for each AWS account with read-only permission policies for the auditor, and disable each account when the audit is complete.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Configure an on-premise AD server and enable SAML and identify federation for single sign-on to each AWS account.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an IAM role with read-only permissions to all AWS services in each AWS account. Create one auditor IAM account and add a permissions policy that allows the auditor to assume the ARN role for each AWS account that has an assigned role.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a custom identity broker application that allows the auditor to use existing Amazon credentials to Log into the AWS environments. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create an IAM role with read-only permissions to all AWS services in each AWS account. Create one auditor IAM account and add a permissions policy that allows the auditor to assume the ARN role for each AWS account that has an assigned role.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as it is best to have a role with correct minimal permissions to be able to access multiple AWS accounts. </p><p>Option A is wrong as creating an AM user in each account is an overhead, cumbersome and difficult to maintain </p><p>Option B and D are wrong as there is no identity provider, it does not need a identity provider and federation handling </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120392">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 22 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249174"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have a business critical two tier web app currently deployed in two availability zones in a single region, using Elastic Load Balancing and Auto Scaling. The app depends on synchronous replication (very low latency connectivity) at the database layer. The application needs to remain fully available even if one application Availability Zone goes off-line, and Auto scaling cannot launch new instances in the remaining Availability Zones. How can the current architecture be enhanced to ensure this?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Deploy in two regions using Weighted Round Robin (WRR), with Auto Scaling minimums set for 100% peak load per region.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Deploy in three AZs, with Auto Scaling minimum set to handle 50% peak load per zone.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Deploy in three AZs, with Auto Scaling minimum set to handle 33% peak load per zone.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Deploy in two regions using Weighted Round Robin (WRR), with Auto Scaling minimums set for 50% peak load per region. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Deploy in three AZs, with Auto Scaling minimum set to handle 50% peak load per zone.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as 3 AZs with 50% each, even if one does down and auto scaling is not able to launch any instances, 50% + 50% LB handles all the load </p><p>Option C is wrong as it gives 33% each and if one goes down, the rest two will handle 66% load </p><p>Choice A &amp; D are wrong as WRR would requires Route 53. The Database also requires Synchronous replication with low latency which would not work. Also, for D 50% would not work any ways. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120427">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 23 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249175"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A development team that is currently doing a nightly six-hour build which is lengthening over time on-premises with a large and mostly under utilized server would like to transition to a continuous integration model of development on AWS with multiple builds triggered within the same day. However, they are concerned about cost, security and how to integrate with existing on-premises applications such as their LDAP and email servers, which cannot move off-premises. The development environment needs a source code repository; a project management system with a MySQL database resources for performing the builds and a storage location for QA to pick up builds from. What AWS services combination would you recommend to meet the development team's requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;A Bastion host Amazon EC2 instance running a VPN server for access from on-premises, Amazon EC2 for the source code repository with attached Amazon EBS volumes, Amazon EC2 and Amazon RDS MySQL for the project management system, EIP for the source code repository and project management system, Amazon SQL for a build queue, An Amazon Auto Scaling group of Amazon EC2 instances for performing builds and Amazon Simple Email Service for sending the build output.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;An AWS Storage Gateway for connecting on-premises software applications with cloud-based storage securely, Amazon EC2 for the resource code repository with attached Amazon EBS volumes, Amazon EC2 and Amazon RDS MySQL for the project management system, EIPs for the source code repository and project management system, Amazon Simple Notification Service for a notification initiated build, An Auto Scaling group of Amazon EC2 instances for performing builds and Amazon S3 for the build output.<br><b>C</b>. <input type="radio" disabled="">&nbsp;An AWS Storage Gateway for connecting on-premises software applications with cloud-based storage securely, Amazon EC2 for the resource code repository with attached Amazon EBS volumes, Amazon EC2 and Amazon RDS MySQL for the project management system, EIPs for the source code repository and project management system, Amazon SQS for a build queue, An Amazon Elastic Map Reduce (EMR) cluster of Amazon EC2 instances for performing builds and Amazon CloudFront for the build output.<br><b>D</b>. <input type="radio" disabled="">&nbsp;A VPC with a VPN Gateway back to their on-premises servers, Amazon EC2 for the source-code repository with attached Amazon EBS volumes, Amazon EC2 and Amazon RDS MySQL for the project management system, EIPs for the source code repository and project management system, SQS for a build queue, An Auto Scaling group of EC2 instances for performing builds and S3 for the build output. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. A VPC with a VPN Gateway back to their on-premises servers, Amazon EC2 for the source-code repository with attached Amazon EBS volumes, Amazon EC2 and Amazon RDS MySQL for the project management system, EIPs for the source code repository and project management system, SQS for a build queue, An Auto Scaling group of EC2 instances for performing builds and S3 for the build output.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is implement hybrid architecture with processing on AWS and email and LDAP on-premises </p><p>Correct answer is <strong>D</strong> as VPN gateway is required for secure connectivity between AWS and on-premises. SQS for build queue and Auto Scaling EC2 for parallel builds. </p><p>Option A is wrong as Bastion is not for VPN connectivity and only as a jump server to be able to access instances in private subnet. SES should not be used as the Email servers on-premises should be utilized </p><p>Option B is wrong as Storage Gateway is for backup and does not provide secure connectivity, still needs VPN. SNS alone cannot handle builds and only for notifications </p><p>Option C is wrong as Storage Gateway is for backup and does not provide secure connectivity, still needs VPN. EMR is not ideal for performing builds as it needs normal EC2 instances </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120371">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 24 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249176"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Company A has hired you to assist with the migration of an interactive website that allows registered users to rate local restaurants. Updates to the ratings are displayed on the home page, and ratings are updated in real time. Although the website is not very popular today, the company anticipates that it will grow rapidly over the next few weeks. They want the site to be highly available. The current architecture consists of a single Windows Server 2008 R2 web server and a MySQL database running on Linux. Both reside inside an on-premises hypervisor. What would be the most efficient way to transfer the application to AWS, ensuring performance and high-availability?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Export web files to an Amazon 53 bucket in us-west-1. Run the website directly out of Amazon 53. Launch a multi -AZ MySQL Amazon RDS instance in us-west-1a. Import the data into Amazon RDS from the latest MySQL backup. Use Route 53 and create an alias record pointing to the elastic load balancer.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Launch two Windows Server 2008 R2 instances in us-west-1b and two in us-west-1a. Copy the web files from on premises web server to each Amazon EC2 web server, using Amazon S3 as the repository. Launch a multi -AZ MySQL Amazon RDS instance in us-west-1a. Import the data into Amazon RDS from the latest MySQL backup. Create an elastic load balancer to front your web servers. Use Route 53 and create an alias record pointing to the elastic load balancer.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use AWS VM Import/Export to create an Amazon Elastic Compute Cloud (EC2) Amazon Machine Image (AMI) of the web server. Configure Auto Scaling to launch two web servers in us-west-1a and two in us-west-1b. Launch a Multi-AZ MySQL Amazon Relational Database Service (RDS) instance in us-west-1b. Import the data into Amazon RDS from the latest MySQL backup. Use Amazon Route 53 to create a hosted zone and point an A record to the elastic load balancer.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use AWS VM Import/Export to create an Amazon EC2 AMI of the web server. Configure auto -scaling to launch two web servers in us-west-1a and two in us-west-1b. Launch a multi-AZ MySQL Amazon RDS instance in us-west-1a. Import the data Into Amazon RDS from the latest MySQL backup. Create an elastic load balancer to front your web servers. Use Amazon Route 53 and create an A record pointing to the elastic load balancer. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Launch two Windows Server 2008 R2 instances in us-west-1b and two in us-west-1a. Copy the web files from on premises web server to each Amazon EC2 web server, using Amazon S3 as the repository. Launch a multi -AZ MySQL Amazon RDS instance in us-west-1a. Import the data into Amazon RDS from the latest MySQL backup. Create an elastic load balancer to front your web servers. Use Route 53 and create an alias record pointing to the elastic load balancer.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is cloud migration to ensure HA and performance </p><p>Correct answer is <strong>B</strong> as EC2 servers can be launched with web files from S3. Multi-AZ RDS and Route 53 with ELB and alias record would provide HA. </p><p>Option A is wrong as its an interactive website and its migration so would need modifications to use javascript SDK. Also why ELB. </p><p>Option C is wrong as the solution does not create a load balancer and cannot point a A record to ELB </p><p>Option D is wrong as for need to create a aliased record from Route 53 to ELB </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120366">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 25 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249177"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You need to create an audit log of all changes to customer banking data. You use DynamoDB to store this customer banking data. It's important not to lose any information due to server failures. What is an elegant way to accomplish this?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use a DynamoDB Stream Specification and stream all changes to AWS Lambda. Log the changes to AWS CloudWatch Logs, removing sensitive information before logging.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Before writing to DynamoDB, do a pre-write acknowledgment to disk on the application server, removing sensitive information before logging. Periodically rotate these log files into S3. <br><b>C</b>. <input type="radio" disabled="">&nbsp;Use a DynamoDB Stream Specification and periodically flush to an EC2 instance store, removing sensitive information before putting the objects. Periodically flush these batches to S3. <br><b>D</b>. <input type="radio" disabled="">&nbsp;Before writing to DynamoDB, do a pre-write acknowledgment to disk on the application server, removing sensitive information before logging. Periodically pipe these files into CloudWatch Logs. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Use a DynamoDB Stream Specification and stream all changes to AWS Lambda. Log the changes to AWS CloudWatch Logs, removing sensitive information before logging.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as with once the data is written to DynamoDB it would be pushed to streams and have lambda handling it to push to CloudWatch logs which provides a durable storage </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html" target="_blank">DynamoDB Streams</a> &amp; <a href="http://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html" target="_blank">Lambda with DynamoDB</a> </p><p><img src="./sap-03_files/ddb-pull-model-10.png"><br><br> </p><p><em>A DynamoDB stream is an ordered flow of information about changes to items in an Amazon DynamoDB table. When you enable a stream on a table, DynamoDB captures information about every modification to data items in the table.</em> </p><p><em>Whenever an application creates, updates, or deletes items in the table, DynamoDB Streams writes a stream record with the primary key attribute(s) of the items that were modified. A stream recordcontains information about a data modification to a single item in a DynamoDB table. You can configure the stream so that the stream records capture additional information, such as the "before" and "after" images of modified items.</em> </p><p><em>DynamoDB Streams guarantees the following:</em> </p><ul> <li><em>Each stream record appears exactly once in the stream.</em></li> <li><em>For each item that is modified in a DynamoDB table, the stream records appear in the same sequence as the actual modifications to the item.</em></li> </ul><p><em>DynamoDB Streams writes stream records in near real time, so that you can build applications that consume these streams and take action based on the contents.</em> </p><p>Option A &amp; D are wrong as it is before handling the write, it is susceptible to lose information in case of any failures. </p><p>Option C is wrong as using instance store would not guarantee durability and might lead to loss of information. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120518">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 26 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249178"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A Company has developed a viral marketing website that specializes in posting blog posts that go viral. The posts usually receive 90% of the viral traffic within 24 hours of being posted and often need to be updated with corrections during the first 24 hours. What would be the best method for implementing a solution to help handle the scale of requests given the behavior of the blog posts? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an ElastiCache cluster and use lazy loading for the caching strategies.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use a CloudFront CDN and configure 0 TTL and enable URL parameter forwarding to the origin.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an ElastiCache cluster and use write through caching strategies to quickly update the content when blog posts require it.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use CloudFront CDN and configure a lower TTY using CloudFront invalidation mechanisms to clear the cache when updates are required. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Use a CloudFront CDN and configure 0 TTL and enable URL parameter forwarding to the origin.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B </strong>as CloudFront can help maintain a persistent connection to origin and with TTY set to 0 it still caches the results and check if its modified </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/blogs/aws/amazon-cloudfront-support-for-dynamic-content/" target="_blank">CloudFront Dynamic Content</a> </p><p><em>Persistent TCP Connections – Establishing a TCP connection takes some time because each new connection requires a <a href="http://www.inetdaemon.com/tutorials/internet/tcp/3-way_handshake.shtml" target="_self">three-way handshake</a> between the server and the client. Amazon CloudFront makes use of persistent connections to each origin for dynamic content. This obviates the connection setup time that would otherwise slow down each request. Reusing these “long-haul” connections back to the server can eliminate hundreds of milliseconds of connection setup time. The connection from the client to the CloudFront edge location is also kept open whenever possible.<span class="redactor-invisible-space"><br></span> </em> </p><p><em>Variable Time-To-Live (TTL) – In many cases, dynamic content is either not cacheable or cacheable for a very short period of time, perhaps just a few seconds. In the past, CloudFront’s minimum TTL was 60 minutes since all content was considered static. The new minimum TTL value is 0 seconds. If you set the TTL for a particular origin to 0, CloudFront will still cache the content from that origin. It will then make a GET request with an If-Modified-Since header, thereby giving the origin a chance to signal that CloudFront can continue to use the cached content if it hasn’t changed at the origin.</em><span class="redactor-invisible-space"><br></span> </p><p><span class="redactor-invisible-space">Option A &amp; C are wrong as using ElastiCache would result in frequent updates to cache and would not be useful.</span> </p><p><span class="redactor-invisible-space">Option D is wrong as invalidation can be costly as it is not free.</span> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120537">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 27 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249179"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A Solutions Architect is designing an application for a genomic research company. The application will perform several complex mathematical calculations on a nightly basis. Each calculation is independent of all other calculations and each may take several hours to complete. The application design must minimize costs and interdependencies. Calculations should execute in parallel. How can these requirements be met?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Submit the calculations to AWS Batch as jobs. Run the jobs in separate containers within Amazon ECS.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Submit each calculation to an Amazon API Gateway. Use AWS Lambda functions to perform the calculations.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Submit each calculation to a master Amazon EC2 instance. Configure the EC2 instance to forward the calculations to an appropriate EC2 worker node.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Submit each calculation to an ELB Application Load Balancer. Configure the ELB to use path-based routing to forward the request to an appropriate Amazon EC2 worker node. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Submit the calculations to AWS Batch as jobs. Run the jobs in separate containers within Amazon ECS.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as AWS Batch helps running jobs optimally. It can run jobs in parallel, independently in a cost effective manner. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/batch/faqs/" target="_blank">AWS Batch</a> </p><p><em>AWS Batch is a set of batch management capabilities that enables developers, scientists, and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS. AWS Batch dynamically provisions the optimal quantity and type of compute resources (e.g., CPU or memory optimized instances) based on the volume and specific resource requirements of the batch jobs submitted. With AWS Batch, there is no need to install and manage batch computing software or server clusters, allowing you to instead focus on analyzing results and solving problems. AWS Batch plans, schedules, and executes your batch computing workloads using <a href="https://aws.amazon.com/ec2/" target="_blank">Amazon EC2</a> and <a href="https://aws.amazon.com/ec2/spot/">Spot Instances</a>.<br></em> </p><ul> <li><em>It can shift the time of job processing to periods when greater or less expensive capacity is available.</em></li> <li><em>It avoids idling compute resources with frequent manual intervention and supervision.</em></li> <li><em>It increases efficiency by driving higher utilization of compute resources. <br></em></li> <li><em>It enables the prioritization of jobs, aligning resource allocation with business objectives.</em></li> </ul><p><em>AWS Batch handles job execution and compute resource management, allowing you to focus on developing applications or analyzing results instead of setting up and managing infrastructure. If you are considering running or moving batch workloads to AWS, you should consider using AWS Batch.</em> </p><p><em>AWS Batch is optimized for batch computing and applications that scale through the execution of multiple jobs in parallel. Deep learning, genomics analysis, financial risk models, Monte Carlo simulations, animation rendering, media transcoding, image processing, and engineering simulations are all excellent examples of batch computing applications.</em><em></em><br> </p><p>Option B is wrong as Lambda is not suitable for long running jobs. Its maximum time allowed currently is 15 mins. </p><p>Option C is wrong as EC2 master with nodes is not a scalable cost effective architecture. Single Master would create dependency.<br> </p><p>Option D is wrong as ELB and EC2 workers are not ideal for batch kind of jobs.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121066">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 28 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249180"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> ABCD has developed a sensor intended to be placed inside of people's shoes, monitoring the number of steps taken every day. ABCD is expecting thousands of sensors reporting in every minute and hopes to scale to millions by the end of the year. A requirement for the project is it needs to be able to accept the data, run it through ETL to store in warehouse and archive it on Amazon Glacier, with room for a real-time dashboard for the sensor data to be added at a later date. What is the best method for architecting this application given the requirements? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use Amazon Cognito to accept the data when the user pairs the sensor to the phone, and then have Cognito send the data to Dynamodb. Use Data Pipeline to create a job that takes the DynamoDB tablee and sends it to an EMR cluster for ETL, then outputs to Redshift and S3 while, using S3 lifecycle policies to archive on Glacier.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Write the sensor data directly to a scaleable DynamoDB; create a data pipeline that starts an EMR cluster using data from DynamoDB and sends the data to S3 and Redshift.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Write the sensor data to Amazon S3 with a lifecycle policy for Glacier, create an EMR cluster that uses the bucket data and runs it through ETL. It then outputs that data into Redshift data warehouse.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Write the sensor data directly to Amazon Kinesis and output the data into Amazon S3 creating a lifecycle policy for Glacier archiving. Also, have a parallel processing application that runs the data through EMR and sends to a Redshift data warehouse. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Write the sensor data directly to Amazon Kinesis and output the data into Amazon S3 creating a lifecycle policy for Glacier archiving. Also, have a parallel processing application that runs the data through EMR and sends to a Redshift data warehouse.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as the requirement is real time data ingestion and analytics, the best option is to use Kinesis for storing the real time incoming data. The data can then be moved to S3 and analyzed using EMR and Redshift. Data can then be moved to Glacier for archival. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/streams/latest/dev/introduction.html" target="_blank">Kinesis</a> </p><p><em>Amazon Kinesis is a platform for streaming data on AWS, making it easy to load and analyze streaming data, and also providing the ability for you to build custom streaming data applications for specialized needs.</em> </p><ul> <li><em>Use Amazon Kinesis Streams to collect and process large streams of data records in real time.</em></li> </ul><p><em></em> </p><ul> <li><em>Use Amazon Kinesis Firehose to deliver real-time streaming data to destinations such as Amazon S3 and Amazon Redshift.<br></em></li> <li><em>Use Amazon Kinesis Analytics to process and analyze streaming data with standard SQL.</em></li> </ul><p>Option A is wrong as Cognito is not suitable for handling real time data<br> </p><p><em>Amazon Cognito lets you easily add user sign-up and sign-in and manage permissions for your mobile and web apps. You can create your own user directory within Amazon Cognito, or you can authenticate users through social identity providers such as Facebook, Twitter, or Amazon; with SAML identity solutions; or by using your own identity system. In addition, Amazon Cognito enables you to save data locally on users' devices, allowing your applications to work even when the devices are offline. You can then synchronize data across users' devices so that their app experience remains consistent regardless of the device they use.</em><em></em><br> </p><p>Option B is wrong as DynamoDB is not suitable for streaming data ingestion and handling.<br> </p><p>Option C is wrong as S3 is not an ideal solution to handle this huge amount of requests. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120532">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 29 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249181"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company has two departments. Both departments own several EC2 instances. Department A has a requirement to backup EBS volumes every 12 hours and the administrator has set up a Data Lifecycle Policy in DLM for their instances. Department B requires a similar Data Lifecycle Policy as well for their instances. However they prefer the schedule to run every 24 hours. The administrator has noticed that 2 EBS volumes are owned by both the departments at the same time. How can the administrator setup the Data Lifecycle Policy for the Department B?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Add a tag for EBS volumes that Department B has owned. Set up a Data Lifecycle Policy based on the tag. For the EBS volumes owned by two departments, snapshots will be taken every 12 hours and 24 hours</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Add a tag for EBS volumes that Department B has owned. Set up a Data Lifecycle Policy based on the tag. For the EBS volumes owned by two departments, snapshots will not be taken, as there is a schedule conflict between two policies. However other EBS volumes are not affected.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Add a tag for EBS volumes that Department B has owned. Set up a Data Lifecycle Policy based on the tag. For the EBS volumes owned by two departments, snapshots will be taken every 12 hours as 12 hours schedule takes priority<br><b>D</b>. <input type="radio" disabled="">&nbsp;Add a tag for EBS volumes that Department B has owned except the EBS volumes owned by two departments. Set up a Data Lifecycle Policy based on this tag. For the EBS volumes owned by two departments, snapshots are taken every 12 hours due to the policy of Department A <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Add a tag for EBS volumes that Department B has owned. Set up a Data Lifecycle Policy based on the tag. For the EBS volumes owned by two departments, snapshots will be taken every 12 hours and 24 hours<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as each volume needs to be tagged uniquely for the lifecycle policy to be followed. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html" target="_blank">EC2 Snapshot Lifecycle Policy</a> </p><p><em>Amazon DLM uses resource tags to identify the EBS volumes to back up. Tags are customizable metadata that you can assign to your AWS resources (including EBS volumes and snapshots). An Amazon DLM policy (described below) targets a volume for backup using a single unique tag. Multiple tags can be assigned to a volume if you want to run multiple policies on it.</em><em></em><br> </p><p><em>You can create multiple policies to back up an EBS volume, as long as each policy targets a unique tag on the volume. Target tags cannot be reused across policies, even disabled policies. If an EBS volume has two tags, where tag A is the target for policy A to create a snapshot every 12 hours, and tag B is the target for policy B to create a snapshot every 24 hours, Amazon DLM creates snapshots according to the schedules for both policies.<span class="redactor-invisible-space"><br></span></em> </p><p><span class="redactor-invisible-space"></span>Option B is wrong as there is no schedule conflict for this scenario. </p><p>Option C is wrong as there is no priority and both schedules can run in parallel. </p><p>Option D is wrong as the EBS volumes owned by two departments can add another tag and be included in the policy for Department B. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121832">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 30 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249182"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Repeated - You are designing a social media site and are considering how to mitigate distributed denial-of-service (DDoS) attacks. Which of the below are viable mitigation techniques? (Choose 3 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Add multiple elastic network interfaces (ENIs) to each EC2 instance to increase the network bandwidth.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use dedicated instances to ensure that each instance has the maximum performance possible.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use an Amazon CloudFront distribution for both static and dynamic content.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use an Elastic Load Balancer with auto scaling groups at the web app and Amazon Relational Database Service (RDS) tiers<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Add alert Amazon CloudWatch to look for high Network in and CPU utilization.<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Create processes and capabilities to quickly add and remove rules to the instance OS firewall. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use an Amazon CloudFront distribution for both static and dynamic content.<br><b>D</b>. Use an Elastic Load Balancer with auto scaling groups at the web app and Amazon Relational Database Service (RDS) tiers<br><b>E</b>. Add alert Amazon CloudWatch to look for high Network in and CPU utilization.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to understand AWS DDOS Mitigation techniques<br> </p><p>Correct answer are <strong>C, D &amp; E</strong> </p><p>Refer to the <a href="https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf" target="_blank">DDOS mitigation whitepaper</a> (Highly Recommended) which mentions <br> </p><pre>Minimize the Attack Surface Area
Be Ready to Scale and Absorb the Attack
Safeguard Exposed Resources
Learn Normal Behavior
Create a Plan for Attacks
</pre><p>Option C as CloudFront would scale and help absorb the attack. CloudFront also helps setup restrictions on accessibility like geo restrictions. </p><p>Option D as ELB with auto scaling would help scale and absorb the attack </p><p>Option E as you can learn normal behaviour and use CloudWatch to provide and configure alerts and actions when crossed </p><p>Option A is wrong as ENI do not help increase network bandwidth. </p><p>Refer AWS <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html" target="_blank">ENI</a> documentation </p><pre>Attaching another network interface to an instance (for example, 
a NIC teaming configuration) cannot be used as a method to increase or double 
the network bandwidth to or from the dual-homed instance.
</pre><p>Option B as using dedicated instances is more for compliance and security </p><p>Option F is not a recommended approach as well needs to automated and as the attack is more multiple IPs it would not help mitigate. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120250">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 31 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249183"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> If one needs to establish a low latency dedicated connection to an S3 public endpoint over the Direct Connect dedicated low Latency connection, what steps need to be taken to accomplish configuring a direct connection to a public S3 endpoint?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure a public virtual interface to connect to a public S3 endpoint resource.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Establish a VPN connection from the VPC to the public S3 endpoint.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Configure a private virtual interface to connect to the public S3 endpoint via the Direct Connect Connection.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Add a BGP route as part of the on-premise router; this will route S3 related traffic to the public S3 endpoint to dedicated AWS region. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Configure a public virtual interface to connect to a public S3 endpoint resource.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Refer to AWS <a href="http://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html" target="_blank">Direct Connect Working With Virtual Interfaces</a> </p><pre>You can create a private virtual interface to connect to your VPC, 
or you can create a public virtual interface to connect to AWS 
services that aren't in a VPC, such as Amazon S3 and Amazon Glacier
</pre><p>Correct answer is <strong>A</strong> as you would need to set up a Public Virtual Interface for public services like S3. </p><p>Option C is wrong as private virtual interface is required to access resources within an VPC. </p><p>Option B &amp; D are wrong as they would not help access S3 endpoint. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120402">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 32 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249184"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A web application runs on Amazon EC2 instances behind an ELB Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones. Data is stored in Amazon DynamoDB tables. The application records how many times each operation is invoked in a DynamoDB table, with each operation having a corresponding item containing an operation ID and a count of invocations. All application logs are streamed to Amazon CloudWatch Logs using the unified CloudWatch agent. During a recent audit, the number of GET requests recorded in the ELB access logs were much higher than the count of GET invocations in the DynamoDB table. While investigating this issue, a Solutions Architect enabled debug logging for the application and saw the following statements in the application log: 2018-11-03 11:20:20.23 DEBUG "Retrieved GET count: 23" 2018-11-03 11:20:20.26 DEBUG "Saved incremented GET count: 24" 2018-11-03 11:20:23.45 DEBUG "Retrieved GET count: 24" 2018-11-03 11:20:23.48 DEBUG "Saved incremented GET count: 25" 2018-11-03 11:20:27.56 DEBUG "Retrieved GET count: 25" 2018-11-03 11:20:27.57 DEBUG "Retrieved GET count: 25" 2018-11-03 11:20:27.59 DEBUG "Saved incremented GET count: 26" 2018-11-03 11:20:27.60 DEBUG "Saved incremented GET count: 26" 2018-11-03 11:20:30.43 DEBUG "Retrieved GET count: 26" 2018-11-03 11:20:30.46 DEBUG "Saved incremented GET count: 27" How should the Solutions Architect fix the application? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use consistent reads when the GetItem call retrieves the current count.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Increase the RCUs for the DynamoDB table.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Increase the WCUs for the DynamoDB table.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use conditional writes when the UpdateItem call saves the incremented count. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Use conditional writes when the UpdateItem call saves the incremented count.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as the application is overwriting the values and hence the count is less as compared to the ELB actual count. Conditional writes help enforce an update only if the underlying value has not changed. The operation can be retried again to reflect the correct value. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.ConditionalUpdate" target="_blank">DynamoDB Working with Items<em></em></a> </p><p><em>By default, the DynamoDB write operations (<code>PutItem</code>, <code>UpdateItem</code>, <code>DeleteItem</code>) are unconditional: each of these operations will overwrite an existing item that has the specified primary key.</em> </p><p><em>DynamoDB optionally supports conditional writes for these operations. A conditional write will succeed only if the item attributes meet one or more expected conditions. Otherwise, it returns an error. Conditional writes are helpful in many situations. For example, you might want a <code>PutItem</code> operation to succeed only if there is not already an item with the same primary key. Or you could prevent an <code>UpdateItem</code> operation from modifying an item if one of its attributes has a certain value.</em> </p><p>Option A is wrong as consistent reads would provide the latest value, however it does not guarantee the underlying value has changed before it is updated. </p><p>Options B &amp; C are wrong as RCU and WCU would increase the provisioned capacity to prevent throttling, which is not an issue. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121040">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 33 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249185"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A newspaper organization has an on-premises application which allows the public to search its back catalogue and retrieve individual newspaper pages via a website written in Java. They have scanned the old newspapers into JPEGs (approx. 17TB) and used Optical Character Recognition (OCR) to populate a commercial search product. The hosting platform and software is now end of life and the organization wants to migrate its archive to AWS and produce a cost efficient architecture and still be designed for availability and durability. Which is the most appropriate?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use S3 with One Zone - IA to store and serve the scanned files, install the commercial search application on EC2 Instances and configure with auto-scaling and an Elastic Load Balancer.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Model the environment using CloudFormation. Use an EC2 instance running Apache webserver and an open source search application, stripe multiple standard EBS volumes together to store the JPEGs and search index.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use S3 with standard redundancy to store and serve the scanned files, use CloudSearch for query processing, and use Elastic Beanstalk to host the website across multiple availability zones.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use a single-AZ RDS MySQL instance to store the search index and the JPEG images use an EC2 instance to serve the website and translate user queries into SQL.<br><b>E</b>. <input type="radio" disabled="">&nbsp;Use a CloudFront download distribution to serve the JPEGs to the end users and Install the current commercial search product, along with a Java Container for the website on EC2 instances and use Route53 with DNS round-robin. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use S3 with standard redundancy to store and serve the scanned files, use CloudSearch for query processing, and use Elastic Beanstalk to host the website across multiple availability zones.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is HA, durable and cost efficient architecture </p><p>Correct answer is <strong>C</strong> as S3 storage is cost effective &amp; durable, CloudSearch for Search and Highly available and durable web application using multi AZ Elastic Beanstalk </p><p>Option A is wrong as Reusing Commercial search application which is nearing end of life not a good option for cost as well S3 One Zone-IA is not durable </p><p>Option B is wrong as storing JPEGs on EBS volumes not cost effective. Single instance for Webserver and open source solution is not HA solution </p><p>Option D is wrong as MySQL not an ideal solution to store index and JPEG images for cost and performance. Single AZ does not provide HA </p><p>Option E is wrong as Web Application not scalable, whats the source for JPEGs files through CloudFront </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120264">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 34 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249186"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company has HQ in Tokyo and branch offices all over the world and is using logistics software with a multi-regional deployment on AWS in Japan, Europe and US .The logistic software has a 3-tier architecture and currently uses MySQL 5.6 for data persistence. Each region has deployed its own database. In the HQ region you run an hourly batch process reading data from every region to compute cross-regional reports that are sent by email to all offices this batch process must be completed as fast as possible to quickly optimize logistics how do you build the database architecture in order to meet the requirements?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;For each regional deployment, use RDS MySQL with a master in the region and a read replica in the HQ region</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;For each regional deployment, use MySQL on EC2 with a master in the region and send hourly EBS snapshots to the HQ region<br><b>C</b>. <input type="radio" disabled="">&nbsp;For each regional deployment, use RDS MySQL with a master in the region and send hourly RDS snapshots to the HQ region<br><b>D</b>. <input type="radio" disabled="">&nbsp;For each regional deployment, use MySQL on EC2 with a master in the region and use S3 to copy data files hourly to the HQ region<br><b>E</b>. <input type="radio" disabled="">&nbsp;Use Direct Connect to connect all regional MySQL deployments to the HQ region and reduce network latency for the batch process <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. For each regional deployment, use RDS MySQL with a master in the region and a read replica in the HQ region<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to support cross region reports with least time </p><p>Correct answer is <strong>A</strong> as you can create a <a href="https://aws.amazon.com/blogs/aws/cross-region-read-replicas-for-amazon-rds-for-mysql/" target="_blank">Cross Region Read replica</a> in the Tokyo HQ for DB in each region and use them to compute reports. </p><p>Option B, C &amp; D are wrong as it would take time for data, snapshots to be transferred and restored to perform the batch analysis </p><p>Option E is wrong as there Direct Connect would be expensive and take time to setup. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120380">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 35 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249187"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is running data application on-premise that requires large amounts of data to be transferred to a VPC containing EC2 instances in an AWS region. The company is concerned about the total overall transfer costs required for this application and is potentially not going to deploy a hybrid environment for the Customer-facing part of the application to run in a VPC. Given that the data transferred to AWS is new data every time, what suggestions could you make to the company to help reduce the overall cost of data transfer to AWS? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Provision a VPN connection between the on-premise data center and the AWS region using the VPN section of a VPC.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Suggest provisioning a Direct Connect connection between the on-premise data center and the AWS region.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Suggest using AWS import/export to transfer the TBs of data while synchronizing the new data as it arrives.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Suggest leaving the data required for the application on-premise and use a VPN to query the on-premise database data from EC2 when required. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Suggest provisioning a Direct Connect connection between the on-premise data center and the AWS region.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as Direct Connect can help reduce cost and provide a dedicated, predictable high performance data transfer route between VPC and the on-premise environment.<br> </p><p>Option A is wrong as although the VPN connection might keep cost low, but would not be preferred option due to the low speeds and unpredictability. </p><p>Option C is wrong as given that the data transferred to AWS is new data every time<span class="redactor-invisible-space">, <a href="https://aws.amazon.com/snowball/disk/" target="_blank">Import/Export</a> would not be an ideal option. As import/export is preferred mainly for first time data migration and using VPN/Direct Connect later on.</span><br> </p><p><span class="redactor-invisible-space"><em>If you have data you need to migrate into the AWS <a href="https://aws.amazon.com/what-is-cloud-computing/" adhocenable="false">cloud</a> for the first time, AWS Import/Export Disk is often much faster than transferring that data via the Internet.</em><span class="redactor-invisible-space"><em></em><br></span></span> </p><p>Option D is wrong as with the <span class="redactor-invisible-space">VPN the performance would be very poor.<br></span> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120439">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 36 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249188"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A marketing research company has developed a tracking system that collects user behavior during web marketing campaigns on behalf of their customers all over the world. The tracking system consists of an auto-scaled group of Amazon Elastic Compute Cloud (EC2) instances behind an elastic load balancer (ELB), and the collected data is stored in Amazon DynamoDB. After the campaign is terminated, the tracking system is torn down and the data is moved to Amazon Redshift, where it is aggregated, analyzed and used to generate detailed reports. The company wants to be able to instantiate new tracking systems in any region without any manual intervention and therefore adopted AWS CloudFormation. What needs to be done to make sure that the AWS CloudFormation template works in every AWS region? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;IAM users with the right to start AWS CloudFormation stacks must be defined for every target region.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;The names of the Amazon DynamoDB tables must be different in every target region.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use the built-in function of AWS CloudFormation to set the Availability Zone attribute of the ELB resource.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Avoid using DeletionPolicies for EBS snapshots.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use the built-in Mappings and FindInMap functions of AWS CloudFormation to refer to the AMI ID set in the ImageId attribute of the Auto Scaling::LaunchConfiguration resource. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use the built-in function of AWS CloudFormation to set the Availability Zone attribute of the ELB resource.<br><b>E</b>. Use the built-in Mappings and FindInMap functions of AWS CloudFormation to refer to the AMI ID set in the ImageId attribute of the Auto Scaling::LaunchConfiguration resource.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C &amp; E</strong><span class="redactor-invisible-space"> as An ELB may be assigned to either an AZ or a subnet (which just maps to an AZ anyway), however the ELB can route traffic to any AZ within its region. By assigning Fn::GetAZs to the CF ELB configuration you are telling it to do this.<span class="redactor-invisible-space"></span></span> </p><p><span class="redactor-invisible-space">Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/example-templates-autoscaling.html" target="_blank">CloudFormation Auto Scaling templates</a></span></p><pre>"ElasticLoadBalancer" : {
      "Type" : "AWS::ElasticLoadBalancing::LoadBalancer",
      "Properties" : {
        "AvailabilityZones" : { "Fn::GetAZs" : "" },
        "CrossZone" : "true",
        "Listeners" : [ {
          "LoadBalancerPort" : "80",
          "InstancePort" : "80",
          "Protocol" : "HTTP"
        } ],
        "HealthCheck" : {
          "Target" : "HTTP:80/",
          "HealthyThreshold" : "3",
          "UnhealthyThreshold" : "5",
          "Interval" : "30",
          "Timeout" : "5"
        }
      }
    }
</pre><pre>"Properties" : {
        "KeyName" : { "Ref" : "KeyName" },
        "ImageId" : { "Fn::FindInMap" : [ "AWSRegionArch2AMI", { "Ref" : "AWS::Region" },
                                          { "Fn::FindInMap" : [ "AWSInstanceType2Arch", { "Ref" : "InstanceType" }, "Arch" ] } ] },
        "SecurityGroups" : [ { "Ref" : "InstanceSecurityGroup" } ],
        "InstanceType" : { "Ref" : "InstanceType" },
        ......
      }
    },
</pre><p>Option A is wrong as IAM users are global </p><p>Option B is wrong as DynamoDB names should be unique only within a region </p><p>Option D is wrong as don’t want the data to be retained </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120557">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 37 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249189"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have configured consolidated billing for your organization with one Master account and 3 linked sub accounts. Your CFO has asked for Detailed Billing reports. What AWS feature can you use with detailed billing reports, which enables cost to be analyzed and decomposed across multiple dimensions and aggregation levels?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 11 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Cross-Account Access</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Web Identity Federation<br><b>C</b>. <input type="radio" disabled="">&nbsp;IAM Roles.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Resource Tagging // Billing Tags <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Resource Tagging // Billing Tags<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as Resource Tagging and Billing Tags help filter billing and cost to a detailed level. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/reportstagsresources.html" target="_blank">Billing Report with Resources and Tags</a> </p><p><em>The detailed billing report with resources and tags adds additional dimensions by which you can view your AWS charges. This report includes resource identifiers for many of the AWS services. Amazon EC2, for example, provides a ResourceID value for each Amazon EC2 instance that is run under your account. You can use this field for viewing your charges for each AWS resource, as well as for data filtering and aggregation.</em> </p><p><em>In addition, any cost allocation tags you have applied to your resources are appended to each line item in the report. You can filter or aggregate on these tags. For more information about creating these tags, see <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html">Using Cost Allocation Tags</a>. You are not required to create and use cost allocation tags to get the detailed billing report with resources and tags.</em> </p><p>Option A is wrong as cross-account access enables you to give users access across AWS accounts. </p><p>Option B is wrong as with web identity federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google, or any other OpenID Connect (OIDC)-compatible IdP.<br> </p><p>Option C is wrong as IAM <em>role</em> is an IAM identity that you can create in your account that has specific permissions. An IAM role is similar to an IAM user, in that it is an AWS identity with permission policies that determine what the identity can and cannot do in AWS. <br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121106">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 38 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249190"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company has been contracted to develop and operate a website that tracks NBA basketball statistics. Statistical data to derive reports like “best game-winning shots from the regular season” and more frequently built reports like “top shots of the game” need to be stored durably for repeated lookup. Leveraging social media techniques, NBA fans submit and vote on new report types from the existing data set so the system needs to accommodate variability in data queries and new static reports must be generated and posted daily. Initial research in the design phase indicates that there will be over 3 million report queries on game day by end users and other applications that use this application as a data source. It is expected that this system will gain in popularity over time and reach peaks of 10-15 million report queries of the system on game days. Select the answer that will allow your application to best meet these requirements while minimizing costs.<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 23 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Launch a multi-AZ MySQL Amazon Relational Database Service (RDS) Read Replica connected to your multi AZ master database and generate reports by querying the Read Replica. Perform a daily table cleanup.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Implement a multi-AZ MySQL RDS deployment and have the application generate reports from Amazon ElastiCache for in-memory performance results. Utilize the default expire parameter for items in the cache.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Generate reports from a multi-AZ MySQL Amazon RDS deployment and have an offline task put reports in Amazon Simple Storage Service (S3) and use CloudFront to cache the content. Use a TTL to expire objects daily.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Query a multi-AZ MySQL RDS instance and store the results in a DynamoDB table. Generate reports from the DynamoDB table. Remove stale tables daily. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Generate reports from a multi-AZ MySQL Amazon RDS deployment and have an offline task put reports in Amazon Simple Storage Service (S3) and use CloudFront to cache the content. Use a TTL to expire objects daily.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here to handle report queries on large scale at low cost. Store frequently built reports in durable storage for repeated reads. New static reports should be created and stored daily. </p><p>Correct answer is <strong>C</strong> to use Offline task to generate reports from MySQL, store reports in S3 storage and serve using CloudFront cache </p><p>Answer A is wrong as RDS would not be able to scale to queries as number of Read Replicas you can launch are limited. Also does not address serving mechanism </p><p>Answer B is wrong as ElastiCache would just help cache results from queries, but the reports still need to generated everytime increasing cost </p><p>Answer D is wrong as RDS with DynamoDB would increase cost as the read throughput required would be high. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120360">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 39 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249191"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing a multi-platform web application for AWS. The application will run on EC2 instances and will be accessed from PCs, tablets and smart phones. Supported accessing platforms are Windows, MACOS, IOS and Android. Separate sticky session and SSL certificate setups are required for different platform types. Which of the following describes the most cost effective and performance efficient architecture setup?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Setup a hybrid architecture to handle session state and SSL certificates on-prem and separate EC2 Instance groups running web applications for different platform types running in a VPC.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Set up one ELB for all platforms to distribute load among multiple instance under it Each EC2 instance implements ail functionality for a particular platform.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Set up two ELBs. The first ELB handles SSL certificates for all platforms and the second ELB handles session stickiness for all platforms for each ELB run separate EC2 instance groups to handle the web application for each platform.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Assign multiple ELBs to an EC2 instance or group of EC2 instances running the common components of the web application, one ELB for each platform type Session stickiness and SSL termination are done at the ELBs. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Assign multiple ELBs to an EC2 instance or group of EC2 instances running the common components of the web application, one ELB for each platform type Session stickiness and SSL termination are done at the ELBs. <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct Answer is <strong>D</strong> as Session stickiness requires HTTPS listener with SSL termination on the ELB and ELB does not support multiple SSL certs so one is required for each cert. SSL can be handled on the EC2 instances only with TCP configured ELB, ELB supports sticky sessions only in HTTP/HTTPS configurations. </p><p>Refer AWS Documentation for <a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html" target="_blank">ELB sticky sessions</a> </p><p>Option A is neither cost effective nor performant </p><p>Option B and C are wrong as ELB can't handle multiple SSL certs. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120180">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 40 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249192"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have been asked to design network connectivity between your existing data centers and AWS. Your application's EC2 instances must be able to connect to existing backend resources located in your data center. Network traffic between AWS and your data centers will start small, but ramp up to 10s of GB per second over the course of several months. The success of your application is dependent upon getting to market quickly. Which of the following design options will allow you to meet your objectives?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Quickly create an internal ELB for your backend applications, submit a DirectConnect request to provision a 1 Gbps cross connect between your data center and VPC, then increase the number or size of your DirectConnect connections as needed.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Allocate EIPs and an Internet Gateway for your VPC instances to use for quick, temporary access to your backend applications, and then provision a VPN connection between a VPC and existing on-premises equipment.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Provision a VPN connection between a VPC and existing on -premises equipment, submit a DirectConnect partner request to provision cross connects between your data center and the DirectConnect location, then cut over from the VPN connection to one or more DirectConnect connections as needed.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Quickly submit a DirectConnect request to provision a 1 Gbps cross connect between your data center and VPC, then increase the number or size of your DirectConnect connections as needed. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Provision a VPN connection between a VPC and existing on -premises equipment, submit a DirectConnect partner request to provision cross connects between your data center and the DirectConnect location, then cut over from the VPN connection to one or more DirectConnect connections as needed.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is time to market with security and then adding up speed </p><p>Correct answer is <strong>C</strong> as VPN provides a secure connection to start with and can be setup quickly. Direct Connect provisioning can start at the same time and once laid out can be cut over from VPN to DX </p><p>Option A is wrong as ELB will also not allow EC2 instances to connect to backend server but will only help load balance incoming traffic </p><p>Option B is wrong as it does not handle the future requirement of ramp up </p><p>Option D is wrong as it does not address the time to market requirement as Direct Connect takes time to setup </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120243">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 41 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249193"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Company B is launching a new game app for mobile devices. Users will log into the game using their existing social media account to streamline data capture. Company B would like to directly save player data and scoring information from the mobile app to a DynamoDB table named Score Data When a user saves their game the progress data will be stored to the Game state S3 bucket. what is the best approach for storing data to DynamoDB and S3?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use an EC2 Instance that is launched with an EC2 role providing access to the Score Data DynamoDB table and the GameState S3 bucket that communicates with the mobile app via web services.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use temporary security credentials that assume a role providing access to the Score Data DynamoDB table and the Game State S3 bucket using web identity federation.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use Login with Amazon allowing users to sign in with an Amazon account providing the mobile app with access to the Score Data DynamoDB table and the Game State S3 bucket.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use an IAM user with access credentials assigned a role providing access to the Score Data DynamoDB table and the Game State S3 bucket for distribution with the mobile app. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Use temporary security credentials that assume a role providing access to the Score Data DynamoDB table and the Game State S3 bucket using web identity federation.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is knowing <a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WIF.html" target="_blank">IAM Web Identity Federation</a> as it needs authentication using existing social media account and access to store in DynamoDB </p><p>Correct answer is <strong>B</strong> using IAM Role with Web Identity Federation to authenticate and get temporary credentials assuming role to access DynamoDB table </p><p><img src="./sap-03_files/wif-overview.png"><br><br> </p><p>Option A is wrong as you don't need an EC2 instance. Mobile app can authenticate and directly access AWS resources also creating a single point of failure. </p><p>Option C is wrong as using login with Amazon does not give access to AWS resources </p><p>Option D is wrong as using an IAM user with access credentials is not recommended </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120214">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 42 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249194"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company has just set up a new document server on its AWS VPC, and it has four very important clients that it wants to give access to. These clients also have VPCs on AWS and it is through these VPCs that they will be given accessibility to the document server. In addition, each of the clients should not have access to any of the other clients' VPCs. Choose the correct answer from the options below<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Set up VPC peering between your company's VPC and each of the clients' VPCs with a non overlapping CIDR block.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Set up VPC peering between your company's VPC and each of the clients' VPCs, but block the IPs from CIDR of the clients' VPCs to deny them access to each other.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Set up VPC peering between your company's VPC and each of the clients' VPC. Each client should have VPC peering set up between each other to speed up access time.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Set up all the VPCs with the same CIDR but have your company's VPC as a centralized VPC. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Set up VPC peering between your company's VPC and each of the clients' VPCs with a non overlapping CIDR block.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is Clients being able to access company VPC and should not be accessible to each other. </p><p>Correct answer is <strong>A</strong> as VPC peering would help Clients VPC connect to Company VPC. VPC peering is not transitive, meaning the communication happens only between the VPCs which are peered and cannot be routed to the other VPCs peered with the Company VPC. Also VPC CIDR block should not overlap. </p><p>Option B is wrong as VPC peering is not transitive hence there is no blocking required. </p><p>Option C is wrong as Clients VPC should not be peered. </p><p>Option D is wrong as it does not address the communication part as well as the CIDR block can't overlap </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120412">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 43 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249195"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A document storage company is deploying their application to AWS and changing their business model to support both free tier and premium tier users. The premium tier users will be allowed to store up to 200GB of data and free tier customers will be allowed to store only 5GB. The customer expects that billions of files will be stored. All users need to be alerted when approaching 75 percent quota utilization and again at 90 percent quota use. To support the free tier and premium tier users, how should they architect their application?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;The company should utilize an amazon simple workflow service activity worker that updates the users data counter in amazon dynamo DB. The activity worker will use simple email service to send an email if the counter increases above the appropriate thresholds.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;The company should deploy an amazon relational data base service relational database with a store objects table that has a row for each stored object along with size of each object. The upload server will query the aggregate consumption of the user in questions (by first determining the files store by the user, and then querying the stored objects table for respective file sizes) and send an email via amazon simple email service if the thresholds are breached.<br><b>C</b>. <input type="radio" disabled="">&nbsp;The company should write both the content length and the username of the files owner as S3 metadata for the object. They should then create a file watcher to iterate over each object and aggregate the size for each user and send a notification via amazon simple queue service to an emailing service if the storage threshold is exceeded.<br><b>D</b>. <input type="radio" disabled="">&nbsp;The company should create two separated amazon simple storage service buckets one for data storage for free tier users and another for data storage for premium tier users. An amazon simple workflow service activity worker will query all objects for a given user based on the bucket the data is stored in and aggregate storage. The activity worker will notify the user via amazon simple Notification Service when necessary <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. The company should utilize an amazon simple workflow service activity worker that updates the users data counter in amazon dynamo DB. The activity worker will use simple email service to send an email if the counter increases above the appropriate thresholds.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as Maintaining the counter incrementally as the event happens would be more performance with sending email using SES. </p><p>Option B might not be a scalable and performant approach with so many objects and the querying process might not be a good option </p><p>Option C is not feasible as <a href="http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketGET.html" target="_blank">List operations</a> on S3 will return limited data and would take time </p><p>Option D is not feasible as well List operations on S3 not feasible as well as SNS does not address email requirement </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120185">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 44 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249196"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your solutions architect has asked you to submit an analysis report to help decide between EFS and S3 as a distributed storage options for the new mobile application. The application will accept images and videos from the mobile app and will store, enhance, watermark and deliver to other users. As per the initial research, it seems the EFS will be a suitable option as the application will be running behind a load balancer and the file system will be shared among the instances so that the data can be delivered fast. They have decided to use the CloudFront before the load balancer to geocache the contents and serve it faster. Under what circumstances EFS will not be best suitable for the current application design? (Select TWO)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;EFS is not redundant and will require periodic backup to ensure no data is at a loss</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Your application will have to handle all the upload/download processing<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Encryption in transit and at the storage level is not available. So in future, if your application needs encryption, EFS will not the right choice.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;EFS performance is dependent on storage size, under heavy load, EFS may start to throttle unexpectedly <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Encryption in transit and at the storage level is not available. So in future, if your application needs encryption, EFS will not the right choice.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B &amp; D</strong> </p><p>Option B as the data is stored in EFS, the application needs to handle the upload and download. </p><p>Option D as the EFS performance depends upon the storage size with the bursting throughput mode. If the demand increases the requests would be throttled. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/efs/latest/ug/performance.html#throughput-modes" target="_blank">EFS Performance</a> </p><p><em>There are two throughput modes to choose from for your file system, Bursting Throughput and Provisioned Throughput. With Bursting Throughput mode, throughput on Amazon EFS scales as the size of your file system in the standard storage class grows.</em><em></em><br> </p><p>Option A is wrong as EFS data is redundantly stored in multiple AZs. </p><p><em>Every file system object (i.e. directory, file, and link) is redundantly stored across multiple Availability Zones. In addition, a file system can be accessed concurrently from all Availability Zones in the region where it is located, which means that you can architect your application to failover from one AZ to other AZs in the region in order to ensure the highest level of application availability. Mount targets themselves are designed to be highly available.</em> </p><p>Option C is wrong as EFS offers both encryption at rest and in transit. </p><p><em>Amazon EFS offers the ability to encrypt data at rest and in transit.</em> </p><p><em>Data encrypted at rest is transparently encrypted while being written, and transparently decrypted while being read, so you don’t have to modify your applications. Encryption keys are managed by the AWS Key Management Service (KMS), eliminating the need to build and maintain a secure key management infrastructure.</em> </p><p><em>Data encryption in transit uses industry standard Transport Layer Security (TLS) 1.2 to encrypt data sent between your clients and EFS file systems.</em> </p><p><em>Encryption of data at rest and of data in transit can be configured together or separately to help meet your unique security requirements.</em> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120767">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 45 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249197"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have been asked to perform a cost review on an AWS environment. The environment contains a mixture of resources managed manually and those created by CloudFormation, OpsWorks and Elastic Beanstalk - as well as various lambda functions. Which of the following should you look to delete to save the organisation costs without impacting any active resources? (Select TWO)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Delete CloudFormation stacks, they are no longer required when the resources have been created.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Any unallocated Elastic IP addresses<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Delete any inactive Auto Scaling groups and launch templates<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Delete any EBS volumes which aren't attached to active instances after confirming they are not required. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Any unallocated Elastic IP addresses<br><b>D</b>. Delete any EBS volumes which aren't attached to active instances after confirming they are not required.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B &amp; D</strong> </p><p>Option B as you are charged for reserved Elastic IPs addresses which are not associated with any instance </p><p>Option D as you are charged for EBS volumes irrespective whether they are attached to instances or not. </p><p>Option A is wrong as CloudFormation stacks represent the resources and if deleted would remove the resources </p><p>Option C is wrong as Auto Scaling groups and templates are static resources and do no cost. The cost is for the underlying resources. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121149">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 46 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249198"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company has a legacy employee verification product, which exists for many years. The system has used some old facial recognition technologies by comparing new photos with original ones in a large file system to verify employees. It is becoming harder to maintain the system as all architects of the product have left and technical documents are not well maintained. The company decides to migrate the system to AWS and use some new technologies if possible. However they do not want to spend huge efforts on the migration and hope to finish it as soon as possible. Which option is the best for the company to choose with a reasonable cost?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Utilize a popular facial recognition service that has used new biometric matching technology. Put the application in EC2 to handle with the facial recognition tasks. Also migrate the on-premise file system to S3.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use Rekognition CLI to develop an application to use AWS Rekognition facial analysis service. For example, aws rekognition detect-faces is able to return a JSON response that contains information for each detected face. It can also compare faces to see if they match<br><b>C</b>. <input type="radio" disabled="">&nbsp;Utilize a modern facial recognition SAAS. Put the application in EC2 or lambda to communicate with the SAAS service provider. Also migrate the on-premise file system to RDS. Make sure that the SAAS provider has the access to RDS.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Transform all source or target pictures to base64-encoded bytes. Use Rekognition CLI to compare faces such as aws rekognition compare-faces by using the pictures with the format of image bytes. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Use Rekognition CLI to develop an application to use AWS Rekognition facial analysis service. For example, aws rekognition detect-faces is able to return a JSON response that contains information for each detected face. It can also compare faces to see if they match<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is B as Rekognition can provide Out Of Box facial recognition and comparison abilities at a reasonable cost. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/rekognition/" target="_blank">Rekognition</a> </p><p><em>Amazon Rekognition makes it easy to add image and video analysis to your applications. You just provide an image or video to the Rekognition API, and the service can identify the objects, people, text, scenes, and activities, as well as detect any inappropriate content. Amazon Rekognition also provides highly accurate facial analysis and facial recognition on images and video that you provide. You can detect, analyze, and compare faces for a wide variety of user verification, people counting, and public safety use cases.<br></em> </p><p><em>Amazon Rekognition is based on the same proven, highly scalable, deep learning technology developed by Amazon’s computer vision scientists to analyze billions of images and videos daily, and requires no machine learning expertise to use. Amazon Rekognition is a simple and easy to use API that can quickly analyze any image or video file stored in Amazon S3. Amazon Rekognition is always learning from new data, and we are continually adding new labels and facial recognition features to the service.</em> </p><p>Option A is wrong as the price will be higher than Rekognition, as it is pay as you use service. </p><p>Option C is wrong as the cost would be higher and RDS is not an ideal storage option for photos.<br> </p><p>Option D is wrong as Rekogniation only supports S3 as its source and target. <em>“If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes isn't supported. The image must be formatted as a PNG or JPEG file.”</em> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120583">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 47 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249199"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are responsible for a legacy web application whose server environment is approaching end of life You would like to migrate this application to AWS as quickly as possible, since the application environment currently has the following limitations: The VM’s single 10GB VMDK is almost full. The virtual network interface still uses the 10Mbps driver, which leaves your 100Mbps WAN connection completely underutilized. It is currently running on a highly customized Windows VM within a VMware environment: You do not have the installation media. This is a mission critical application with an RTO (Recovery Time Objective) of 8 hours. RPO (Recovery Point Objective) of 1 hour. How could you best migrate this application to AWS while meeting your business continuity requirements?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use the EC2 VM Import Connector for vCenter to import the VM into EC2</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use Import/Export to import the VM as an EBS snapshot and attach to EC2.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use S3 to create a backup of the VM and restore the data into EC2.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use the ec2-bundle-instance API to Import an Image of the VM into EC2 <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Use the EC2 VM Import Connector for vCenter to import the VM into EC2<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> to use the VM Import connector for vCenter to import the VM. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/ec2/vm-import/" target="_blank">EC2 VM Import</a></p><p><em>VM Import/Export enables you to easily import virtual machine images from your existing environment to Amazon EC2 instances and export them back to your on-premises environment. This offering allows you to leverage your existing investments in the virtual machines that you have built to meet your IT security, configuration management, and compliance requirements by bringing those virtual machines into Amazon EC2 as ready-to-use instances. You can also export imported instances back to your on-premises virtualization infrastructure, allowing you to deploy workloads across your IT infrastructure.</em></p><p><em>VM Import/Export is available at no additional charge beyond standard usage charges for Amazon EC2 and Amazon S3.</em></p><p><em>To import your images, use the AWS CLI or other developer tools to import a virtual machine (VM) image from your VMware environment. If you use the VMware vSphere virtualization platform, you can also use the AWS Management Portal for vCenter to import your VM. As part of the import process, VM Import will convert your VM into an Amazon EC2 AMI, which you can use to run Amazon EC2 instances. Once your VM has been imported, you can take advantage of Amazon’s elasticity, scalability and monitoring via offerings like Auto Scaling, Elastic Load Balancing and CloudWatch to support your imported images.<br></em></p><p>Option B is wrong as Import/Export is used to transfer large amount of data </p><p>Option C is wrong as using S3 will not take </p><p>Option D is wrong as it only bundles an windows instance store instance </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120191">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 48 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249200"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your team is excited about the use of AWS because now they have access to programmable infrastructure. You have been asked to manage your AWS infrastructure in a manner similar to the way you might manage application code. You want to be able to deploy exact copies of different versions of your infrastructure, stage changes into different environments, revert back to previous versions, and identify what versions are running at any particular time (development, test, QA, production). Which approach addresses this requirement?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use cost allocation reports and AWS OpsWorks to deploy and manage your infrastructure.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use AWS CloudWatch metrics and alerts along with resource tagging to deploy and manage your infrastructure.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use AWS Beanstalk and a version control system like GIT to deploy and manage your infrastructure.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use AWS CloudFormation and a version control system like GIT to deploy and manage your infrastructure. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Use AWS CloudFormation and a version control system like GIT to deploy and manage your infrastructure.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as CloudFormation can be used to maintain application as well infrastructure and using GIT for version control to track changes. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html" target="_blank">CloudFormation</a> </p><p><em>When you provision your infrastructure with AWS CloudFormation, the AWS CloudFormation template describes exactly what resources are provisioned and their settings. Because these templates are text files, you simply track differences in your templates to track changes to your infrastructure, similar to the way developers control revisions to source code. For example, you can use a version control system with your templates so that you know exactly what changes were made, who made them, and when. If at any point you need to reverse changes to your infrastructure, you can use a previous version of your template.</em> </p><p>Option A is wrong as OpsWorks would work but need version control which cost allocation reports does not provide.<br> </p><p>Option B is wrong as CloudWatch is more for monitoring and tagging does not help in deployment but just identification.<br> </p><p>Option C is wrong as Elastic Beanstalk will not help maintain infrastructure.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120547">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 49 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249201"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company plans to deploy a database server cluster in AWS. The database cluster requires near-real-time replication between nodes. The built-in cluster technology requires: Minimum network latency between nodes Maximum network throughput Which solution meets the performance requirements for the database cluster? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Launch Amazon EC2 instances that have enhanced networking enabled using the Elastic Network Adapter (ENA). Launch all instances in a spread placement group.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Launch network-optimized Amazon EC2 instances that have jumbo frames enabled. Launch the instances in the same Availability Zone.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Launch Amazon EC2 instances that have enhanced networking enabled using the Elastic Network Adapter (ENA). Launch all the instances in a cluster placement group and enable jumbo frame support.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Launch Amazon EC2 instances that have multiple network interfaces. Launch all the instances in a cluster placement group and enable jumbo frame support. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Launch Amazon EC2 instances that have enhanced networking enabled using the Elastic Network Adapter (ENA). Launch all the instances in a cluster placement group and enable jumbo frame support.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as Enhanced Networking with ENA and Cluster Placement Groups provide low latency and maximum throughput. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html#placement-groups-cluster" target="_blank">Cluster Placement Groups</a> &amp; <a href="https://aws.amazon.com/premiumsupport/knowledge-center/enable-configure-enhanced-networking/" target="_blank">Enhanced Networking</a> </p><p><em>A cluster placement group is a logical grouping of instances within a single Availability Zone. A placement group can span peered VPCs in the same Region. The chief benefit of a cluster placement group, in addition to a 10 Gbps flow limit, is the non-blocking, non-oversubscribed, fully bi-sectional nature of the connectivity. In other words, all nodes within the placement group can talk to all other nodes within the placement group at the full line rate of 10 Gbps flows and 25 aggregate without any slowing due to over-subscription.</em><br> </p><p><em>Cluster placement groups are recommended for applications that benefit from low network latency, high network throughput, or both, and if the majority of the network traffic is between the instances in the group. To provide the lowest latency and the highest packet-per-second network performance for your placement group, choose an instance type that supports enhanced networking. </em><br> </p><p><em>Placement groups are recommended for applications that benefit from low network latency, high network throughput, or both. To provide the lowest latency and the highest packet-per-second network performance for your instances, consider using a placement group.</em> </p><p><em>If you need to reach speeds up to 10 Gbps between instances, you should launch your instances into a placement group with the enhanced networking instance type.</em> </p><p><em>If you need to reach speeds up to 25 Gbps between instances, you should launch instances in a placement group with ENA.</em> </p><p>Option A is wrong as Spread placement group does not help provide low latency, it is a group of instances that are each placed on distinct racks, with each rack having its own network and power source. </p><p>Option B is wrong as same AZ does not guarantee provide the 10 Gbps flow between the instances. </p><p>Option D is wrong as you need to use Enhanced Networking with Cluster Placement group to provide maximum throughput. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121097">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 50 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249202"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is building a voting system for a popular TV show, viewers would watch the performances then visit the show’s website to vote for their favorite performer. It is expected that in a short period of time after the show has finished the site will receive millions of visitors. The visitors will first login to the site using their Amazon.com credentials and then submit their vote. After the voting is completed the page will display the vote totals. The company needs to build the site such that can handle the rapid influx of traffic while maintaining good performance but also wants to keep costs to a minimum. Which of the design patterns below should they use?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use CloudFront and an Elastic Load balancer in front of an auto-scaled set of web servers, the web servers will first can the Login With Amazon service to authenticate the user then process the users vote and store the result into a multi-AZ Relational Database Service instance.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use CloudFront and the static website hosting feature of S3 with the Javascript SDK to call the Login With Amazon service to authenticate the user, use IAM Roles to gain permissions to a DynamoDB table to store the users vote.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use CloudFront and an Elastic Load Balancer in front of an auto-scaled set of web servers, the web servers will first call the Login with Amazon service to authenticate the user, the web servers will process the users vote and store the result into a DynamoDB table using IAM Roles for EC2 instances to gain permissions to the DynamoDB table.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use CloudFront and an Elastic Load Balancer in front of an auto-scaled set of web servers, the web servers will first call the Login. With Amazon service to authenticate the user, the web servers would process the users vote and store the result into an SQS queue using IAM Roles for EC2 Instances to gain permissions to the SQS queue. A set of application servers will then retrieve the items from the queue and store the result into a DynamoDB table <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Use CloudFront and an Elastic Load Balancer in front of an auto-scaled set of web servers, the web servers will first call the Login. With Amazon service to authenticate the user, the web servers would process the users vote and store the result into an SQS queue using IAM Roles for EC2 Instances to gain permissions to the SQS queue. A set of application servers will then retrieve the items from the queue and store the result into a DynamoDB table<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> - use SQS to decouple the architecture to reduce the throughput on DynamoDB to maintain better performance as well as keep the cost low. Use auto scaling to scale on demand </p><p>The key here is - As the cost needs to be kept minimum while maintaining good performance. </p><p>Option A is wrong as multi AZ RDS would increase the cost as well as the performance would not be better. DynamoDB would be a better alternative </p><p>Option B is wrong as Direct interaction with DynamoDB would require a very high throughput and hence the cost will be high. Although Javascript sdk can handle the web identity federation. </p><p>Option C is wrong as again there is a Direct interaction with DynamoDB would require a very high throughput and hence the cost will be high </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120196">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 51 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249203"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An enterprise wants to use a third-party SaaS application. The SaaS application needs to have access to issue several API commands to discover Amazon EC2 resources running within the enterprise’s account. The enterprise has internal security policies that require any outside access to their environment must conform to the principles of least privilege and there must be controls in place to ensure that the credentials used by the SaaS vendor cannot be used by any other third party. Which of the following would meet all of these conditions?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;From the AWS Management Console, navigate to the Security Credentials page and retrieve the access and secret key for your account.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create an IAM user within the enterprise account assign a user policy to the IAM user that allows only the actions required by the SaaS application create a new access and secret key for the user and provide these credentials to the SaaS provider.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an IAM role for cross-account access allows the SaaS provider’s account to assume the role and assign it a policy that allows only the actions required by the SaaS application<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an IAM role for EC2 instances, assign it a policy that allows only the actions required tor the SaaS application to work, provide the role ARN to the SaaS provider to use when launching their application instances. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create an IAM role for cross-account access allows the SaaS provider’s account to assume the role and assign it a policy that allows only the actions required by the SaaS application<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is understand <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html" target="_blank">IAM best practices</a> of IAM Role and least privilege </p><p>Correct answer is C as you need to create a <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html" target="_blank">cross account access using IAM role</a> with only the required permissions </p><p>Option A &amp; B are wrong as using access and secret key is not a best practice </p><p>Option D is wrong as an IAM role for EC2 instances can only be assumed by EC2 instances. SaaS application need a role to be able to discover EC2 resources and even to launch EC2 instances </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120207">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 52 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249204"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A customer's nightly EMR job processes a single 2-TB data file stored on Amazon Simple Storage Service (S3). The Amazon Elastic Map Reduce (EMR) job runs on two On-Demand core nodes and three On-Demand task nodes. Which of the following may help reduce the EMbR job completion time? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Use three Spot Instances rather than three On-Demand instances for the task nodes.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Change the input split size in the MapReduce job configuration.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use a bootstrap action to present the S3 bucket as a local filesystem.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Launch the core nodes and task nodes within an Amazon Virtual Cloud.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Adjust the number of simultaneous mapper tasks.<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Enable termination protection for the job flow. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Change the input split size in the MapReduce job configuration.<br><b>E</b>. Adjust the number of simultaneous mapper tasks.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to reduce job completion time. </p><p>Refer to <a href="https://d0.awsstatic.com/whitepapers/aws-amazon-emr-best-practices.pdf" target="_blank">EMR Best Practices</a> </p><p>Correct answer is <strong>B &amp; E</strong> </p><p>Option B as the split size of the match in memory block size of task and HDFS files will help to complete the job faster. </p><p>Option E as adjusting and tuning the number of simultaneous mapper task would help reduce time </p><p>Option A is wrong as Spot instances would help reduce cost but might increase the job completion time </p><p>Option C is wrong as it would not help as the data is already there in the data nodes. </p><p>Option D is wrong as the instances would be in VPC already and would not improve job times </p><p>Option E is wrong as termination protection would not help as the instances are not being terminated adhoc </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120257">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 53 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249205"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A 3-tier e-commerce web application is current deployed on-premises and will be migrated to AWS for greater scalability and elasticity. The web server currently shares read-only data using a network distributed file system. The app server tier uses a clustering mechanism for discovery and shared session state that depends on IP multicast The database tier uses shared-storage clustering to provide database fail over capability, and uses several read slaves for scaling. Data on all servers and the distributed file system directory is backed up weekly to off-site tapes. Which AWS storage and database architecture meets the requirements of the application?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Web servers store read-only data in S3, and copy from S3 to root volume at boot time. App servers share state using a combination of DynamoDB and IP unicast. Database use RDS with multi-AZ deployment and one or more Read Replicas. Backup web and app servers backed up weekly via AMIs, database backed up via DB snapshots.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Web servers store read-only data in S3, and copy from S3 to root volume at boot time. App servers share state using a combination of DynamoDB and IP unicast. Database use RDS with multi-AZ deployment and one or more Read replicas. Backup web servers app servers, and database backed up weekly to Glacier using snapshots<br><b>C</b>. <input type="radio" disabled="">&nbsp;Web servers store read-only data In S3 and copy from S3 to root volume at boot time. App servers share state using a combination of DynamoDB and IP unicast. Database use RDS with multi-AZ deployment Backup web and app servers backed up weekly via AMIs. Database backed up via DB snapshots<br><b>D</b>. <input type="radio" disabled="">&nbsp;Web servers, store read-only data in an EC2 NFS server, mount to each web server at boot time App servers share state using a combination of DynamoDB and IP multicast Database use RDS with multi-AZ deployment and one or more Read Replicas Backup web and app servers backed up weekly via AMIs database backed up via DB snapshots <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Web servers store read-only data in S3, and copy from S3 to root volume at boot time. App servers share state using a combination of DynamoDB and IP unicast. Database use RDS with multi-AZ deployment and one or more Read Replicas. Backup web and app servers backed up weekly via AMIs, database backed up via DB snapshots.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key is to have mapping solution for read only data, shared session data, database with failover capability, read slaves and back up with off-site tapes. </p><p>Correct answer is <strong>A</strong> to use S3 for read only data and load during boot time. Session data using DynamoDB and IP unicast. RDS with Multi-AZ and Read Replicas and back ups using AMIs and DB snapshots. </p><p>Option B is wrong as Snapshots to Glacier don’t work directly with EBS snapshots </p><p>Option C is wrong as Read replicas are needed, in replacement for read slaves, for scalability and elasticity. </p><p>Option D is wrong as AWS does not support multicast </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120202">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 54 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249206"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is developing a video application that will emit a log stream. Each record in the stream may contain up to 400 KB of data. To improve the video-streaming experience, it is necessary to collect a subset of metrics from the stream to be analyzed for trends over time using complex SQL queries. A Solutions Architect will create a solution that allows the application to scale without customer interaction. Which solution should the Solutions Architect implement to meet these requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Send the log data to an Amazon Kinesis Data Firehose delivery stream. Use an AWS Lambda function to transform the data. Deliver the data to Amazon Redshift. Query the data in Amazon Redshift.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Send the log data to an Amazon SQS standard queue. Make the queue an event source for an AWS Lambda function that transforms the data and stores it in Amazon Redshift. Query the data in Amazon Redshift.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Send the log data to an Amazon CloudWatch Logs log group. Make the log group an event source for an AWS Lambda function that transforms the data and stores it in an Amazon S3 bucket. Query the data with Amazon Athena.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Send the log data to an Amazon Kinesis data stream. Subscribe an AWS Lambda function to the stream that transforms the data and sends it to a second data stream. Use Amazon Kinesis Data Analytics to query the data in the second stream. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Send the log data to an Amazon Kinesis data stream. Subscribe an AWS Lambda function to the stream that transforms the data and sends it to a second data stream. Use Amazon Kinesis Data Analytics to query the data in the second stream.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as the data can be captured using Kinesis Data Stream and Kinesis Data Analytics can be used to query on the streaming data using time or window queries to generate trend analysis.</p><p>Refer AWS documentation - <a href="https://aws.amazon.com/solutions/streaming-analytics-pipeline/" target="_blank">Streaming Analytics Pipeline</a></p><p><em>Many Amazon Web Services (AWS) customers use <a href="https://aws.amazon.com/streaming-data/" target="_blank">streaming data</a> to gain real-time insight into customer activity and immediate business trends. Streaming data, which is generated continuously from thousands of data sources, includes a wide variety of data such as log files from your mobile or web applications, e-commerce purchases, in-game player activity, information from social networks, financial trading floors, or geospatial services, and telemetry from connected devices. This data can help companies make well-informed decisions and proactively respond to changing business conditions.</em></p><p><em><a href="https://aws.amazon.com/kinesis/" target="_blank">Amazon Kinesis</a>, a platform for streaming data on AWS, offers powerful services that make it easier to build data processing applications, load massive volumes of streaming data, and analyze it in real time.</em></p><p><img src="./sap-03_files/real-time-web-analytics-with-kinesis-architecture.2f7f348cf627d65c5eb29d0548524e9b8be028b2.png"><br><br></p><p>Options A, B &amp; C are wrong as they do not provide analytics on streaming data.</p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121082">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 55 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249207"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company has multiple different AWS accounts for their IT departments and want to leverage a single central identity validation solution. How can they connect to a central VPC for identity validation? How would you best design this solution?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Migrate each VPC resources to the Central VPC using migration tools such as Import/Export, Snapshot, AMI Copy, and S3 sharing.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a VPC peering connection with the central VPC.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a Direct Connect connection from each VPC endpoint to the central VPC.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an OpenVPN instance in central VPC and establish an IPSec tunnel between VPCs. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create a VPC peering connection with the central VPC.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Refer to the <a href="http://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/peering-configurations-partial-access.html#one-to-two-vpcs-specific-subnets" target="_blank">AWS VPC Peering Scenario</a><br> </p><p>Correct answer is <strong>B</strong> as <strong></strong>VPC peering connection can be set between your VPCs, or between a VPC that you own and a VPC in a different AWS account </p><p>You can have a central VPC that is used for Active Directory services. Specific instances in peer VPCs send requests to the Active Directory servers and require full access to the central VPC. The central VPC does not require full access to the peer VPCs; it only needs to route response traffic to the specific instances. </p><p><img src="./sap-03_files/one-to-two-vpcs-specific-subnets-diagram.png"><br>Option A is not a scalable solution as well it does not help in segregation. </p><p>Option C &amp; D are wrong as Direct Connection and VPN connections are better suited for connectivity between VPC and On-premises data center</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/peering-configurations-partial-access.html#one-to-two-vpcs-specific-subnets" target="_blank"></a> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120407">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="col-sm-12 well"><h4 class="sm" style="color:#333;">14/55 Questions right</h4></div></div><style type="text/css">
span.label.label-danger,span.label.label-success {
    padding: .2em .6em .3em;
}
.saved{color:red; }
.question_info{
  margin-bottom: 40px;
  border: solid 1px #ccc;
  border-radius: 5px;
  overflow: hidden;
}
.question_no {
    background: #f4f4f4;
    padding: 0 15px;
    line-height: 40px;
    border-bottom: solid 1px #ccc;
}

.question_detail {
    padding: 10px;
}
.hide{
  display: none;
}
input[type="radio"]{
  -webkit-appearance: radio;
}
input[type="checkbox"]{
  -webkit-appearance: checkbox;
}
span.bgcolor {
    background: yellow;
    padding: 5px;
    margin-left: -5px;
}
</style><link href="./sap-03_files/mcoursestyle.css" rel="stylesheet"></div> <script type="text/javascript" src="./sap-03_files/bc-course.min_031117.js.下载"></script> <div class="overlayForm" style=""></div></div></div></div></div></div><div class="overlayForm"></div></div><iframe style="position:absolute;left:-999px;top:-999px;visibility:hidden" src="./sap-03_files/saved_resource.html"></iframe><iframe style="display: none; visibility: hidden;" src="./sap-03_files/saved_resource(1).html"></iframe><iframe style="display: none; visibility: hidden;" src="./sap-03_files/saved_resource(2).html"></iframe></body></html>