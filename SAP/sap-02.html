<!DOCTYPE html>
<!-- saved from url=(0112)https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215 -->
<html xmlns:fb="http://ogp.me/ns/fb#" lang="en-gb" dir="ltr" class="secondary-14px wf-proximanova-n7-active wf-proximanova-i7-active wf-proximanova-n4-active wf-raleway-n1-active wf-raleway-n7-active wf-raleway-n4-active wf-raleway-n5-active wf-raleway-n3-active wf-raleway-n8-active wf-raleway-n9-active wf-raleway-n2-active wf-raleway-n6-active wf-proximanova-i4-active wf-active"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><meta name="format-detection" content="telephone=no"><script type="text/javascript" src="./sap-02_files/pageload"></script><script type="text/javascript" src="./sap-02_files/display.js.下载"></script><script type="text/javascript" src="./sap-02_files/pro"></script><script type="text/javascript" src="./sap-02_files/l.js.下载"></script><script type="text/javascript" src="./sap-02_files/l.js(1).下载"></script><script type="text/javascript" src="./sap-02_files/l.js(2).下载"></script><script type="text/javascript" src="./sap-02_files/l.js(3).下载"></script><script type="text/javascript" async="" src="./sap-02_files/atatus.js.下载"></script><script type="text/javascript" async="" src="./sap-02_files/analytics.js.下载"></script><script src="./sap-02_files/fMy5LNtdDqis6adCpEbCXQHA47I.js.下载"></script><script src="./sap-02_files/js"></script><link rel="canonical" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215"><link rel="stylesheet" type="text/css" href="./sap-02_files/bc-course.min_092917.css"><link rel="stylesheet" type="text/css" href="./sap-02_files/bc-style-092917.css"><!--[if lt IE 9]> <script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script> <script src="//css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script> <![endif]--><link rel="shortcut icon" href="https://www.braincert.com/images/favicon.ico"> <script type="text/javascript" src="./sap-02_files/jquery-1.11.0.min.js.下载"></script> <script type="text/javascript">jQuery.noConflict();</script> <script type="application/javascript" src="./sap-02_files/fVBYAHUg.js.下载"></script><script type="text/javascript" src="./sap-02_files/ga.js.下载"></script> <script type="text/javascript">jwplayer.key="Kfk7MAHVl4Y33jPduQlHwUdmLu+1l6cvPHVklw==";</script> <script src="./sap-02_files/jdk4nqa.js.下载"></script> <style type="text/css">.tk-proxima-nova{font-family:"proxima-nova",sans-serif;}.tk-raleway{font-family:"raleway",sans-serif;}</style><style type="text/css">@font-face{font-family:tk-proxima-nova-n7;src:url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:tk-proxima-nova-i7;src:url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-weight:700;font-style:italic;}@font-face{font-family:tk-proxima-nova-n4;src:url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:tk-proxima-nova-i4;src:url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-weight:400;font-style:italic;}@font-face{font-family:tk-raleway-n1;src:url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff2"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("opentype");font-weight:100;font-style:normal;}@font-face{font-family:tk-raleway-n7;src:url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:tk-raleway-n4;src:url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:tk-raleway-n5;src:url(https://use.typekit.net/af/145edc/000000000000000000013289/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}@font-face{font-family:tk-raleway-n3;src:url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff2"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("opentype");font-weight:300;font-style:normal;}@font-face{font-family:tk-raleway-n8;src:url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff2"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("opentype");font-weight:800;font-style:normal;}@font-face{font-family:tk-raleway-n9;src:url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff2"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("opentype");font-weight:900;font-style:normal;}@font-face{font-family:tk-raleway-n2;src:url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff2"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("opentype");font-weight:200;font-style:normal;}@font-face{font-family:tk-raleway-n6;src:url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-weight:600;font-style:normal;}</style><script>try{Typekit.load({ async: true });}catch(e){}</script> <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="keywords" content="virtual classroom, online test, online course, MOOC,  SCORM, whiteboard, adaptive testing, e-learning, online education, learn online, teach online, live class, lms, monetize, sell course, online meetings, collaboration, webinar, how to, social, teach, learn"><meta name="description" content="Deliver live engaging classes using Virtual Classroom. Create and sell courses and tests online."><title>Review Answers | BrainCert</title><link href="https://www.braincert.com/templates/yoo_nano/favicon.ico" rel="shortcut icon" type="image/vnd.microsoft.icon"> <script type="text/javascript">
function keepAlive() {	var myAjax = new Request({method: "get", url: "index.php"}).send();} window.addEvent("domready", function(){ keepAlive.periodical(3540000); });
  </script> <script type="text/javascript">
				/*<![CDATA[*/
					var jax_live_site = 'https://www.braincert.com/index.php';
					var jax_token_var='925395911814f17127e11ea28577607f';
				/*]]>*/
				</script><script type="text/javascript" src="./sap-02_files/ajax_1.5.pack.js.下载"></script> <link rel="apple-touch-icon-precomposed" href="https://d9q55ve2f7k8m.cloudfront.net/images/apple_touch_icon.png"> <script>
        !function(window, document) {
            window._atatusConfig = {
                apikey: '8c2f3d535648489b9826fd95a6484c2b'
            };
            function _asyncAtatus(callback) {
                var script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.src = "https://dmc1acwvwny3.cloudfront.net/atatus.js";
                var node = document.getElementsByTagName("script")[0];
                script.addEventListener('load', function (e) {
                    callback(null, e);
                }, false);
                node.parentNode.insertBefore(script, node);
            }
            _asyncAtatus(function() {
                // Any atatus related calls.
                if (window.atatus) {
                    window.atatus.setUser('138600', 'liugongjianxin@163.com', 'gongjian liu');
                    console.log(window.atatus);
                }
            });
        }(window, document);
</script> <style type="text/css">@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-weight:700;font-style:italic;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-weight:400;font-style:italic;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff2"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("opentype");font-weight:100;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/145edc/000000000000000000013289/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff2"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("opentype");font-weight:300;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff2"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("opentype");font-weight:800;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff2"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("opentype");font-weight:900;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff2"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("opentype");font-weight:200;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-weight:600;font-style:normal;}</style><script async="" type="text/javascript" src="./sap-02_files/pops"></script><script async="" type="text/javascript" src="./sap-02_files/pops(1)"></script><script type="text/javascript" src="./sap-02_files/jquery.min.js.下载"></script></head><body id="page-top"><div id="page-wrap"><div id="preloader"> </div> <header id="header" class="header chapter-header"><div class="container"><div class="logo"><a href="https://www.braincert.com/"><img src="./sap-02_files/bc-logo-sm.png" alt="BrainCert" style="max-height:60px;"></a> </div><nav class="navigation"><div class="navbar-header"> <a class="navbar-brand" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215#"><span class="navbar-header-title"> AWS Certified Solutions Architect Professional SAP-C01 Practice </span></a> </div><ul class="menu"> <li><a href="https://www.braincert.com/">Home</a></li> </ul><div class="search-box"> <a href="https://www.braincert.com/test/11995-AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice-Exam-2" class="smoothScroll"><i class="fa fa-chevron-left"></i> Back</a> </div></nav> </div> </header><div class="main-container"> <script type="text/javascript">
  jQuery(document).ready(function (){
     
    jQuery( "html" ).addClass( "secondary-14px" );
    jQuery(document)[0].oncontextmenu = function() {return false;} 
    // code for preventing copy from keyboard
    var ambit = jQuery(document);
    // Disable Cut + Copy + Paste (input)
    ambit.on('copy paste cut', function (e) {
    e.preventDefault(); //disable cut,copy,paste
      return false;
    });
      });
</script> <div class="container"><div id="content-main" class="row-fluid"><div class="col-sm-12"><h2 style="margin-bottom:10px;margin-top:10px; float:left">Test Report</h2><div style="margin-top:10px;float:right"><a onclick="window.history.back();" class="btn btn-warning"><span><strong>Back</strong></span></a></div><div style="float:right;margin-top:10px;margin-right: 10px;"><a href="https://www.braincert.com/test/reviewtest/exportdata/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215" class="btn btn-primary"><span><strong><i class="fa fa-share-square-o"></i>&nbsp;Export to .CSV</strong></span></a></div><div style="border-bottom-width: 1px;border-bottom-style: dashed;border-bottom-color: #e0e0e0;margin-bottom: 10px; clear:both"></div><div style="clear:both;"></div><div class="col-md-6 pull-left row"><h3 style="margin-top: 0px;"><strong>Review questions</strong></h3></div><div class="col-md-6 pull-right row" style="font-size: 16px;text-align: right;"><strong>Student : </strong>gongjian liu
<br> <i class="fa fa-calendar"></i>&nbsp;Jun 16, 2019&nbsp;&nbsp;<i class="fa fa-clock-o"></i>&nbsp;11:56PM EDT<br> <br> </div><div id="test_results" style="padding-top: 80px;"><div id="quiz_specific"> <span id="select"></span> <div class="quiz_attempt_breakdown"><div class="percent_correct_bar col-sm-2"><div class="progress" style="margin-bottom: 2px;"><div class="progress-bar" role="progressbar" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100" style="width:18%"> </div> </div> <span id="percent"><strong>18% </strong>correct</span> </div><div><div class="questions_correct col-sm-2"><span class="inline_pipe">|</span>&nbsp;&nbsp; <img src="./sap-02_files/tick.webp" alt="you got this question right">&nbsp;<strong>10 correct</strong></div><div class="questions_incorrect col-sm-2"><span class="inline_pipe"> | </span>&nbsp;&nbsp; <img src="./sap-02_files/cross.webp" alt="you got this question wrong">&nbsp;<strong>45 incorrect</strong></div><div class="questions_incorrect col-sm-3" style="margin:0;"><span class="inline_pipe"> | </span>&nbsp;&nbsp;<img src="./sap-02_files/icon_un_answered.webp" alt="you got this question unanswer">&nbsp;<strong>0 Unanswered</strong></div><div class="total_questions col-sm-3"><span class="inline_pipe"> | </span>&nbsp;&nbsp;<strong>55 questions attempted out of 55</strong></div></div></div><br class="clear"><hr style="clear:both"><br> <br><div style="margin-bottom: 10px;"> <b style="font-size: 14.5px;">Filter by</b> : <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215" class="label-default label">All</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215?sort=1">correct</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215?sort=0">incorrect</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215?sort=-1">Unanswered</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145215?sort=2">Question feedback</a> </div><br><div class="" style="font-size: 18px;line-height: 25px;"><div class="question_info"><div class="question_no"><b>Question : 1 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249033"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing a personal document-archiving solution for your global enterprise with thousands of employee. Each employee has potentially gigabytes of data to be backed up in this archiving solution. The solution will be exposed to he employees as an application, where they can just drag and drop their files to the archiving system. Employees can retrieve their archives through a web interface. The corporate network has high bandwidth AWS DirectConnect connectivity to AWS. You have regulatory requirements that all data needs to be encrypted before being uploaded to the cloud. How do you implement this in a highly available and cost efficient way?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 1856 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Manage encryption keys on-premise in an encrypted relational database. Set up an on-premises server with sufficient storage to temporarily store files and then upload them to Amazon S3, providing a client-side master key.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Manage encryption keys in a Hardware Security Module (HSM) appliance on-premise server with sufficient storage to temporarily store, encrypt, and upload files directly into amazon Glacier.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Manage encryption keys in amazon Key Management Service (KMS), upload to amazon simple storage service (s3) with client-side encryption using a KMS customer master key ID and configure Amazon S3 lifecycle policies to store each object using the amazon glacier storage tier.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Manage encryption keys in an AWS CloudHSM appliance. Encrypt files prior to uploading on the employee desktop and then upload directly into amazon glacier <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Manage encryption keys in amazon Key Management Service (KMS), upload to amazon simple storage service (s3) with client-side encryption using a KMS customer master key ID and configure Amazon S3 lifecycle policies to store each object using the amazon glacier storage tier.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> - With CSE-KMS the encryption happens at client side before the object is upload to S3 and KMS is cost effective as well </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html" target="_blank">S3 Client Side Encryption</a></p><p>CloudHSM and HSM are not a cost effective options ruling out option B and D. </p><p>Option A does not work as Storing data on-premises temporarily would also cost as HA needs to be implemented </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120184">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 2 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249034"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your security team have approached you and asked that you restrict the ability of an EC2 instance to access a certain remote DNS API endpoint. The remote endpoint may change IP's over time and its imperative it can NEVER access this endpoint. What solution will work as expected?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 11 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure the NACL of the instance subnet to block any outbound traffic to the FQDN of the API endpoint or its return traffic</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Configure the SG of the instance to block any outbound traffic to the FQDN of the API endpoint or its return traffic<br><b>C</b>. <input type="radio" disabled="">&nbsp;Configure Layer-7 filtering on the NAT Gateway in the VPC and add a DNS blacklist entry<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use an 'on instance' proxy and configure this to perform DNS resolution and only allow traffic which doesn't breach security restrictions. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Use an 'on instance' proxy and configure this to perform DNS resolution and only allow traffic which doesn't breach security restrictions.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as the traffic needs to be restricted using DNS names, it can be achieved using an 'on instance' proxy. </p><p>Refer AWS documentation - <a href="https://d0.awsstatic.com/aws-answers/Controlling_VPC_Egress_Traffic.pdf" target="_blank">Controlling VPC Egress Traffic</a> </p><p><em>A forward proxy server acts as an intermediary for requests from internal users and servers, often caching content to speed up subsequent requests. Companies usually implement proxy solutions to provide URL and web content filtering, IDS/IPS, data loss prevention, monitoring, and advanced threat protection. AWS customers often use a VPN or AWS Direct Connect connection to leverage existing corporate proxy server infrastructure, or build a forward proxy farm on AWS using software such as Squid proxy servers with internal Elastic Load Balancing (ELB). </em> </p><p><em>Web proxy servers are the most common type of proxy server used today. Web proxies control HTTP and HTTPS traffic and have ubiquitous support from web clients such as web browsers, web command line tools, programming tools, and web application servers. SOCKS proxy servers, although less common than web proxies, leverage custom SOCKS proxy clients to control any type of IP network traffic. In either case, each EC2 instance must be configured (typically through initial instance bootstrapping or application deployment and configuration) to leverage the proxy solution at either the OS or application level. </em><em></em><br> </p><p>Options A, B &amp; C are wrong as they do not provide the ability to filter traffic based on DNS. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121148">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 3 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249035"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have a periodic Image analysis application that gets some files as input, analyzes them and for each file writes some data in output to a temp file. The number of files in input per day is high and concentrated in a few hours of the day. Currently you have a server on EC2 with a large EBS volume that hosts the input data and the results it takes almost 20 hours per day to complete the process. What services could be used to reduce the elaboration time and improve the availability of the solution?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;S3 to store I/O files. SQS to distribute elaboration commands to a group of hosts working in parallel. Auto scaling to dynamically size the group of hosts depending on the length of the SQS queue</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;EBS with Provisioned IOPS (PIOPS) to store I/O files. SNS to distribute elaboration commands to a group of hosts working in parallel Auto Scaling to dynamically size the group of hosts depending on the number of SNS notifications<br><b>C</b>. <input type="radio" disabled="">&nbsp;S3 to store I/O files, SNS to distribute elaboration commands to a group of hosts working in parallel. Auto scaling to dynamically size the group of hosts depending on the number of SNS notifications<br><b>D</b>. <input type="radio" disabled="">&nbsp;EBS with Provisioned IOPS (PIOPS) to store I/O files SQS to distribute elaboration commands to a group of hosts working in parallel Auto Scaling to dynamically size the group to hosts depending on the length of the SQS queue. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. S3 to store I/O files. SQS to distribute elaboration commands to a group of hosts working in parallel. Auto scaling to dynamically size the group of hosts depending on the length of the SQS queue<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to reduce the processing time, files are high and concentrated only during few hours and maintaining availability. </p><p>Correct answer is <strong>A</strong>, as the files can be stored in S3 as a common location which can be shared and access from multiple instances and scaled as per the demand. </p><p>Option B and C are wrong as SNS is not a right service for load distribution<br> </p><p>Option D is wrong as EBS does not provide a scalable and sharable storage option. It cannot be shared across the instances. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120201">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 4 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249036"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your customer is implementing a video on-demand streaming platform on AWS. The requirements are; support for multiple devices such as is, Android, and PC as client devices, using a standard client player, using streaming technology (not download) and scalable architecture with cost effectiveness.<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Store the video contents to Amazon Simple Storage Service (S3) as an origin server, Configure the Amazon CloudFront distribution with a streaming option to stream the video contents</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Store the video contents to Amazon S3 as an origin server. Configure the Amazon CloudFront distribution with a download option to stream the video contents<br><b>C</b>. <input type="radio" disabled="">&nbsp;Launch a streaming server on Amazon Elastic Compute Cloud (EC2) (for example, Adobe Media Server), and store the video contents as an origin server. Configure the Amazon CloudFront distribution with a download option to stream the video contents<br><b>D</b>. <input type="radio" disabled="">&nbsp;Launch a streaming server on Amazon Elastic Compute Cloud (EC2) (for example, Adobe Media Server), and store the video contents as an origin server. Launch and configure the required amount of streaming servers on Amazon EC2 as an edge server to stream the video contents <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Store the video contents to Amazon S3 as an origin server. Configure the Amazon CloudFront distribution with a download option to stream the video contents<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is scalable architecture with cost effectiveness with support to stream videos. </p><p>Correct answer is <strong>B</strong> as the requirement is more for on-demand streaming platform on multiple devices. CloudFront can support the streaming of videos using the download option configured for progressive option. </p><p>Refer to AWS documentation for <a href="https://aws.amazon.com/blogs/aws/using-amazon-cloudfront-for-video-streaming/" target="_blank">Video Streaming using CloudFront</a> </p><p>Option A is wrong as RTMP or streaming is an Adobe protocol and did not work with all devices esp. IOS </p><p>Option C &amp; D are wrong as the requirement is for an on-demand platform as well as not cost effective as compare to S3. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120221">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 5 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249037"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A news company runs their current application entirely all on-premise. However, they are expecting a big boost in traffic and need to figure out a way to decrease the load to handle the scale. Unfortunately, they cannot migrate their application to AWS in the period required. What could they do with their current on-premise application to help offload some of the traffic and scale to meet the demand expected in 24 hours?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Deploy OpsWorks on-premise to manage the instance in order to configure on-premise auto scaling to meet the demand.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Upload all static files to Amazon S3 and create a CloudFront distribution serving those static files.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Duplicate half your web infrastructure on AWS, offload the DNS to Route 53 and configure weighted based DNS routing to send half the traffic to AWS.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a CloudFront CDN, enable query string forwarding and configure suitable TTL. Offload the DNS to AWS to handle CloudFront CDN traffic but use on-premise load balancers as the origin. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Create a CloudFront CDN, enable query string forwarding and configure suitable TTL. Offload the DNS to AWS to handle CloudFront CDN traffic but use on-premise load balancers as the origin.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as CloudFront can be configured with custom origin. Also as it is a news company, CloudFront can help scale and handle additional load. </p><p>Option A is wrong as OpsWorks is used to build orchestration and will only help speed up environment setup but not reduce load or scale. </p><p>Option B is wrong as the site is not entirely static.<br> </p><p>Option C is wrong as time is the constraint, replicating the environment would not be an option. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120401">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 6 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249038"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have deployed a three-tier web application in a VPC with a CIDR block of 10.0.0.0/28. You initially deploy two web servers, two application servers, two database servers and one NAT instance tor a total of seven EC2 instances. The Web Application and database servers are deployed across two availability zones (AZs). You also deploy an ELB in front of the two web servers, and use Route 53 for DNS Web .Traffic gradually increases in the first few days following the deployment, so you attempt to double the number of instances in each tier of the application to handle the new load unfortunately some of these new instances fail to launch. Which of the following could the root caused? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;The Internet Gateway (IGW) of your VPC has scaled-up adding more instances to handle the traffic spike, reducing the number of available private IP addresses for new instance launches.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;AWS reserves one IP address in each subnet’s CIDR block for Route 53 so you do not have enough addresses left to launch all of the new EC2 instances.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;AWS reserves the first and the last private IP address in each subnet’s CIDR block so you do not have enough addresses left to launch all of the new EC2 instances.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;The ELB has scaled-up. Adding more instances to handle the traffic reducing the number of available private IP addresses for new instance launches<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;AWS reserves the first four and the last IP address in each subnet’s CIDR block so you do not have enough addresses left to launch all of the new EC2 instances. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. The ELB has scaled-up. Adding more instances to handle the traffic reducing the number of available private IP addresses for new instance launches<br><b>E</b>. AWS reserves the first four and the last IP address in each subnet’s CIDR block so you do not have enough addresses left to launch all of the new EC2 instances.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D &amp; E</strong> </p><p>Option E as <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html#VPC_Sizing" target="_blank">AWS reserves first four IP addresses and the last IP address</a> in each subnet CIDR block, and cannot be assigned to an instance </p><p>Option D as ELB being a managed AWS service scales up as the demand increases and would take some ip address </p><p>Option A is wrong as IGW is managed by AWS and does not take reduce private IP addresses from the subnet </p><p>Option B &amp; C are wrong as AWS reserves first 4 and last IP address in each subnet's CIDR block. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120385">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 7 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249039"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A Company is running an Amazon Redshift cluster with four nodes running 24/7/365 and expects, potentially, to add one on-demand node for one to two days once during the year. Which architecture would have the lowest possible cost for the cluster requirement? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Purchase 5 reserved nodes to cover all possible node usage during the year</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Purchase 4 reserved nodes and rely on on-demand instances for the fifth node, if required<br><b>C</b>. <input type="radio" disabled="">&nbsp;Purchase 2 reserved nodes and utilize 3 on-demand nodes only for peak usage times<br><b>D</b>. <input type="radio" disabled="">&nbsp;Purchase 4 reserved nodes and bid on spot instances for the extra node usage required <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Purchase 4 reserved nodes and rely on on-demand instances for the fifth node, if required<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B </strong>as the 4 nodes are expected to run always, purchasing reserved instances for four nodes will reduce overall costs. The fifth node is expected to run, at most, one day which can be an on demand instance, which is the best possible cost option in relationship to reserved instances.<span class="redactor-invisible-space"></span> </p><p>Option A is wrong as the 5th reserved node is not needed and would lead to cost overhead </p><p>Option C is wrong as the usage is guaranteed for 4 nodes to run continously, reserved instances would help in cost saving </p><p>Option D is wrong as Spot instances cannot be guaranteed to run and would be used in case the application is able to recover from a sudden termination of the node.<span class="redactor-invisible-space"></span> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120443">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 8 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249040"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company is hosting a web application on AWS. According to the architectural best practices, the application must be highly available, scalable, cost effective, with high-performance and should require minimal human intervention. You have deployed the web servers and database servers in public and private subnet of the VPC respectively. While testing the application via web browser, you noticed that the application is not accessible. Which configuration settings you must do to tackle this problem? Choose 2 options<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Configure a NAT instance in your VPC and create a default route via the NAT instance and associate it with all subnets. Configure a DNS A record that points to the NAT instance public IP address.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Configure a CloudFront distribution and configure the origin to point to the private IP addresses of your Web servers. Configure a Route53 CNAME record to your CloudFront distribution.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Place all your web servers behind ELB. Configure a Route53 ALIAS-Record to point to the ELB DNS name.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Assign EIP's to all web servers. Configure a Route53 A-Record set with all EIPs with health checks and DNS failover.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Configure ELB with an EIP. Place all your Web servers behind ELB Configure a Route 53 A record that points to the EIP <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Place all your web servers behind ELB. Configure a Route53 ALIAS-Record to point to the ELB DNS name.<br><b>D</b>. Assign EIP's to all web servers. Configure a Route53 A-Record set with all EIPs with health checks and DNS failover.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is C &amp; D as the key point here is HA solution<br> </p><p>Option C as you can use ELB and configure CNAME to point to ELB DNS, need to be alias for non zone apex record. </p><p>Option D as you can have EIPs assigned and switched for HA and have them configured with Route 53 record set. Refer <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-ec2-instance.html" target="_blank">AWS documentation</a><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-ec2-instance.html">documentation</a> </p><p>Option A is wrong as NAT is for internet connectivity for instances in private subnet and not to route traffic in. </p><p>Option B is wrong as CloudFront is more of a caching solution for scalability rather than HA </p><p>Option E is wrong as you cannot associate a EIP with ELB </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120561">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 9 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249041"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your application Amazon Elastic Compute Cloud (EC2) instances bootstrap by using a master configuration file that is kept in a version-enabled Amazon Simple Storage Service (S3) bucket. Which one of the following methods should you use to securely install the current configuration version onto the instances in a cost-effective way?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an Amazon DynamoDB table to store the different versions of the configuration file. Associate AWS Identity and Access Management (IAM) EC2 roles to the Amazon EC2 instances, and reference the DynamoDB table to get the latest file from Amazon Simple Storage Service (S3). </span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Associate an IAM S3 role to the bucket, list the object versions using the Amazon S3 API, and then get the latest object. <br><b>C</b>. <input type="radio" disabled="">&nbsp;Associate an IAM EC2 role to the instances, list the object versions using the Amazon S3 API, and then get the latest object. <br><b>D</b>. <input type="radio" disabled="">&nbsp;Associate an IAM EC2 role to the instances, and then simply get the object from Amazon S3, because the default is the current version. <br><b>E</b>. <input type="radio" disabled="">&nbsp;Store the IAM credentials in the Amazon EC2 user data for each instance, and then simply get the object from S3, because the default is the current version. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Associate an IAM EC2 role to the instances, and then simply get the object from Amazon S3, because the default is the current version. <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as IAM Role is a preferred secure way to access S3 from EC2. Also, accessing the object from S3 would return the current version by default. </p><p>Option A is wrong as DynamoDB is not a preferred choice for saying configurations and adding additional component would not be cost-effective.<br> </p><p>Option B is wrong as its IAM EC2 role and you don't need to list object versions.<br> </p><p>Option C is wrong as you don't need to list object versions.<br> </p><p>Option E is wrong as storing IAM credentials in user data is not secured. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120556">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 10 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249042"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have been asked to create a DR plan for a business. The specific application they have asked you to look at runs on an EC2 instance. The application takes around 20 minutes to install using a set of installation scripts. At the present time, the EC2 instance has an EBS volume attached to it which contains 200Gb of data (mapped into the file system as /medicalimages). The medical images are the only 'non-static' part of the application. The application runs in AZ-A in a given AWS region and the business have asked that you make sure it can be moved over to another AZ quickly and efficiently if an AZ failure occurs. The application runs on a Linux instance - and its a general purpose instance. For the sake of this exercise you have not been asked to account for data corruption - only AZ failure. The application has an RTO of 15 minutes and an RPO of 30 minutes. What would you suggest? (Select TWO)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Store the medical images onto a separate EBS volume using the IO2 type. Configure point in time recovery of the volume with the Two Zone option configured to ensure replication between at least two AZ's</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Migrate the medicalimages data to an EFS file system configured to operate within all AZ's in that region. Configure the EC2 instances on boot to map the EFS file system.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Configure the application install scripts within a launch configuration and use this for an auto-scaling group with a 1:1:1 configuration.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Configure recovery on the EC2 instance and ensure fault-tolerance is enabled for both the EC2 and EBS components<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Create a new EC2 instance; install the application. Stop the instance and create an AMI - use this for a Launch template and auto-scaling group with a 1:1:1 configuration. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Migrate the medicalimages data to an EFS file system configured to operate within all AZ's in that region. Configure the EC2 instances on boot to map the EFS file system.<br><b>E</b>. Create a new EC2 instance; install the application. Stop the instance and create an AMI - use this for a Launch template and auto-scaling group with a 1:1:1 configuration.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B &amp; E</strong> </p><p>Option B as using <a href="https://aws.amazon.com/efs/" target="_blank">EFS</a> will allow seamless sharing of the file system across instances in AZs. </p><p><em>Amazon Elastic File System (Amazon EFS) provides a simple, scalable, elastic file system for Linux-based workloads for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, so your applications have the storage they need – when they need it. It is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies. Amazon EFS is a fully managed service that requires no changes to your existing applications and tools, providing access through a standard file system interface for seamless integration. There is a Standard and an Infrequent Access storage class available with Amazon EFS. Using Lifecycle Management, files not accessed for 30 days will automatically be moved to a cost-optimized Infrequent Access storage class, giving you a simple way to store and access active and infrequently accessed file system data in the same file system while reducing storage costs by up to 85%. Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. You can access your file systems across AZs, regions, and VPCs and share files between thousands of Amazon EC2 instances and on-premises servers via AWS Direct Connect or AWS VPN.</em><br> </p><p>Option E as creating a pre-baked AMI would reduce the startup time improving the RTO. Also, with Auto Scaling with min/max/desired as 1 would ensure the instance are recreated in the available AZ. </p><p>Option A is wrong as there is no Two Zone option with EBS. EBS volume are specific to AZ and can be attached only to a single instance at a time. </p><p>Option C is wrong as using user data scripts at launch would not meet the RTO of 15 minutes. </p><p>Option D is wrong as there is no fault tolerance option and its needs to be enabled using different recovery techniques. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%202%20-%20%23121199">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 11 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249043"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are the administrator for a new startup company which has a production account and a development account on AWS. Up until this point, no one has had access to the production account except yourself. There are 20 people on the development account who now need various levels of access provided to them on the production account. 10 of them need read-only access to all resources on the production account, 5 of them need read/write access to EC2 resources, and the remaining 5 only need read-only access to S3 buckets. Which of the following options would be the best way, both practically and security-wise, to accomplish this task? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Copy the 20 users IAM accounts from the development account to the production account. Then change the access levels for each user on the production account.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create encryption keys for each of the resources that need access and provide those keys to each user depending on the access required.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create 3 new users on the production account with the various levels of permissions needed. Give each of the 20 users the login for whichever one of the 3 accounts they need depending on the level of access required.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create 3 roles in the production account with a different policy for each of the access levels needed. Add permissions to each IAM user on the developer account. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Create 3 roles in the production account with a different policy for each of the access levels needed. Add permissions to each IAM user on the developer account.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as the IAM best practice is to create 3 roles and allow the ability to the users to assume the role for appropriate access. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html" target="_blank">IAM Role Cross Account Access</a><br> </p><p><em>You share resources in one account with users in a different account. By setting up cross-account access in this way, you don't need to create individual IAM users in each account. In addition, users don't have to sign out of one account and sign into another in order to access resources that are in different AWS accounts. After configuring the role, you see how to use the role from the AWS Management Console, the AWS CLI, and the API.</em><br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120536">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 12 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249044"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your social media marketing application has a component written in Ruby running on AWS Elastic Beanstalk. This application component posts messages to social media sites in support of various marketing campaigns. Your management now requires you to record replies to these social media messages to analyze the effectiveness of the marketing campaign in comparison to past and future efforts. You’ve already developed a new application component to interface with the social media site APIs in order to read the replies. Which process should you use to record the social media replies in a durable data store that can be accessed at any time for analytics of historical data?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Deploy the new application component in an Auto Scaling group of Amazon EC2 instances, read the data from the social media sites, store it with Amazon Elastic Block Store, and use AWS Data Pipeline to publish it to Amazon Kinesis for analytics.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Deploy the new application component as an Elastic Beanstalk application, read the data from the social media sites, store it in DynamoDB, and use Apache Hive with Amazon Elastic MapReduce for analytics.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Deploy the new application component in an Auto Scaling group of Amazon EC2 instances, read the data from the social media sites, store it in Amazon Glacier, and use AWS Data Pipeline to publish it to Amazon RedShift for analytics.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Deploy the new application component as an Amazon Elastic Beanstalk application, read the data from the social media site, store it with Amazon Elastic Block store, and use Amazon Kinesis to stream the data to Amazon CloudWatch for analytics. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Deploy the new application component as an Elastic Beanstalk application, read the data from the social media sites, store it in DynamoDB, and use Apache Hive with Amazon Elastic MapReduce for analytics.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as the point here is durable data store with any time analytics the best option is to store the data in DynamoDB and use Apache Hive with Amazon Elastic MapReduce for analytics.<br> </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EMRforDynamoDB.Tutorial.html" target="_blank">DynamoDB EMR Hive Processing</a> </p><p>Option A is wrong as Elastic Block Store is not ideal for storing social media data </p><p>Option C is wrong as Amazon Glacier is not an ideal for storing social media data </p><p>Option D is wrong as Elastic Block Store is not ideal for storing social media data and CloudWatch is not for analytics. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120541">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 13 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249045"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is migrating an application from its data center to AWS. The application currently stores an API key used to access a third-party service in a local file. When deployed on AWS, the application will run on Amazon EC2 instances. As part of the migration, the application must make the API key more secure. Specifically: Each environment (such as development, test, and production) must have its own API key. All API key access requests should be logged for auditing purposes. The API keys must be encrypted at rest using a customer-managed key. Access permissions must be granular; the development environment cannot access the production API key, for example. What is the MOST secure way to meet these requirements? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM user with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the API key for the environment. Store an access key for that user in a credential store on each Amazon EC2 instance. </span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the proper API key. Launch each Amazon EC2 instance with the proper IAM role. <br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an Amazon DynamoDB table encrypted with an AWS KMS customer master key (CMK). Store each API key in a different item in the table. Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the dynamodb:getitem action for the correct item. Launch each Amazon EC2 instance with the proper IAM role. <br><b>D</b>. <input type="radio" disabled="">&nbsp;Pass the proper API key to each Amazon EC2 instance upon launch utilizing user data. Assign an IAM role to each EC2 instance with permissions to the kms:encrypt and the kms:decrypt actions for a customer-managed AWS KMS customer master key (CMK). In the user data script, encrypt the API key using the CMK. Store the encrypted API key on each EC2 instance. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the proper API key. Launch each Amazon EC2 instance with the proper IAM role. <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as AWS Systems Manager Parameter Store provides a secure storage for API keys with the ability for customer managed keys. Also, you should use IAM role to prevent hardcoding credentials. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html" target="_blank">Systems Manager Parameter Store</a> </p><p><em>AWS Systems Manager Parameter Store provides secure, hierarchical storage for configuration data management and secrets management. You can store data such as passwords, database strings, and license codes as parameter values. You can store values as plain text or encrypted data. You can then reference values by using the unique name that you specified when you created the parameter. Highly scalable, available, and durable, Parameter Store is backed by the AWS Cloud.</em> </p><p><em>Parameter Store offers the following benefits and features.</em> </p><ul> <li><em>Use a secure, scalable, hosted secrets management service (No servers to manage).</em></li> <li><em>Improve your security posture by separating your data from your code.</em></li> <li><em>Store configuration data and secure strings in hierarchies and track versions.</em></li> <li><em>Control and audit access at granular levels.</em></li> <li><em>Configure change notifications and trigger automated actions.</em></li> <li><em>Tag parameters individually, and then secure access from different levels, including operational, parameter, EC2 tag, or path levels.</em></li> <li><em>Reference AWS Secrets Manager secrets by using Parameter Store parameters.</em></li> <li><em>Use Parameter Store parameters with other Systems Manager capabilities and AWS services to retrieve secrets and configuration data from a central store. The following AWS services support Parameter Store parameters: Amazon EC2, Amazon Elastic Container Service, AWS Lambda, AWS CloudFormation, AWS CodeBuild, and AWS CodeDeploy.</em></li> <li><em>Configure integration with AWS Key Management Service (KMS), Amazon Simple Notification Service (SNS), Amazon CloudWatch, and AWS CloudTrail for encryption, notification, monitoring, and audit capabilities.</em></li> </ul><p><em>With AWS Systems Manager Parameter Store, you can create secure string parameters, which are parameters that have a plaintext parameter name and an encrypted parameter value. Parameter Store uses AWS KMS to encrypt and decrypt the parameter values of secure string parameters.</em> </p><p><em>With Parameter Store you can create, store, and manage data as parameters with values. You can create a parameter in Parameter Store and use it in multiple applications and services subject to policies and permissions that you design. When you need to change a parameter value, you change one instance, rather than managing error-prone changes to numerous sources. Parameter Store supports a hierarchical structure for parameter names, so you can qualify a parameter for specific uses.</em> </p><p><em>To manage sensitive data, you can create secure string parameters. Parameter Store uses AWS KMS customer master keys (CMKs) to encrypt the parameter values of secure string parameters when you create or change them. It also uses CMKs to decrypt the parameter values when you access them. You can use the AWS managed CMK that Parameter Store creates for your account or specify your own customer managed CMK.</em> </p><p>Option A is wrong as using IAM user is not a best practice. </p><p>Options C &amp; D are wrong as using DynamoDB and User data is not a secure and recommended way for passing sensitive data. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121086">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 14 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249046"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A customer is deploying an SSL enabled Web application to AWS and would like to implement a separation of roles between the EC2 service administrators that are entitled to login to Instances as well as making API calls and the security officers who will maintain and have exclusive access to the application’s X.509 certificate that contains the private key. Which configuration option could satisfy the above requirement?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure the web servers to retrieve the certificate upon boot from an CloudHSM that is managed by the security officers.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Upload the certificate on an S3 bucket owned by the security officers and accessible only by the EC2 Role of the web servers.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Configure system permissions on the web servers to restrict access to the certificate only to the authorized security officers.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Configure IAM policies authorizing access to the certificate store only to the security officers and terminate SSL on an ELB. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Configure IAM policies authorizing access to the certificate store only to the security officers and terminate SSL on an ELB.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is separation of access control. </p><p>Correct answer is <strong>D</strong> cert is not stored on the box and accessible only to the security officers and termination SSL on ELB does not expose the cert </p><p>Option A, B and C still expose the certificate on the EC2 box and being accessible to the EC2 service administrator who can login into the box </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120263">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 15 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249047"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your CIO has become very paranoid recently after a series of security breaches and wants you to start providing additional layers of security to all your company's AWS resources. First up he wants you to provide additional layers of protection to all your EC2 resources. Which of the following would be a way of providing that additional layer of protection to all your EC2 resources? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Ensure that the proper tagging strategies have been implemented to identify all of your EC2 resources.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Add an IP address condition to policies that specify that requests to EC2 instances should come from a specific IP address or CIDR block range.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Add policies which have deny and/or allow permissions on tagged resources<br><b>D</b>. <input type="radio" disabled="">&nbsp;All actions listed here would provide additional layers of protection. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. All actions listed here would provide additional layers of protection.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as you can implement tagging and define proper permissions and restrictions on the tagged resource. you can also restrict the access to the EC2 resources to originate from known IP addresses only. </p><p>Refer AWS documentation <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_examples.html" target="_blank">IAM Access Policies</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120522">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 16 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249048"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You require the ability to analyze a customer’s clickstream data on a website so they can do behavioral analysis. Your customer needs to know what sequence of pages and ads their customer clicked on. This data will be used in real time to modify the page layouts as customers click through the site to increase stickiness and advertising click-through. Which option meets the requirements for capturing and analyzing this data?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Log clicks in weblogs by URL store to Amazon S3, and then analyze with Elastic MapReduce</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Push web clicks by session to Amazon Kinesis and analyze behavior using Kinesis workers<br><b>C</b>. <input type="radio" disabled="">&nbsp;Write click events directly to Amazon Redshift and then analyze with SQL<br><b>D</b>. <input type="radio" disabled="">&nbsp;Publish web clicks by session to an Amazon SQS queue and periodically drain these events to Amazon RDS and analyze with SQL <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Push web clicks by session to Amazon Kinesis and analyze behavior using Kinesis workers<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is real time data capture and analytics </p><p>Correct answer is <strong>B</strong> as Kinesis helps to collect real time data capture and analyze using kinesis workers </p><p>Option A is wrong as S3 &amp; EMR is not ideal for real time data ingestion and analytics </p><p>Option C is wrong as Redshift is not suitable for real time data ingestion and only allows jdbc/odbc data connection </p><p>Option D is wrong as SQS is not ideal for real time data ingestion. Also periodical analytics is not real time to be able to modify the behavior </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120375">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 17 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249049"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A public archives organization is about to move a pilot application they are running on AWS into production. You have been of hired to analyze their application architecture and give cost-saving recommendations. The application displays scanned historical documents. Each document is split into individual image tiles at multiple zoom levels to improve responsiveness and ease of use for the end users. At maximum zoom level the average document will be 8000 x 6000 pixels in size, split into multiple 40px x 40px image tiles. The tiles are batch processed by Amazon Elastic Compute Cloud (EC2) instances, and put into an Amazon Simple Storage Service (S3) bucket. A browser-based JavaScript viewer fetches tiles from the Amazon (S3) bucket and displays them to users as they zoom and pan around each document. The average storage size of all zoom levels for a document is approximately 30MB of JPEG tiles. Originals of each document are archived in Amazon Glacier. The company expects to process and host over 500,000 scanned documents in the first year. What are your recommendations? Choose 3 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Deploy an Amazon CloudFront distribution in front of the Amazon S3 tiles bucket.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Increase the size (width/height) of the individual tiles at the maximum zoom level.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Decrease the size (width/height) of the individual tiles at the maximum zoom level.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Store the maximum zoom level in the low cost Amazon S3 Glacier option and only retrieve the most frequently access tiles as they are requested by users<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use Amazon S3 Reduced Redundancy Storage for each zoom level.<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Use Amazon S3 Standard Storage for each zoom level. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Deploy an Amazon CloudFront distribution in front of the Amazon S3 tiles bucket.<br><b>B</b>. Increase the size (width/height) of the individual tiles at the maximum zoom level.<br><b>F</b>. Use Amazon S3 Standard Storage for each zoom level.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to save cost. </p><p>Correct answer is <strong>A, B &amp; F</strong> </p><p>Option A with CloudFront performs caching and helps reduce load on the origin services. </p><p>Option B as increasing the size of the images would help reduce the cost of GET/PUT requests on the origin server. </p><p>Option F as AWS recommends using S3 standard for storage as it is now more cost effective as compared to RRS </p><p>Option C is wrong as decreasing size would require more requests and increased expense </p><p>Option D is wrong as Glacier is more for archiving and not for serving requests </p><p>Option E is wrong as AWS recommends Standard over RRS.<br> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120359">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 18 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249050"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company currently has a highly available web application running in production. The application's web front-end utilizes an Elastic Load Balancer and Auto scaling across 3 availability zones. During peak load, your web servers operate at 90% utilization and leverage a combination of heavy utilization reserved instances for steady state load and on-demand and spot instances for peak load. You are asked with designing a cost effective architecture to allow the application to recover quickly in the event that an availability zone is unavailable during peak load. Which option provides the most cost effective high availability architectural design for this application?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Increase auto scaling capacity and scaling thresholds to allow the web-front to cost-effectively scale across all availability zones to lower aggregate utilization levels that will allow an availability zone to fail during peak load without affecting the applications availability.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Continue to run your web front-end at 90% utilization, but purchase an appropriate number of utilization RIs in each availability zone to cover the loss of any of the other availability zones during peak load.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Continue to run your web front-end at 90% utilization, but leverage a high bid price strategy to cover the loss of any of the other availability zones during peak load.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Increase use of spot instances to cost effectively to scale the web front-end across all availability zones to lower aggregate utilization levels that will allow an availability zone to fail during peak load without affecting the applications availability. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Increase auto scaling capacity and scaling thresholds to allow the web-front to cost-effectively scale across all availability zones to lower aggregate utilization levels that will allow an availability zone to fail during peak load without affecting the applications availability.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is A - Ideal for HA using auto scaling to reduce and distribute load and would the cost down </p><p>Option B is wrong as RIs would increase the cost further and is not needed </p><p>Option C is wrong as high bid price would neither guarantee instances and would increase cost as it would be similar to the On-Demand instances </p><p>Option D is wrong as Availability cannot be guaranteed </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120190">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 19 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249051"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your web site is hosted on 10 EC2 instances in 5 regions around the globe with 2 instances per region. How could you configure your site to maintain site availability with minimum downtime if one of the 5 regions was to lose network connectivity for extended period of time? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an Elastic Load Balancer to place in front of the EC2 instances. Set an appropriate health check on each ELB.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Establish VPN Connections between the instances in each region. Rely on BGP to failover in the case of a region wide connectivity outage<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a Route 53 Latency Based Routing Record Set that resolves to an Elastic Load Balancer in each region. Set an appropriate health check on each ELB.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a Route 53 Latency Based Routing Record Set that resolves to Elastic Load Balancers in each region and has the Evaluate Target Health flag set to true. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Create a Route 53 Latency Based Routing Record Set that resolves to Elastic Load Balancers in each region and has the Evaluate Target Health flag set to true.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as a Route 53 latency based routing can be configured with ELB in each region. If a region goes down, Route 53 would automatically redirect the traffic to the region with least latency. </p><p><em>With latency-based routing, Amazon Route 53 can direct your users to the lowest-latency AWS endpoint available. For example, you might associate a DNS name like <code><a href="http://www.example.com/">www.example.com</a></code> with an ELB Classic or Application Load Balancer, or with Amazon EC2 instances or Elastic IP addresses that are hosted in the US East (Ohio) and EU (Ireland) regions</em> </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/TutorialTransitionToLBR.html" target="_blank">Latency routing</a>, <a href="https://aws.amazon.com/blogs/aws/latency-based-multi-region-routing-now-available-for-aws/" target="_blank">AWS Blog for Multi Region Latency Routing</a> &amp; Route 53 - <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html#dns-failover-complex-configs-eth-no" target="_blank">Evaluate target health</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120421">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 20 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249052"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is running a batch analysis every hour on their main transactional DB running on an RDS MySQL instance to populate their central Data Warehouse running on Redshift. During the execution of the batch their transactional applications are very slow. When the batch completes they need to update the top management dashboard with the new data. The dashboard is produced by another system running on-premises that is currently started when a manually-sent email notifies that an update is required The on-premises system cannot be modified because is managed by another team. How would you optimize this scenario to solve performance issues and automate the process as much as possible?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Replace RDS with Redshift for the batch analysis and SNS to notify the on-premises system to update the dashboard</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Replace RDS with Redshift for the batch analysis and SQS to send a message to the on-premises system to update the dashboard<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an RDS Read Replica for the batch analysis and SNS to notify the on-premises system to update the dashboard<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an RDS Read Replica for the batch analysis and SQS to send a message to the on-premises system to update the dashboard. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create an RDS Read Replica for the batch analysis and SNS to notify the on-premises system to update the dashboard<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here to reduce load on the DB and email notification. </p><p>Correct answer is <strong>C</strong> as Read Replica can be used to scale the RDS to reduce load on the master DB. SNS can be used to send email. </p><p>Option A and B are wrong as Redshift is more of an data warehosuing solution rather then a transaction DB </p><p>Refer <a href="https://aws.amazon.com/redshift/faqs/" target="_blank">Redshift FAQs</a> - When would I use Amazon Redshift vs. Amazon RDS? </p><p>Option B and D are incorrect as SQS cannot be used to send email to on-premises system. Or the on premises application would need modification to poll SQS for updates. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120379">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 21 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249053"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A corporate web application is deployed within an Amazon Virtual Private Cloud (VPC) and is connected to the corporate data center via an IPsec VPN. The application must authenticate against the on-premises LDAP server. After authentication, each logged-in user can only access an Amazon Simple Storage Space (S3) keyspace specific to that user. Which two approaches can satisfy these objectives? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Develop an identity broker that authenticates against IAM security Token service to assume a IAM role in order to get temporary AWS security credentials The application calls the identity broker to get AWS temporary security credentials with access to the appropriate S3 bucket.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;The application authenticates against LDAP and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM role The application can use the temporary credentials to access the appropriate S3 bucket.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Develop an identity broker that authenticates against LDAP and then calls IAM Security Token Service to get IAM federated user credentials The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;The application authenticates against LDAP the application then calls the AWS identity and Access Management (IAM) Security Token service to log in to IAM using the LDAP credentials the application can use the IAM temporary credentials to access the appropriate S3 bucket.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;The application authenticates against IAM Security Token Service using the LDAP credentials the application uses those temporary AWS security credentials to access the appropriate S3 bucket. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. The application authenticates against LDAP and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM role The application can use the temporary credentials to access the appropriate S3 bucket.<br><b>C</b>. Develop an identity broker that authenticates against LDAP and then calls IAM Security Token Service to get IAM federated user credentials The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to understand <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html" target="_blank">IAM Identity providers and Federation</a><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html"></a><br> </p><p>You can <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html" target="_blank">Request temporary credentials</a> using either AssumeRole of GetFederationToken </p><p>Correct answer is <strong>B &amp; C</strong> as B authenticates with LDAP and calls the AssumeRole and C uses Custom Identity broker implementation, with authentication with LDAP and using federated token </p><p>Option A &amp; E are wrong as the application needs to authenticate against LDAP and not IAM. </p><p>Option D is wrong as you can't login to IAM using LDAP credentials </p><p><img src="./sap-02_files/enterprise-authentication-with-identity-broker-application.diagram.png"><br><br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120213">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 22 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249054"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are building a website that will retrieve and display highly sensitive information to users. The amount of traffic the site will receive is known and not expected to fluctuate. The site will leverage SSL to protect the communication between the clients and the web servers. Due to the nature of the site you are very concerned about the security of your SSL private key and want to ensure that the key cannot be accidentally or intentionally moved outside your environment. Additionally, while the data the site will display is stored on an encrypted EBS volume, you are also concerned that the web servers’ logs might contain some sensitive information; therefore, the logs must be stored so that they can only be decrypted by employees of your company. Which of these architectures meets all of the requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 13 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use Elastic Load Balancing to distribute traffic to a set of web servers. To protect the SSL private key, upload the key to the load balancer and configure the load balancer to offload the SSL traffic. Write your web server logs to an ephemeral volume that has been encrypted using a randomly generated AES key.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use Elastic Load Balancing to distribute traffic to a set of web servers. Use TCP load balancing on the load balancer and configure your web servers to retrieve the private key from a private Amazon S3 bucket on boot. Write your web server logs to a private Amazon S3 bucket using Amazon S3 server-side encryption.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use Elastic Load Balancing to distribute traffic to a set of web servers, configure the load balancer to perform TCP load balancing, use an AWS CloudHSM to perform the SSL transactions, and write your web server logs to a private Amazon S3 bucket using Amazon S3 server-side encryption.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use Elastic Load Balancing to distribute traffic to a set of web servers. Configure the load balancer to perform TCP load balancing, use an AWS CloudHSM to perform the SSL transactions, and write your web server logs to an ephemeral volume that has been encrypted using a randomly generated AES key. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Use Elastic Load Balancing to distribute traffic to a set of web servers. Configure the load balancer to perform TCP load balancing, use an AWS CloudHSM to perform the SSL transactions, and write your web server logs to an ephemeral volume that has been encrypted using a randomly generated AES key.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> over A as CloudHSM provides strong protection of private keys with physical device control and application having no access to the keys. Key point here is not allowing the key to move and the logs storage to be decrypted by employees of company<br> </p><p>Option B and C are wrong as with S3 server side encryption, AWS encrypts data and manages the key for you . Would need CSE for only employees to decrypt the data. </p><p>Option B is wrong as Retrieving private key and having it on server doesn’t make it secure from user having access to the box </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120567">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 23 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249055"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Which of the following are techniques to stop DDoS attacks on your AWS architecture? Choose 3 answers from the options below <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Add multiple elastic network interfaces (ENIs) to each EC2 instance to increase the network bandwidth</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use dedicated instances to ensure that each instance has the maximum performance possible.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use an Amazon Cloud Front distribution for both static and dynamic content.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use an Elastic Load Balancer with auto scaling groups at the web, App and Amazon Relational Database Service (RDS) tiers<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Add alert Amazon CloudWatch to look for high Network in and CPU utilization.<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Create processes and capabilities to quickly add and remove rules to the instance OS firewall. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use an Amazon Cloud Front distribution for both static and dynamic content.<br><b>D</b>. Use an Elastic Load Balancer with auto scaling groups at the web, App and Amazon Relational Database Service (RDS) tiers<br><b>E</b>. Add alert Amazon CloudWatch to look for high Network in and CPU utilization.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Refer to <a href="https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf" target="_blank">DDOS Mitigation Whitepaper</a> </p><p>Correct answer is <strong>C, D and E</strong><span class="redactor-invisible-space"> as C &amp; D would help to scale and E would help to Learn Normal Behavior and alert</span> </p><p>It mentions 4 aspects for DDOS mitigation</p><ul> <li>1. Minimize the Attack Surface Area</li> <li>2. Be Ready to Scale to Absorb the Attack</li> <li>3. Safeguard Exposed &amp; Hard to Scale Expensive Resources</li> <li>4. Learn Normal Behavior</li> </ul><p>Option A is wrong as using ENIs is more for HA and failover </p><p>Option B is wrong as using dedicated instances is more for an compliance and security aspect. </p><p>Option F is wrong as it would not work as the attack is fast and from multiple sources </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120416">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 24 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249056"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A DynamoDB table used for a busy online store is currently set to 3000RCU and 1000WCU and is experiencing performance issues during sale periods, the table has a good Partition and sort key architecture for the read and write workloads. You have identified that the read and write workloads during a sale period increase by 50x and 2x respectively. The sale periods are important to the business and occur twice per month. The business has asked for solutions to accommodate the extra load and while they are willing to spend extra, the solution should be the most economical, what should you suggest? (Select THREE)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Increase the RCU to 150,000 on the table during the sale periods and reduce it afterwards</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Integrate DAX with the online store application<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use SQS for read caching against the DynamoDB Table<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Increase the WCU to 2,000 on the table during busy periods and reduce it afterwards<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use SQS for write buffering against the DynamoDB table <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Integrate DAX with the online store application<br><b>D</b>. Increase the WCU to 2,000 on the table during busy periods and reduce it afterwards<br><b>E</b>. Use SQS for write buffering against the DynamoDB table<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B, D &amp; E</strong> </p><p>Option B as it would help in caching and improving read performance without increasing RCU </p><p>Option D as the write increases 2X during sale, the WCU can be increased and reduced after the sale. </p><p>Option E as SQS would provide a buffering layer for writes, without any need to increase WCU. </p><p>Option A is wrong as RCU to 150,000 would increase the cost considerably </p><p>Option C is wrong as SQS for read caching would make the user response asynchronous impacting the experience and performance. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%202%20-%20%23121178">AWS SAP-C01 Question feedback</a> </div></div></div><div class="question_info"><div class="question_no"><b>Question : 25 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249057"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An organization has a requirement to store 10TB worth of scanned files. They are required to have a search application in place to search through the scanned files. Which of the below mentioned options is ideal for implementing the storage and search facility?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use S3 with reduced redundancy to store and serve the scanned files. Install a commercial search application on EC2 Instances and configure with Auto-Scaling and an Elastic Load Balancer.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Model the environment using CloudFormation. Use an EC2 instance running Apache webserver and an open source search application, stripe multiple standard EBS volumes together to store the scanned files with a search index.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use S3 with standard redundancy to store and serve the scanned files. Use CloudSearch for query processing and use Elastic Beanstalk to host the website across multiple Availability Zones.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use a single-AZ RDS MySQL instance to store the search index for the scanned files and use an EC2 instance with a custom application to search based on the index. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use S3 with standard redundancy to store and serve the scanned files. Use CloudSearch for query processing and use Elastic Beanstalk to host the website across multiple Availability Zones.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as S3 Standard Redundancy would provide the storage for the files, which can then be indexed using CloudSearch to be searchable. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/s3/storage-classes/" target="_blank">S3 Storage Classes</a> &amp; <a href="https://aws.amazon.com/cloudsearch/" target="_blank">CloudSearch</a> </p><p><em>Amazon CloudSearch is a managed service in the AWS Cloud that makes it simple and cost-effective to set up, manage, and scale a search solution for your website or application.<br> </em> </p><p><em>Amazon CloudSearch supports 34 languages and popular search features such as highlighting, autocomplete, and geospatial search </em> </p><p>Option A is wrong as Reduced Redundancy would not an ideal choice for scanned files, as they might not reproducible. Also, commercial search application would not be cost effective </p><p>Option B is wrong as EBS striped volumes and custom application would not be cost effective.<br> </p><p>Option D is wrong as RDS is not an ideal solution to store files and custom application would not be cost effective to scale.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120603">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 26 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249058"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Refer to the architecture diagram of a batch processing solution using Simple Queue Service (SQS) to set up a message queue between EC2 instances, which are used as batch processors. CloudWatch monitors the number of Job requests (queued messages) and an Auto Scaling group adds or deletes batch servers automatically based on parameters set in Cloud Watch alarms. You can use this architecture to implement which of the following features in a cost effective and efficient manner? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Reduce the overall time for executing jobs through parallel processing by allowing a busy EC2 instance that receives a message to pass it to the next instance in a daisy-chain setup.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Implement fault tolerance against EC2 instance failure since messages would remain in SQS and worn can continue with recovery of EC2 instances implement fault tolerance against SQS failure by backing up messages to S3.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Implement message passing between EC2 instances within a batch by exchanging messages through SOS.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Coordinate number of EC2 instances with number of job requests automatically thus Improving cost effectiveness<br><b>E</b>. <input type="radio" disabled="">&nbsp;Handle high priority jobs before lower priority jobs by assigning a priority metadata field to SQS messages. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Coordinate number of EC2 instances with number of job requests automatically thus Improving cost effectiveness<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is understand the <a href="http://en.clouddesignpattern.org/index.php" target="_blank">Cloud Design pattern</a> </p><p>Correct answer is <strong>D</strong> as this is a <a href="http://en.clouddesignpattern.org/index.php/CDP:Job_Observer_Pattern" target="_blank">Job Observer pattern</a> which can be used to scale based on demand to handle load and reduce cost </p><p>Option A is wrong as the architecture does not provide a daisy chain implementation </p><p>Option B is wrong as the pattern is more of a scaling solution rather than fault tolerance solution </p><p>Option C is more of a <a href="http://en.clouddesignpattern.org/index.php/CDP:Queuing_Chain_Pattern" target="_blank">Queuing chain pattern</a> </p><p>Option E is wrong as it a <a href="http://en.clouddesignpattern.org/index.php/CDP:Priority_Queue_Pattern" target="_blank">Priority Queue Pattern</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120235">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 27 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249059"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your mission is to create a lights-out datacenter environment, and you plan to use AWS OpsWorks to accomplish this. First you created a stack and added an App Server layer with an instance running in it. Next you added an application to the instance, and now you need to deploy a MySQL RDS database instance. Which of the following answers accurately describe how to add a backend database server to an OpsWorks stack? Choose 3 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Add a new database layer and then add recipes to the deploy actions of the database and App Server layers.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use OpsWorks’ “Clone Stack” feature to create a second RDS stack in another Availability Zone for redundancy in the event of a failure in the Primary AZ. To switch to the secondary RDS instance, set the [:database] attributes to values that are appropriate for your server, which you can do by using custom JSON.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;The variables that characterize the RDS database connection—host, user, and so on—are set using the corresponding values from the deploy JSON’s [:deploy][:app_name][:database] attributes.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Cookbook attributes are stored in a repository, so OpsWorks requires that the “password”: “your_password” attribute for the RDS instance must be encrypted using at least a 256-bit key.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Set up the connection between the app server and the RDS layer by using a custom recipe. The recipe configures the app server as required, typically by creating a configuration file. The recipe gets the connection data such as the host and database name from a set of attributes in the stack configuration and deployment JSON that AWS OpsWorks installs on every instance. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Add a new database layer and then add recipes to the deploy actions of the database and App Server layers.<br><b>C</b>. The variables that characterize the RDS database connection—host, user, and so on—are set using the corresponding values from the deploy JSON’s [:deploy][:app_name][:database] attributes.<br><b>E</b>. Set up the connection between the app server and the RDS layer by using a custom recipe. The recipe configures the app server as required, typically by creating a configuration file. The recipe gets the connection data such as the host and database name from a set of attributes in the stack configuration and deployment JSON that AWS OpsWorks installs on every instance.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A, C &amp; E </strong>as you need to setup the database layer, setup connection between the app and database layer and configure variables for connectivity. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/customizing-rds.html" target="_blank">OpsWorks Customizing RDS</a> </p><p>Option B is wrong as Clone stack is not needed for RDS redundancy and Multi-AZ can be used. </p><p>Option D is wrong as OpsWorks does not require attribute to be encrypted. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120546">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 28 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249060"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company asked you to create a mobile feedback application. The application is built to work with DynamoDB as the backend and JavaScript as the frontend. During the usage of the application you notice that there are spikes in the application, especially in the DynamoDB area. Which TWO options provide a cost effective and scalable architecture for this application?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Enable DynamoDB Auto Scaling to meet the requirements</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Increase write capacity of DynamoDB to meet the peak loads<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Create a service that pulls SQS messages and writes these to DynamoDB to handle sudden spikes in DynamoDB<br><b>D</b>. <input type="checkbox" disabled="">&nbsp; Launch DynamoDB in Multi-AZ configuration with a global index to balance writes <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Enable DynamoDB Auto Scaling to meet the requirements<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A &amp; C</strong> </p><p><strong></strong>Option A as <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html" target="_blank">DynamoDB Auto Scaling</a> helps scale the throughput capacity as the demand changes, thus providing a cost effective and scalable solution. </p><p><em>DynamoDB auto scaling uses the AWS Application Auto Scaling service to dynamically adjust provisioned throughput capacity on your behalf, in response to actual traffic patterns. This enables a table or a global secondary index to increase its provisioned read and write capacity to handle sudden increases in traffic, without throttling. When the workload decreases, Application Auto Scaling decreases the throughput so that you don't pay for unused provisioned capacity.</em><span class="redactor-invisible-space"><em></em><br></span> </p><p>Correct answer is <strong>C</strong> as it's a feedback mobile application, SQS can be used to provide a scalable cost effective solution keeping the same provisioned throughput. </p><p>Option B is wrong as increasing the write throughput for DynamoDB would increase the cost </p><p>Option D is wrong as there is no Multi-AZ configuration. Also, Multi-AZ configurations are always for High Availability and not Scalability </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120406">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 29 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249061"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A video-sharing mobile application uploads files greater than 10 GB to an Amazon S3 bucket. However, when using the application in locations far away from the S3 bucket region, uploads take extended periods of time, and sometimes fail to complete. Which combination of methods would improve the performance of uploading to the application? (Select TWO.)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Configure an S3 bucket in each region to receive the uploads, and use cross-region replication to copy the files to the distribution bucket.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Modify the application to add random prefixes to the files before uploading.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Set up Amazon Route 53 with latency-based routing to route the uploads to the nearest S3 bucket region.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Enable S3 Transfer Acceleration on the S3 bucket, and configure the application to use the Transfer Acceleration endpoint for uploads.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Configure the application to break the video files into chunks and use a multipart upload to transfer files to Amazon S3. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Enable S3 Transfer Acceleration on the S3 bucket, and configure the application to use the Transfer Acceleration endpoint for uploads.<br><b>E</b>. Configure the application to break the video files into chunks and use a multipart upload to transfer files to Amazon S3.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>D &amp; E</strong> </p><p>Option D as <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html" target="_blank">S3 Transfer Acceleration</a> helps speed up the upload performance. <em>Amazon S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and an S3 bucket. Transfer Acceleration takes advantage of Amazon CloudFront’s globally distributed edge locations. As the data arrives at an edge location, data is routed to Amazon S3 over an optimized network path.</em> </p><p>Option E as <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html">multipart upload</a> helps provide better recoverability. </p><p><em>Depending on the size of the data you are uploading, Amazon S3 offers the following options:</em> </p><ul> <li><em><strong>Upload objects in a single operation—</strong>With a single PUT operation, you can upload objects up to 5 GB in size.</em></li> <li><em><strong>Upload objects in parts—</strong>Using the multipart upload API, you can upload large objects, up to 5 TB.The multipart upload API is designed to improve the upload experience for larger objects. You can upload objects in parts. These object parts can be uploaded independently, in any order, and in parallel. You can use a multipart upload for objects from 5 MB to 5 TB in size.</em></li> </ul><p><em>We recommend that you use multipart uploading in the following ways:</em> </p><p><em></em> </p><ul> <li><em>If you're uploading large objects over a stable high-bandwidth network, use multipart uploading to maximize the use of your available bandwidth by uploading object parts in parallel for multi-threaded performance.</em></li> <li><em>If you're uploading over a spotty network, use multipart uploading to increase resiliency to network errors by avoiding upload restarts. When using multipart uploading, you need to retry uploading only parts that are interrupted during the upload. You don't need to restart uploading your object from the beginning.</em></li> </ul><p>Option A is wrong as the mobile application needs to be configured for different endpoints and does not improve performance. Also, cross region replication would create duplication and increase cost. </p><p>Option B is wrong as random prefixes are no more needed for improving performance.<br> </p><p>Option C is wrong as Route 53 latency based routing works only with S3 static website.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121065">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 30 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249062"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company has developed a Ruby on Rails content management platform. Currently, OpsWorks with several stacks for dev, staging, and production is being used to deploy and manage the application. Now, the company wants to start using Python instead of Ruby. How should the company manage the new deployment such that it should be able to revert back to the old application with Ruby if the new deployment starts adversely impacting the existing customers?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a new stack that contains the Python application code and manages separate deployments of the application via the secondary stack using the deploy lifecycle action to implement the application code.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a new stack that contains a new layer with the Python code. Route only a small portion of the production traffic to use the new deployment stack. Once the application is validated, slowly increase the production traffic to the new stack using the Canary Deployment. Revert to the old stack, if the new stack deployment fails or does not work.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a new stack that contains the Python application code. Route all the traffic to the new stack at once so that all the customers get to access the updated application.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Update the existing host instances of the application with the new Python code. This will save the cost of having to maintain two stacks, hence cutting down on the costs. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create a new stack that contains a new layer with the Python code. Route only a small portion of the production traffic to use the new deployment stack. Once the application is validated, slowly increase the production traffic to the new stack using the Canary Deployment. Revert to the old stack, if the new stack deployment fails or does not work.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as it deploys the new stack via the canary deployment method where the new stack is tested only on a small portion production traffic first. If the new deployment has any errors it reverses back to the old deployment stack. </p><p>Option A is wrong as it fails to mention how the rollback would happen in case of an failure. </p><p>Option C is wrong as the traffic management should be gradual with proper testing and the ability to rollback quickly in case of a failure. </p><p>Option D is wrong because updating the existing production instances at once is risky and does not provide a quick rollback option. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120582">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 31 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249063"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have set up your company in AWS Organizations in a hierarchical manner. You now need to move an account from one organization to another organization. How can you do this with as little effort as possible?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;You can not do it. Delete the account and re-create it in the organization where you want it.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Have the account request membership in the new organization.<br><b>C</b>. <input type="radio" disabled="">&nbsp;First, remove the account from your organization and make it a standalone account. After making the account standalone, it can then be invited to join another organization.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Have the new organization send the account an invitation to join the new organization. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. First, remove the account from your organization and make it a standalone account. After making the account standalone, it can then be invited to join another organization.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as the migration process needs you remove the account from the existing organization and move the account to new organization. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/premiumsupport/knowledge-center/organizations-move-accounts/" target="_blank">Organizations Move Account</a> </p><p><em>Planning the migration process</em> </p><ul> <li><em>If you have only a few accounts to migrate, you can use the <a href="https://console.aws.amazon.com/organizations/" target="_blank">AWS Organizations console</a>.</em></li> <li><em>If you are migrating many accounts, you might use the <a href="https://docs.aws.amazon.com/organizations/latest/APIReference/Welcome.html" target="_blank">AWS Organizations API</a> or <a href="https://docs.aws.amazon.com/cli/latest/reference/organizations/index.html" target="_blank">AWS Command Line Interface (AWS CLI)</a> to move the accounts instead.</em></li> </ul><p><em>In either case, plan how you will do the following with each member account:</em> </p><ol> <li><em><a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_remove.html#orgs_manage_accounts_remove-from-master" target="_blank">Remove the member account from the old organization</a>.</em></li> <li><em><a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_invites.html" target="_blank">Send an invite from the new organization</a>.</em></li> <li><em><a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_invites.html#orgs_manage_accounts_accept-decline-invite" target="_blank">Accept the invite to the new organization from the member account</a>.</em></li> </ol><p><em>If you want the master account of the old organization to also join the new organization, do the following:</em> </p><ol> <li><em>Remove the member accounts from the organization using the preceding process.</em></li> <li><em><a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_org_delete.html" target="_blank">Delete the old organization</a>.</em></li> <li><em>Repeat the preceding process to invite the old master account to the new organization as a member account.</em></li> </ol> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121105">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 32 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249064"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your mobile application includes a photo-sharing service that is expecting tens of thousands of users at launch. You will leverage Amazon Simple Storage Service (S3) for storage of the user Images, and you must decide how to authenticate and authorize your users for access to these images. You also need to manage the storage of these images. Which two of the following approaches should you use? (Choose two)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Create an Amazon S3 bucket per user, and use your application to generate the S3 URI for the appropriate content.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use AWS Identity and Access Management (IAM) user accounts as your application-level user database, and offload the burden of authentication from your application code.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Authenticate your users at the application level, and use AWS Security Token Service (STS) to grant token-based authorization to S3 objects.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Authenticate your users at the application level, and send an SMS token message to the user. Create an Amazon S3 bucket with the same name as the SMS message token, and move the user’s objects to that bucket.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use a key-based naming scheme comprised from the user IDs for all user objects in a single Amazon S3 bucket. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Authenticate your users at the application level, and use AWS Security Token Service (STS) to grant token-based authorization to S3 objects.<br><b>E</b>. Use a key-based naming scheme comprised from the user IDs for all user objects in a single Amazon S3 bucket.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>C &amp; E </strong>as you can have application based authentication - using IAM Role <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html" target="_blank">Identity Providers &amp; Federation</a> - with temporary access to S3 objects and for authorization, create a folder for each user so that permissions can be limited for each user to their respective folder. </p><p>Refer AWS blog example - <a href="https://aws.amazon.com/articles/4617974389850313" target="_blank">Web Identity Federation with Mobile Applications</a> </p><p>Option A is wrong as this can be managed with a single bucket, without having to create multiple buckets.<br> </p><p>Option B is wrong as IAM users cannot be used for authentication.<br> </p><p>Option D is wrong as there is no SMS based token service.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120517">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 33 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249065"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Which of the following is not one of the ways to minimize the attack surface area as a DDOS minimization strategy in AWS? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure services such as Elastic Load Balancing and Auto Scaling to automatically scale.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Reduce the number of necessary Internet entry points.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Separate end user traffic from management traffic.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Eliminate non-critical Internet entry points. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Configure services such as Elastic Load Balancing and Auto Scaling to automatically scale.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as it is more to <strong>Be Ready to Scale to Absorb the Attack </strong>aspect<br> </p><p>Refer to <a href="https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf" target="_blank">DDOS Mitigation Whitepaper</a><br> </p> <pre>It mentions 4 aspects for DDOS mitigation
1. Minimize the Attack Surface Area
2. Be Ready to Scale to Absorb the Attack
3. Safeguard Exposed &amp; Hard to Scale Expensive Resources
4. Learn Normal Behavior
</pre><p><a href="https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf" target="_blank"></a> </p><pre>Strategy to minimize the Attack surface area
1. reduce the number of necessary Internet entry points,    
2. don’t expose back end servers,    
3. eliminate non-critical Internet entry points,    
4. separate end user traffic from management traffic,    
5. obfuscate necessary Internet entry points to the level that untrusted end users cannot access them, and    
6. decouple Internet entry points to minimize the effects of attacks.
</pre><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120396">AWS SAP-C01 Question feedback</a> </p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 34 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249066"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company runs a sensitive application on Amazon EC2 instances in a VPC. The company wants to monitor and analyze network traffic for possible threats. The solution must: Require minimal development and administration. Scale to accommodate large amounts of network traffic. Allow queries and visualizations of the data. Which solution will meet these requirements? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a flow log for the VPC and publish it to an Amazon DynamoDB table. Use an AWS Lambda function to read the data from the DynamoDB stream and write the log data to a table in Amazon Aurora. Connect the database from Amazon QuickSight to visualize the data.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a flow log for the VPC and publish it to an Amazon S3 bucket. Create an external table in Amazon Athena to query the log files, and connect to Amazon Athena from Amazon QuickSight to visualize the data.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use Amazon Kinesis Data Streams to capture the log files from Amazon CloudWatch. Use Amazon Kinesis Data Firehose to push the log files to Amazon S3. Create an external table in Amazon Athena to query the log files, and connect to Amazon Athena from Amazon QuickSight to visualize the data.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a flow log for the VPC and publish it into an in-memory Spark application running on an Amazon EMR cluster. Connect to the cluster from Amazon QuickSight to visualize the data using Spark SQL. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create a flow log for the VPC and publish it to an Amazon S3 bucket. Create an external table in Amazon Athena to query the log files, and connect to Amazon Athena from Amazon QuickSight to visualize the data.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as the VPC flow logs can help monitor and analyze network traffic. VPC logs are stored in S3 which can be queried using Athena and Visualizaed using QuickSight with minimal development effort. </p><p><em>VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. Flow log data can be published to Amazon CloudWatch Logs and Amazon S3. After you've created a flow log, you can retrieve and view its data in the chosen destination.</em> </p><p><em></em> </p><p><em>Flow logs can help you with a number of tasks; for example, to troubleshoot why specific traffic is not reaching an instance, which in turn helps you diagnose overly restrictive security group rules. You can also use flow logs as a security tool to monitor the traffic that is reaching your instance.</em> </p><p><em>Flow logs can publish flow log data to Amazon S3. </em><em>When publishing to Amazon S3, flow log data is published to an existing Amazon S3 bucket that you specify. Flow log records for all of the monitored network interfaces are published to a series of log file objects that are stored in the bucket. If the flow log captures data for a VPC, the flow log publishes flow log records for all of the network interfaces in the selected VPC</em> </p><p>Option A is wrong as using DynamoDB, Aurora with increase the cost as well as development effort with Lambda. </p><p>Option C is wrong as it does not mention capturing VPC flow logs. Flow logs can be either directed to CloudWatch Logs or S3. </p><p>Option D is wrong as in-memory Spark application running on EMR would required administration as well as development effort. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121081">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 35 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249067"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You're working as a consultant for a company designing a new hybrid architecture to manage part of their application infrastructure in the cloud and on-premise. As part of the infrastructure, they need to consistently transfer high amounts of data. They require a low latency and high consistency traffic to AWS. The company is looking to keep costs as low possible and is willing to accept slow traffic in the event of primary failure. Given these requirements how would you design a hybrid architecture? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Provision a Direct Connect connection to an AWS region using a Direct Connect partner. Provision a VPN connection as a backup in the event of Direct Connect connection failure.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a dual VPN tunnel for private connectivity, which increases network consistency and reduces latency. The dual tunnel provides a backup VPN in the case of primary failover.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Provision a Direct Connect connection which has automatic failover and backup built into the service.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Provision a Direct Connect connection to an AWS region using a Direct Connect provider. Provision a secondary Direct Connect connection as a failover. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Provision a Direct Connect connection to an AWS region using a Direct Connect partner. Provision a VPN connection as a backup in the event of Direct Connect connection failure.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is low latency and high consistency traffic as low cost backup. </p><p>Correct answer is <strong>A</strong> as Direct Connect can provide low latency and a high consistency connectivity and VPN can be the low cost failover option. </p><p>Option B is wrong as VPN alone does not provide low latency and consistency as it still used the internet for data transfer. </p><p>Option C is wrong ad Direct Connect does not provide automatic failover and are not redundant </p><p><em>Each connection consists of a single dedicated connection between ports on your router and an Amazon router. We recommend establishing a second connection if redundancy is required. When you request multiple ports at the same AWS Direct Connect location, they will be provisioned on redundant Amazon routers.</em><br></p><p>Option D is wrong as Direct Connect connection for both primary and failover would be expensive. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120391">AWS SAP-C01 Question feedback</a> </p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 36 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249068"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> In reviewing the auto scaling events for your application you notice that your application is scaling up and down multiple times in the same hour. What design choice could you make to optimize for the cost while preserving elasticity? Choose 2 answers.<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Modify the Amazon CloudWatch alarm period that triggers your auto scaling scale down policy.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Modify the Auto scaling group termination policy to terminate the oldest instance first.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Modify the Auto scaling policy to use scheduled scaling actions.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Modify the Auto scaling group cool down timers.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Modify the Auto scaling group termination policy to terminate newest instance first. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Modify the Amazon CloudWatch alarm period that triggers your auto scaling scale down policy.<br><b>D</b>. Modify the Auto scaling group cool down timers.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A &amp; D</strong> as the scaling activity is happening quite frequently, the reasons would either be that the alarms configured are causing the auto scaling to scale up and down fast or the cool down timers are small due to which the auto scaling activity is triggered before the new instance gets a chance to handle traffic. </p><p>Option B is wrong as terminating oldest instance would help save cost but would not prevent the auto scaling from scale up/down cycle. </p><p>Option C is wrong as scheduled scaling only helps when the pattern is known </p><p>Option E is wrong as terminating newest instance would increase cost but also would not prevent the auto scaling from scale up/down cycle. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120426">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 37 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249069"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have two different groups using Redshift to analyze data of a petabyte-scale data warehouse. Each query issued by the first group takes approximately 1-2 hours to analyze the data while the second group's queries only take between 5-10 minutes to analyze data. You don't want the second group's queries to wait until the first group's queries are finished. You need to design a solution so that this does not happen. Which of the following would be the best and cheapest solution to deploy to solve this dilemma? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a read replica of Redshift and run the second team's queries on the read replica.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create two separate workload management groups and assign them to the respective groups.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Pause the long queries when necessary and resume them when there are no queries happening.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Start another Redshift cluster from a snapshot for the second team if the current Redshift cluster is busy processing long queries. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create two separate workload management groups and assign them to the respective groups.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as Redshift workload management allows proper usage of cluster. </p><p>Refer to the <a href="https://aws.amazon.com/blogs/big-data/run-mixed-workloads-with-amazon-redshift-workload-management/" target="_blank">AWS Blog for Redshift to run mixed workloads</a> </p><p>Amazon Redshift Workload Management allows you to manage workloads of various sizes and complexity for specific environments. Parameter groups contain WLM configuration, which determines how many query queues are available for processing and how queries are routed to those queues<span class="redactor-invisible-space">. Following settings are available</span><br> </p><p><span class="redactor-invisible-space"></span> </p><ul> <li>How many queries can run concurrently in each queue</li> <li>How much memory is allocated among the queues</li> <li>How queries are routed to queues, based on criteria such as the user who is running the query or a query label</li> <li>Query timeout settings for a queue</li> </ul> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120411">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 38 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249070"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are implementing AWS Direct Connect. You intend to use AWS public service end points such as Amazon S3, across the AWS Direct Connect link. You want other Internet traffic to use your existing link to an Internet Service Provider. What is the correct way to configure AWS Direct Connect for access to services such as Amazon S3?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure a public Interface on your AWS Direct Connect link Configure a static route via your AWS Direct Connect link that points to Amazon S3 Advertise a default route to AWS using BGP.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a private interface on your AWS Direct Connect link. Configure a static route via your AWS Direct connect link that points to Amazon S3 Configure specific routes to your network in your VPC.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a public interface on your AWS Direct Connect link. Redistribute BGP routes into your existing routing infrastructure advertise specific routes for your network to AWS<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a private interface on your AWS Direct connect link. Redistribute BGP routes into your existing routing infrastructure and advertise a default route to AWS. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create a public interface on your AWS Direct Connect link. Redistribute BGP routes into your existing routing infrastructure advertise specific routes for your network to AWS<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> </p><p>Refer to the AWS documentation for Direct Connect <a href="http://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html" target="_blank">Virtual Interfaces</a> </p><pre>To access public resources, you must set up a public virtual interface 
and establish a border gateway protocol (BGP) session
After you have created a public virtual interface and established a BGP session to it, 
your router learns the routes and transfers data
</pre><p>Options B &amp; D are wrong as private interface is needed for VPC and instance within it. </p><p>Option A is wrong as you need to setup BGP and not static route </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120242">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 39 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249071"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your organization is planning to shift one of the high-performance data analytics applications purchased from the 3rd party vendor to the AWS. Currently, the application works in an on-premise load balancer and all the data is stored in a very large shared file system for low-latency and high throughput purpose. The management wants minimal disruption to existing service and also wants to do stepwise migration for easy rollback. How can the organization plan its migration? (Select THREE)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Save all the data on S3 and use it as shared storage, use an application load balancer with EC2 instances to share the processing load</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Create a RAID 1 storage using EBS and run the application on EC2 with application-level load balancers to share the processing load<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use the VPN or Direct Connect to create a link between your company premise and AWS regional data center<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use the VPC Peering to create a link between your company premise and AWS regional data center<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Create an EFS with provisioned throughput and share the storage between your on-premise instances and EC2 instances<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Setup a Route 53 record to distribute the load between on-premise and AWS load balancer with the weighted routing policy<br><b>G</b>. <input type="checkbox" disabled="">&nbsp;Setup a CloudFront to distribute the load between on-premise and AWS load balancer with the weighted routing policy <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use the VPN or Direct Connect to create a link between your company premise and AWS regional data center<br><b>E</b>. Create an EFS with provisioned throughput and share the storage between your on-premise instances and EC2 instances<br><b>F</b>. Setup a Route 53 record to distribute the load between on-premise and AWS load balancer with the weighted routing policy<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>C, E &amp; F</strong>. </p><p>Option C as VPN or Direct Connect would enable instances on-premises and AWS to communication and access the same shared storage. </p><p>Option E as EFS would provide the shared storage. </p><p>Option F as Route 53 can help route traffic between on-premises and AWS load balancer is a weighted manner. This can be used for gradual migration to AWS. </p><p>Option A is wrong as S3 is not an ideal storage choice for shared file system. It is an object storage. </p><p>Option B is wrong as RAID 1 EBS volume provides fault tolerance, but it cannot be shared.<br> </p><p>Option D is wrong as VPC Peering only allows peering between VPCs within AWS.<br> </p><p>Option G is wrong as CloudFront does not distribute load using weighted policy. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120766">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 40 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249072"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> The company you work for has a huge amount of infrastructure built on AWS. However there has been some concerns recently about the security of this infrastructure, and an external auditor has been given the task of running a thorough check of all of your company's AWS assets. The auditor will be in the USA while your company's infrastructure resides in the Asia Pacific (Sydney) region on AWS. Initially, he needs to check all of your VPC assets, specifically, security groups and NACLs You have been assigned the task of providing the auditor with a login to be able to do this. Which of the following would be the best and most secure solution to provide the auditor with, so he can begin his initial investigations? Choose the correct answer<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an IAM user tied to an administrator role. Also provide an additional level of security with MFA.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create an IAM user with full VPC access but set a condition that will not allow him to modify anything if the request is from any IP other than his own.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Give him root access to your AWS Infrastructure, because he is an auditor he will need access to every service.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an IAM user who will have read-only access to your AWS VPC infrastructure and provide the auditor with those credentials. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Create an IAM user who will have read-only access to your AWS VPC infrastructure and provide the auditor with those credentials.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as Auditor would only need read only access, so the best approach would be to create an IAM user with Read Only access i.e. least privilege access. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html" target="_blank">IAM Best Practices</a> </p><p>Option A is wrong as the best practice should be to provide least privilege and administrator access would provide all access to AWS except billing. </p><p>Option C is wrong as the root access should never be given and should be given a IAM user access with limited privileges. </p><p>Option B is wrong as the best practice should be to provide least privilege as required by the user. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120531">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 41 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249073"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A research scientist is planning for the one-time launch of an Elastic MapReduce cluster and is encouraged by her manager to minimize the costs. The cluster is designed to ingest 200TB of genomics data with a total of 100 Amazon EC2 instances and is expected to run for around four hours. The resulting data set must be stored temporarily until archived into an Amazon RDS Oracle instance. Which option will help save the most money while meeting requirements?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Store ingest and output files in Amazon S3. Deploy on-demand for the master and core nodes and spot for the task nodes.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Optimize by deploying a combination of on-demand, RI and spot-pricing models for the master, core and task nodes. Store ingest and output files in Amazon S3 with a lifecycle policy that archives them to Amazon Glacier.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Store the ingest files in Amazon S3 RRS and store the output files in S3. Deploy Reserved Instances for the master and core nodes and on-demand for the task nodes.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Deploy on-demand master, core and task nodes and store ingest and output files in Amazon S3 RRS <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Store ingest and output files in Amazon S3. Deploy on-demand for the master and core nodes and spot for the task nodes.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to save most money while being able to process the huge data. </p><p>Correct answer is <strong>A</strong> as it follows best practice of using On demand for master and core and spot for task nodes also help reduce cost using spot instances. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances.html" target="_blank">EMR Instances</a> </p><p>Option B is wrong as RI will make it expensive as there is no consistent requirement </p><p>Option C is wrong as RI will make it expensive as there is no consistent requirement. </p><p>Option D is wrong as input should be in S3 standard, as re-ingesting the input data might end up being more costly then holding the data for limited time in standard S3 </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120256">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 42 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249074"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing a system, which needs, at minimum, 8 m4.large instances operating to service traffic. When designing a system for high availability in the us-east-1 region, which has 6 Availability Zones, you company needs to be able to handle death of a full availability zone. How should you distribute the servers, to save as much cost as possible, assuming all of the EC2 nodes are properly linked to an ELB? Your VPC account can utilize us-east-1's AZ's a through f, inclusive.<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;3 servers in each of AZ's a through d, inclusive.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;8 servers in each of AZ's a and b.<br><b>C</b>. <input type="radio" disabled="">&nbsp;2 servers in each of AZ's a through e, inclusive.<br><b>D</b>. <input type="radio" disabled="">&nbsp;4 servers in each of AZ's a through c, inclusive. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. 2 servers in each of AZ's a through e, inclusive.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as you need to design for N+1 redundancy on Availability Zones. </p><pre>ZONE_COUNT = (REQUIRED_INSTANCES / INSTANCE_COUNT_PER_ZONE) + 1.
</pre><p>To minimize cost, spread the instances across as many possible zones as you can. By using a though e, you are allocating 5 zones. Using 2 instances, you have 10 total instances. If a single zone fails, you have 4 zones left, with 2 instances each, for a total of 8 instances. By spreading out as much as possible, you have increased cost by only 25% and significantly de-risked an availability zone failure. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120370">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 43 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249075"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An administrator is using Amazon CloudFormation to deploy a three tier web applications that consists of a web tier and application tier that will utilize Amazon DynamoDB for storage when creating the CloudFormation template which of the following would allow the application instance access to the DynamoDB tables without exposing API credentials?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an Identity and Access Management Role that has the required permissions to read and write from the required DynamoDB table and associate the Role to the application instances by referencing an instance profile.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use the Parameter section in the Cloud Formation template to nave the user input Access and Secret Keys from an already created IAM user that has me permissions required to read and write from the required DynamoDB table.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an Identity and Access Management Role that has the required permissions to read and write from the required DynamoDB table and reference the Role in the instance profile property of the application instance.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an identity and Access Management user in the CloudFormation template that has permissions to read and write from the required DynamoDB table, use the GetAtt function to retrieve the Access and secret keys and pass them to the application instance through user-data. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create an Identity and Access Management Role that has the required permissions to read and write from the required DynamoDB table and reference the Role in the instance profile property of the application instance.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as Role needs to be referenced in the instance profile property which is used by the application. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-instanceprofile.html" target="_blank">CloudFormation IAM Instance Profile</a> </p><pre>{
    "Resources": {
        "MyInstanceProfile": {
            "Type": "AWS::IAM::InstanceProfile",
            "Properties": {
                "Path": "/",
                "Roles": ["MyIAMRole"]
            }
        },
        "Instance": {
            "Type": "AWS::EC2::Instance",
            "Properties": {
                "IamInstanceProfile": {
                    "Ref": "MyInstanceProfile"
                }
            }
        }
    }
}
</pre> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120526">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 44 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249076"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A customer needs corporate IT governance and cost oversight of all AWS resources consumed by its divisions. The divisions want to maintain administrative control of the discrete AWS resources they consume and keep those resources separate from the resources of other divisions. Which of the following options, when used together will support the autonomy/control of divisions while enabling corporate IT to maintain governance and cost oversight? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Use AWS Consolidated Billing and disable AWS root account access for the child accounts.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Enable IAM cross-account access for all corporate IT administrators in each child account.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Create separate VPCs for each division within the corporate IT AWS account.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use AWS Consolidated Billing to link the divisions’ accounts to a parent corporate account.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Write all children AWS CloudTrail and Amazon CloudWatch logs to each child account’s Amazon S3 'Log' bucket. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Enable IAM cross-account access for all corporate IT administrators in each child account.<br><b>D</b>. Use AWS Consolidated Billing to link the divisions’ accounts to a parent corporate account.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key here is to understand <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html" target="_blank">Cross Account access with IAM Roles</a> &amp; <a href="http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html" target="_blank">Consolidated Billing</a><br> </p><p>Correct answer is <strong>B &amp; D</strong> as B provides IT governance using the Cross Account access using IAM roles and D would provide cost oversight using consolidate billing </p><p>Option A is wrong as you need to link accounts and disabling root access is just a best practice but does not help here </p><p>Option C is wrong as using it you would need to control access at VPC level and also does not provide cost oversight which might need tagging to be implemented </p><p>Option E is wrong as the preferred approach would be to store logs from multiple accounts to a single S3 bucket with CloudTrail for IT Governance and CloudWatch alerts for Cost Oversight </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120206">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 45 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249077"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have recently joined a startup company building sensors to measure street noise and air quality in urban areas. The company has been running a pilot deployment of around 100 sensors for 3 months. Each sensor uploads 1KB of sensor data every minute to a backend hosted on AWS. During the pilot, you measured a peak or 10 IOPS on the database, and you stored an average of 3GB of sensor data per month in the database. The current deployment consists of a load-balanced auto scaled Ingestion layer using EC2 instances and a PostgreSQL RDS database with 500GB standard storage. The pilot is considered a success and your CEO has managed to get the attention or some potential investors. The business plan requires a deployment of at least 100K sensors, which needs to be supported by the backend. You also need to store sensor data for at least two years to be able to compare year over year Improvements. To secure funding, you have to make sure that the platform meets these requirements and leaves room for further scaling. Which setup will meet the requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Add an SQS queue to the ingestion layer to buffer writes to the RDS instance</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Ingest data into a DynamoDB table and move old data to a Redshift cluster <br><b>C</b>. <input type="radio" disabled="">&nbsp;Replace the RDS instance with a 6 node Redshift cluster with 96TB of storage<br><b>D</b>. <input type="radio" disabled="">&nbsp;Keep the current architecture but upgrade RDS storage to 3TB and 10K provisioned IOPS <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Ingest data into a DynamoDB table and move old data to a Redshift cluster <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is backend supporting the data with 2 years retention and architecture being scalable </p><p>Correct answer is <strong>B</strong> as DynamoDB can be used to support the ingestion throughput via autoscaled instances and later store data into Redshift for analysis </p><p>Option A &amp; D are wrong as RDS would not be scalable and performant with high input rate and storage for 2 years </p><p>Option C is wrong as Redshift is designed for data warehousing and would not be able to support the ingestion throughput </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120248">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 46 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249078"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are working for a large company and you have set up the AWS consolidated billing with a master account and several linked accounts. However in the master account’s cost allocation report that Cost Explorer provides, it does not use the AWS generated cost allocation tags to organize the resource costs. For example, there is an AWS tag called "createdBy" which tracks who created a resource. But in the report, the operator cannot track the cost filtered by "createdBy" tag. How can you fix this issue in the cost allocation report?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use master account to login into AWS console and activate the user-defined tags in the Billing and Cost Management console.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;For both master account and linked accounts, use AWS CLI to activate AWS generated tags for Billing and Cost Management.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Login into AWS console for both master account and linked accounts; activate the user-defined tags in Billing -&gt; Cost Explorer -&gt; Cost Allocation Tags.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Login into AWS console using master account and activate the AWS generated tags in the Billing and Cost Management console. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Login into AWS console using master account and activate the AWS generated tags in the Billing and Cost Management console.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as "createdBy" is an AWS Generated Tag and needs to be activated. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html" target="_blank">Cost Allocation Tags</a> </p><p><em>A tag is a label that you or AWS assigns to an AWS resource. Each tag consists of a key and a value. A key can have more than one value. You can use tags to organize your resources, and cost allocation tags to track your AWS costs on a detailed level. After you activate cost allocation tags, AWS uses the cost allocation tags to organize your resource costs on your cost allocation report, to make it easier for you to categorize and track your AWS costs. AWS provides two types of cost allocation tags, an AWS generated tags and user-defined tags. AWS defines, creates, and applies the AWS generated tags for you, and you define, create, and apply user-defined tags. You must activate both types of tags separately before they can appear in Cost Explorer or on a cost allocation report.</em> </p><p><em></em> </p><p><em>The following diagram illustrates the concept. In the example, you've assigned and activated tags on two Amazon EC2 instances, one tag called Cost Center and another tag called Stack. Each of the tags has an associated value. You also activated the AWS generated tags, <code>createdBy</code>before creating these resources. The <code>createdBy</code> tag tracks who created a resource. The user-defined tags use the <code>user</code> prefix, and the AWS generated tag uses the <code>aws:</code> prefix.</em> </p><p>Options A &amp; C are wrong as "createdBy" is an AWS generated tag </p><p>Option B is wrong as AWS generated tags can only be activated in master account. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120829">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 47 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249079"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> When deploying a highly available 2-tier web application on AWS, which combination of AWS services meets the requirements? AWS Direct Connect Amazon Route 53 AWS Storage Gateway Elastic Load Balancing Amazon EC2 Auto scaling Amazon VPC AWS Cloud Trail <br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;2,4,5 and 6</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;3,4,5 and 8<br><b>C</b>. <input type="radio" disabled="">&nbsp;1 through 8<br><b>D</b>. <input type="radio" disabled="">&nbsp;1,3,5 and 7<br><b>E</b>. <input type="radio" disabled="">&nbsp;1,2,5 and 6 <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. 2,4,5 and 6<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as for HA Route 53, ELB, Auto Scaling, EC2 instances </p><p>Options C, D &amp; E are wrong as Direct Connect is more for connectivity with on-premises data center and does not provide redundancy </p><p>Option B, C are wrong as CloudTrail is for audit logging </p><p>Option B &amp; D are wrong as Storage Gateway is more of archival and backup solution </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120365">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 48 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249080"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is performing a full migration of its systems from an on-premises data center to AWS. The company needs to move all the data stored on-premises to Amazon S3 within the next 4 weeks. Currently, the on-premises storage holds 900 TB of data and is connected to the Internet over a 100 Mbps link. Up to 20% of the link's throughput is regularly used in real time by existing systems. What is the MOST cost-effective way to perform the data migration in the given time frame?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Order multiple AWS Snowball devices to ship the data.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use a multipart upload to transfer the data over the existing link.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Set up an AWS Direct Connect link to upload the data.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Configure a VPN tunnel for the AWS environment to upload the data. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Order multiple AWS Snowball devices to ship the data.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as with 900TB of data and 80% of 100Mbps line, it would take years to transfer the data. Snowball provides a quick and cost effective option to transfer huge data from on-premises to AWS S3. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/snowball/" target="_blank">Snowball</a> </p><p><em>Snowball is a petabyte-scale data transport solution that uses devices designed to be secure to transfer large amounts of data into and out of the AWS Cloud. Using Snowball addresses common challenges with large-scale data transfers including high network costs, long transfer times, and security concerns. Customers today use Snowball to migrate analytics data, genomics data, video libraries, image repositories, backups, and to archive part of data center shutdowns, tape replacement or application migration projects. Transferring data with Snowball is simple, fast, more secure, and can be as little as one-fifth the cost of transferring data via high-speed Internet.</em><em></em><br> </p><p><img src="./sap-02_files/Migration-Speeds.png"><br><br> </p><p>Options B &amp; D are wrong as the transfer is still done through internet. </p><p>Option C is wrong as Direct Connect needs time to setup and is not that cost effective for one time data transfer. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121038">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 49 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249081"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A Company is designing a high availability solution for a customer. This customer's requirements are that their application needs to be able to handle an unexpected amount of load and allow site visitors to read data from a DynamoDB table, which contains the results of an online polling system. Given this information, what would be the best and most cost-saving method for architecting and developing this application? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a CloudFront distribution that serves the HTML web page, but send the visitors to an Auto Scaling ELB application pointing to EC2 instances.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use the JavaScript SDK and build a static HTML page, hosted inside of an Amazon S3 bucket; use CloudFront and Route 53 to serve the website, which uses JavaScript client-side language to communicate with DynamoDB.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a Lambda script, which pulls the most recent DynamoDB polling results and creates a custom HTML page, inside of Amazon S3 and use CloudFront and Route 53 to serve the static website.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Deploy an Auto Scaling application with Elastic Load Balancer pointing to EC2 instances that use a server-side SDK to communicate with the DynamoDB table. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Use the JavaScript SDK and build a static HTML page, hosted inside of an Amazon S3 bucket; use CloudFront and Route 53 to serve the website, which uses JavaScript client-side language to communicate with DynamoDB.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as the requirement is for a cost saving and simplest solution, the site can be hosted on S3 as a static site with JavaScript SDK to interact with DynamoDB. Use Route 53 and CloudFront to deliver the site and caching to reduce the read load on DynamoDB, thus saving on the provisioned reads. </p><p>Option A &amp; D are wrong as using ELB, Auto Scaling with EC2 instances would increase the price. </p><p>Option C is wrong as using Lambda on DynamoDB to poll frequently would increase the cost. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120438">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 50 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249082"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are developing a new mobile application and are considering storing user preferences in AWS, which would provide a more uniform cross-device experience to users using multiple mobile devices to access the application. The preference data for each user is estimated to be 50KB in size. Additionally 5 million customers are expected to use the application on a regular basis. The solution needs to be cost-effective, highly available, scalable and secure, how would you design a solution to meet the above requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Setup an RDS MySQL instance in 2 availability zones to store the user preference data. Deploy a public facing application on a server in front of the database to manage security and access credentials</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Setup a DynamoDB table with an item for each user having the necessary attributes to hold the user preferences. The mobile application will query the user preferences directly from the DynamoDB table. Utilize STS. Web Identity Federation, and DynamoDB Fine Grained Access Control to authenticate and authorize access<br><b>C</b>. <input type="radio" disabled="">&nbsp;Setup an RDS MySQL instance with multiple read replicas in 2 availability zones to store the user preference data .The mobile application will query the user preferences from the read replicas. Leverage the MySQL user management and access privilege system to manage security and access credentials.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Store the user preference data in S3 Setup a DynamoDB table with an item for each user and an item attribute pointing to the user’ S3 object. The mobile application will retrieve the S3 URL from DynamoDB and then access the S3 object directly utilize STS, Web identity Federation, and S3 ACLs to authenticate and authorize access. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Setup a DynamoDB table with an item for each user having the necessary attributes to hold the user preferences. The mobile application will query the user preferences directly from the DynamoDB table. Utilize STS. Web Identity Federation, and DynamoDB Fine Grained Access Control to authenticate and authorize access<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to design a cost-effective, highly available, scalable and secure solution. </p><p>Correct answer is <strong>B</strong> as DynamoDB is ideal for storing user preferences. The mobile application can authenticate using web identity federation and STS and access DynamoDB table. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WIF.html" target="_blank">Web Identity Federation</a></p><p>Option A is wrong as RDS is not scalable and cost effective. Also DB in 2 AZs doesn't make sense. It does not describe how the authentication will take place. </p><p>Option C is wrong as MySQL user management and access privilege system cannot be used for controlling access. </p><p>Option D is wrong as DynamoDB can store up to 400KB for a single item. So there is no need to store the data in S3 and point it from DynamoDB, which would make is slower. Also, S3 is not a good solution if the user preferences are changing. Refer <a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html#limits-items" target="_blank">DynamoDB limits</a> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120195">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 51 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249083"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing an SSL/TLS solution that requires HTTPS clients to be authenticated by the Web server using client certificate authentication. The solution must be resilient. Which of the following options would you consider for configuring the web server infrastructure? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Configure ELB with TCP listeners on TCP/443. And place the Web servers behind it.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Configure your Web servers with EIPs. Place the Web servers in a Route 53 Record Set and configure health checks against all Web servers.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Configure ELB with HTTPS listeners, and place the Web servers behind it.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Configure your web servers as the origins for a CloudFront distribution. Use custom SSL certificates on your CloudFront distribution <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Configure ELB with TCP listeners on TCP/443. And place the Web servers behind it.<br><b>B</b>. Configure your Web servers with EIPs. Place the Web servers in a Route 53 Record Set and configure health checks against all Web servers.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct Answer is A &amp; B </p><p>Key point is ELB does not support client certificate authentication </p><p>Option A - As you can terminate SSL on the instance using client-side certificate </p><p>Option B - You can remove the ELB and use Route 53 directly with the Web Servers. </p><p>Option C is wrong as ELB with HTTPs does not support Client-Side certificates </p><p>Option D is wrong as CloudFront does not support Client-Side ssl certificates. Refer <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorCustomOrigin.html#RequestCustomClientSideSslAuth" target="_blank">AWS documentation</a> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120179">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 52 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249084"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are an architect for a news-sharing mobile application. Anywhere in the world, your users can see local news on of topics they choose. They can post pictures and videos from inside the application. Since the application is being used on a mobile phone, connection stability is required for uploading content, and delivery should be quick. Content is accessed a lot in the first minutes after it has been posted, but is quickly replaced by new content before disappearing. The local nature of the news means that 90 percent of the uploaded content is then read locally (less than a hundred kilometers from where it was posted). What solution will optimize the user experience when users upload and view content (by minimizing page load times and minimizing upload times)?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Upload and store the content in a central Amazon Simple Storage Service (S3) bucket, and use an Amazon Cloud Front Distribution for content delivery.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Upload and store the content in an Amazon Simple Storage Service (S3) bucket in the region closest to the user, and use multiple Amazon Cloud Front distributions for content delivery.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Upload the content to an Amazon Elastic Compute Cloud (EC2) instance in the region closest to the user, send the content to a central Amazon Simple Storage Service (S3) bucket, and use an Amazon Cloud Front distribution for content delivery.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use an Amazon CloudFront distribution for uploading the content to a central Amazon Simple Storage Service (S3) bucket and for content delivery. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Use an Amazon CloudFront distribution for uploading the content to a central Amazon Simple Storage Service (S3) bucket and for content delivery.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point is to minimize GET and POST/PUT request. </p><p>Correct answer is <strong>D</strong> as CloudFront distribution can be used to handle upload requests which needs to be enabled. </p><p>Refer to the AWS Announcement for <a href="https://aws.amazon.com/about-aws/whats-new/2013/10/15/amazon-cloudfront-now-supports-put-post-and-other-http-methods/" target="_blank">CloudFront support for PUT/POST</a> </p><p>When end users upload content, CloudFront will send the upload request back to the origin web server (such as an Amazon S3 bucket, an Amazon EC2 instance, an Elastic Load Balancer, or your own origin server) over an optimized route that uses persistent connections, TCP/IP and network path optimizations </p><p>Option A, B and C are wrong as it does not improve the upload times as the request still needs to come to the resource in a specific region </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120227">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 53 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249085"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have a Linux EC2 web server instance running inside a VPC. The instance is in a public subnet and has an EIP associated with it so you can connect to it over the Internet via HTTP or SSH. The instance was also fully accessible when you last logged in via SSH and was also serving web requests on port 80. Now you are not able to SSH into the host nor does it respond to web requests on port 80 that were working fine last time you checked. You have double-checked that all networking configuration parameters (security groups route tables, IGW, EIP. NACLs etc.) are properly configured and you haven’t made any changes to those anyway since you were last able to reach the Instance. You look at the EC2 console and notice that system status check shows “impaired.” Which should be your next step in troubleshooting and attempting to get the instance back to a healthy state so that you can log in again?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Stop and start the instance so that it will be able to be redeployed on a healthy host system that most likely will fix the “impaired” system status</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Reboot your instance so that the operating system will have a chance to boot in a clean healthy state that most likely will fix the ‘impaired” system status<br><b>C</b>. <input type="radio" disabled="">&nbsp;Add another dynamic private IP address to me instance and try to connect via that new path, since the networking stack of the OS may be locked up causing the “impaired” system status.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Add another Elastic Network Interface to the instance and try to connect via that new path since the networking stack of the OS may be locked up causing the “impaired” system status<br><b>E</b>. <input type="radio" disabled="">&nbsp;un-map and then re-map the EIP to the instance, since the IGW/NAT gateway may not be working properly, causing the “impaired” system status <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Stop and start the instance so that it will be able to be redeployed on a healthy host system that most likely will fix the “impaired” system status<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p><i>Correct answer is <strong>A</strong></i> </p><ul> <li><em>For an instance using an Amazon EBS-backed AMI, stop and restart the instance.</em></li> <li><em>For an instance using an instance-store backed AMI, terminate the instance and launch a replacement.</em></li> </ul><p>Option B is wrong as reboot does not help and launches the instance on the same machine &amp; host. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstances.html#InitialSteps" target="_blank">EC2 Troubleshooting Initial steps</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120432">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 54 of 55 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249086"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are hired as an AWS solutions architect in a startup company. You notice that there are some issues for the backup strategy of EC2 instances and there is no snapshot lifecycle management at all. Users just create snapshots manually without a routine policy to control. You want to suggest using a proper EBS Snapshot Lifecycle policy. How would you persuade your team leads to approve this suggestion? (Select TWO)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;A snapshot lifecycle policy helps to retain backups as required by auditors or internal compliance.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;An EBS Snapshot Lifecycle helps to protect valuable data by enforcing a regular backup schedule.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;A proper snapshot lifecycle policy is able to reduce storage costs as the snapshots taken by the schedule policy are free<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;User can design their own schedule to backup snapshots according to different requirements, such as every 15 mins, 1 hour, 12 hours, 24 hours, 1 week, etc. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. A snapshot lifecycle policy helps to retain backups as required by auditors or internal compliance.<br><b>B</b>. An EBS Snapshot Lifecycle helps to protect valuable data by enforcing a regular backup schedule.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A &amp; B </strong>as Snapshot lifecycle can enforce regular backups to protect data and inline with compliance and auditor requirements </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html" target="_blank">EBS Snapshot Lifecycle</a> </p><p><em>You can use Amazon Data Lifecycle Manager (Amazon DLM) to automate the creation, retention, and deletion of snapshots taken to back up your Amazon EBS volumes. Automating snapshot management helps you to:</em> </p><ul> <li><em>Protect valuable data by enforcing a regular backup schedule.</em></li> <li><em>Retain backups as required by auditors or internal compliance.</em></li> <li><em>Reduce storage costs by deleting outdated backups.</em></li> </ul><p><em>Combined with the monitoring features of Amazon CloudWatch Events and AWS CloudTrail, Amazon DLM provides a complete backup solution for EBS volumes at no additional cost.</em> </p><p>Option C is wrong as Snapshots taken are not free and there is a cost associated. However, cost can be reduced by implementing deletion policies. </p><p>Option D is wrong as schedule policies cannot be created 15 mins or every hour. </p><p><em><strong>Create snapshots every</strong> <strong>n</strong> <strong>Hours</strong>—The number of hours between policy runs. The supported values are 2, 3, 4, 6, 8, 12, and 24.</em> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120774">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 55 of 55 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249087"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company is storing millions of sensitive transactions across thousands of 100-GB files that must be encrypted in transit and at rest. Analysts concurrently depend on subsets of files, which can consume up to 5TB of space, to generate simulations that can be used to steer business decisions. You are required to design an AWS solution that can cost effectively accommodate the long-term storage and in-flight subsets of data.<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use Amazon Simple Storage Service (S3) with server-side encryption, and run simulations on subsets in ephemeral drives on Amazon EC2.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use Amazon S3 with server-side encryption, and run simulations on subsets in-memory on Amazon EC2.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use HDFS on Amazon EMR, and run simulations on subsets in ephemeral drives on Amazon EC2.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Use HDFS on Amazon Elastic MapReduce (EMR), and run simulations on subsets in-memory on Amazon Elastic Compute Cloud (EC2).<br><b>E</b>. <input type="radio" disabled="">&nbsp;Store the full data set in encrypted Amazon Elastic Block Store (EBS) volumes, and regularly capture snapshots that can be cloned to EC2 workstations <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Use Amazon Simple Storage Service (S3) with server-side encryption, and run simulations on subsets in ephemeral drives on Amazon EC2.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as the S3 with SSE provides encryption at rest and HTTPS can be used to push data to S3 for encryption in transit. S3 provides an option for cost effective long term storage. Ephemeral drives would help run simulations and the data would lost once the EC2 instance is terminated. </p><p>Option B is wrong as S3 with SSE provides encryption at rest and HTTPS can be used to push data to S3 for encryption in transit. However, in memory simulations with 5 TB data would not be feasible. </p><p>Option C &amp; D are wrong as HDFS is not an cost effective solution as data nodes would be required to store the data and it does not provide encryption by default. </p><p>Option E is wrong as EBS for long term storage is an expensive option. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120551">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="col-sm-12 well"><h4 class="sm" style="color:#333;">10/55 Questions right</h4></div></div><style type="text/css">
span.label.label-danger,span.label.label-success {
    padding: .2em .6em .3em;
}
.saved{color:red; }
.question_info{
  margin-bottom: 40px;
  border: solid 1px #ccc;
  border-radius: 5px;
  overflow: hidden;
}
.question_no {
    background: #f4f4f4;
    padding: 0 15px;
    line-height: 40px;
    border-bottom: solid 1px #ccc;
}

.question_detail {
    padding: 10px;
}
.hide{
  display: none;
}
input[type="radio"]{
  -webkit-appearance: radio;
}
input[type="checkbox"]{
  -webkit-appearance: checkbox;
}
span.bgcolor {
    background: yellow;
    padding: 5px;
    margin-left: -5px;
}
</style><link href="./sap-02_files/mcoursestyle.css" rel="stylesheet"></div> <script type="text/javascript" src="./sap-02_files/bc-course.min_031117.js.下载"></script> <div class="overlayForm" style=""></div></div></div></div></div></div><div class="overlayForm"></div></div><iframe style="position:absolute;left:-999px;top:-999px;visibility:hidden" src="./sap-02_files/saved_resource.html"></iframe><iframe style="display: none; visibility: hidden;" src="./sap-02_files/saved_resource(1).html"></iframe><iframe style="display: none; visibility: hidden;" src="./sap-02_files/saved_resource(2).html"></iframe></body></html>