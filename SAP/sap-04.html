<!DOCTYPE html>
<!-- saved from url=(0112)https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219 -->
<html xmlns:fb="http://ogp.me/ns/fb#" lang="en-gb" dir="ltr" class="secondary-14px wf-proximanova-n7-active wf-proximanova-i7-active wf-proximanova-n4-active wf-raleway-n1-active wf-raleway-n7-active wf-raleway-n4-active wf-raleway-n5-active wf-raleway-n3-active wf-raleway-n8-active wf-raleway-n9-active wf-raleway-n2-active wf-raleway-n6-active wf-proximanova-i4-active wf-active"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><meta name="format-detection" content="telephone=no"><script type="text/javascript" src="./sap-04_files/display.js.下载"></script><script type="text/javascript" src="./sap-04_files/pro"></script><script type="text/javascript" src="./sap-04_files/l.js.下载"></script><script type="text/javascript" src="./sap-04_files/l.js(1).下载"></script><script type="text/javascript" src="./sap-04_files/l.js(2).下载"></script><script type="text/javascript" src="./sap-04_files/l.js(3).下载"></script><script type="text/javascript" async="" src="./sap-04_files/analytics.js.下载"></script><script type="text/javascript" async="" src="./sap-04_files/atatus.js.下载"></script><script src="./sap-04_files/fMy5LNtdDqis6adCpEbCXQHA47I.js.下载"></script><script src="./sap-04_files/js"></script><link rel="canonical" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219"><link rel="stylesheet" type="text/css" href="./sap-04_files/bc-course.min_092917.css"><link rel="stylesheet" type="text/css" href="./sap-04_files/bc-style-092917.css"><!--[if lt IE 9]> <script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script> <script src="//css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script> <![endif]--><link rel="shortcut icon" href="https://www.braincert.com/images/favicon.ico"> <script type="text/javascript" src="./sap-04_files/jquery-1.11.0.min.js.下载"></script> <script type="text/javascript">jQuery.noConflict();</script> <script type="application/javascript" src="./sap-04_files/fVBYAHUg.js.下载"></script> <script type="text/javascript">jwplayer.key="Kfk7MAHVl4Y33jPduQlHwUdmLu+1l6cvPHVklw==";</script> <script src="./sap-04_files/jdk4nqa.js.下载"></script> <style type="text/css">.tk-proxima-nova{font-family:"proxima-nova",sans-serif;}.tk-raleway{font-family:"raleway",sans-serif;}</style><style type="text/css">@font-face{font-family:tk-proxima-nova-n7;src:url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:tk-proxima-nova-i7;src:url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-weight:700;font-style:italic;}@font-face{font-family:tk-proxima-nova-n4;src:url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:tk-proxima-nova-i4;src:url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-weight:400;font-style:italic;}@font-face{font-family:tk-raleway-n1;src:url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff2"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("opentype");font-weight:100;font-style:normal;}@font-face{font-family:tk-raleway-n7;src:url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:tk-raleway-n4;src:url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:tk-raleway-n5;src:url(https://use.typekit.net/af/145edc/000000000000000000013289/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}@font-face{font-family:tk-raleway-n3;src:url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff2"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("opentype");font-weight:300;font-style:normal;}@font-face{font-family:tk-raleway-n8;src:url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff2"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("opentype");font-weight:800;font-style:normal;}@font-face{font-family:tk-raleway-n9;src:url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff2"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("opentype");font-weight:900;font-style:normal;}@font-face{font-family:tk-raleway-n2;src:url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff2"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("opentype");font-weight:200;font-style:normal;}@font-face{font-family:tk-raleway-n6;src:url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-weight:600;font-style:normal;}</style><script>try{Typekit.load({ async: true });}catch(e){}</script> <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="keywords" content="virtual classroom, online test, online course, MOOC,  SCORM, whiteboard, adaptive testing, e-learning, online education, learn online, teach online, live class, lms, monetize, sell course, online meetings, collaboration, webinar, how to, social, teach, learn"><meta name="description" content="Deliver live engaging classes using Virtual Classroom. Create and sell courses and tests online."><title>Review Answers | BrainCert</title><link href="https://www.braincert.com/templates/yoo_nano/favicon.ico" rel="shortcut icon" type="image/vnd.microsoft.icon"> <script type="text/javascript">
function keepAlive() {	var myAjax = new Request({method: "get", url: "index.php"}).send();} window.addEvent("domready", function(){ keepAlive.periodical(3540000); });
  </script> <script type="text/javascript">
				/*<![CDATA[*/
					var jax_live_site = 'https://www.braincert.com/index.php';
					var jax_token_var='925395911814f17127e11ea28577607f';
				/*]]>*/
				</script><script type="text/javascript" src="./sap-04_files/ajax_1.5.pack.js.下载"></script> <link rel="apple-touch-icon-precomposed" href="https://d9q55ve2f7k8m.cloudfront.net/images/apple_touch_icon.png"> <script>
        !function(window, document) {
            window._atatusConfig = {
                apikey: '8c2f3d535648489b9826fd95a6484c2b'
            };
            function _asyncAtatus(callback) {
                var script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.src = "https://dmc1acwvwny3.cloudfront.net/atatus.js";
                var node = document.getElementsByTagName("script")[0];
                script.addEventListener('load', function (e) {
                    callback(null, e);
                }, false);
                node.parentNode.insertBefore(script, node);
            }
            _asyncAtatus(function() {
                // Any atatus related calls.
                if (window.atatus) {
                    window.atatus.setUser('138600', 'liugongjianxin@163.com', 'gongjian liu');
                    console.log(window.atatus);
                }
            });
        }(window, document);
</script> <style type="text/css">@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/925423/00000000000000003b9b038f/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/cd78b3/00000000000000003b9b038e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-weight:700;font-style:italic;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/219c30/00000000000000003b9b0389/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/0de7d4/00000000000000003b9b0388/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-weight:400;font-style:italic;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff2"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("woff"),url(https://use.typekit.net/af/4c4265/00000000000000000001328e/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n1&v=3) format("opentype");font-weight:100;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/00d57c/000000000000000000013287/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-weight:700;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/3c6666/000000000000000000013288/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-weight:400;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/145edc/000000000000000000013289/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/145edc/000000000000000000013289/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff2"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("woff"),url(https://use.typekit.net/af/9a0c16/00000000000000000001328a/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n3&v=3) format("opentype");font-weight:300;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff2"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("woff"),url(https://use.typekit.net/af/62d84a/00000000000000000001328b/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n8&v=3) format("opentype");font-weight:800;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff2"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("woff"),url(https://use.typekit.net/af/f4139f/00000000000000000001328c/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3) format("opentype");font-weight:900;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff2"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("woff"),url(https://use.typekit.net/af/6b6454/00000000000000000001328d/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n2&v=3) format("opentype");font-weight:200;font-style:normal;}@font-face{font-family:raleway;src:url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/baea6e/000000000000000000014968/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-weight:600;font-style:normal;}</style><script type="text/javascript" src="./sap-04_files/ga.js.下载"></script><script async="" type="text/javascript" src="./sap-04_files/pops"></script><script async="" type="text/javascript" src="./sap-04_files/pops(1)"></script><script type="text/javascript" src="./sap-04_files/jquery.min.js.下载"></script></head><body id="page-top"><div id="page-wrap"><div id="preloader"> </div> <header id="header" class="header chapter-header"><div class="container"><div class="logo"><a href="https://www.braincert.com/"><img src="./sap-04_files/bc-logo-sm.png" alt="BrainCert" style="max-height:60px;"></a> </div><nav class="navigation"><div class="navbar-header"> <a class="navbar-brand" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219#"><span class="navbar-header-title"> AWS Certified Solutions Architect Professional SAP-C01 Practice </span></a> </div><ul class="menu"> <li><a href="https://www.braincert.com/">Home</a></li> </ul><div class="search-box"> <a href="https://www.braincert.com/test/11997-AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice-Exam-4" class="smoothScroll"><i class="fa fa-chevron-left"></i> Back</a> </div></nav> </div> </header><div class="main-container"> <script type="text/javascript">
  jQuery(document).ready(function (){
     
    jQuery( "html" ).addClass( "secondary-14px" );
    jQuery(document)[0].oncontextmenu = function() {return false;} 
    // code for preventing copy from keyboard
    var ambit = jQuery(document);
    // Disable Cut + Copy + Paste (input)
    ambit.on('copy paste cut', function (e) {
    e.preventDefault(); //disable cut,copy,paste
      return false;
    });
      });
</script> <div class="container"><div id="content-main" class="row-fluid"><div class="col-sm-12"><h2 style="margin-bottom:10px;margin-top:10px; float:left">Test Report</h2><div style="margin-top:10px;float:right"><a onclick="window.history.back();" class="btn btn-warning"><span><strong>Back</strong></span></a></div><div style="float:right;margin-top:10px;margin-right: 10px;"><a href="https://www.braincert.com/test/reviewtest/exportdata/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219" class="btn btn-primary"><span><strong><i class="fa fa-share-square-o"></i>&nbsp;Export to .CSV</strong></span></a></div><div style="border-bottom-width: 1px;border-bottom-style: dashed;border-bottom-color: #e0e0e0;margin-bottom: 10px; clear:both"></div><div style="clear:both;"></div><div class="col-md-6 pull-left row"><h3 style="margin-top: 0px;"><strong>Review questions</strong></h3></div><div class="col-md-6 pull-right row" style="font-size: 16px;text-align: right;"><strong>Student : </strong>gongjian liu
<br> <i class="fa fa-calendar"></i>&nbsp;Jun 17, 2019&nbsp;&nbsp;<i class="fa fa-clock-o"></i>&nbsp;12:42AM EDT<br> <br> </div><div id="test_results" style="padding-top: 80px;"><div id="quiz_specific"> <span id="select"></span> <div class="quiz_attempt_breakdown"><div class="percent_correct_bar col-sm-2"><div class="progress" style="margin-bottom: 2px;"><div class="progress-bar" role="progressbar" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100" style="width:15%"> </div> </div> <span id="percent"><strong>15% </strong>correct</span> </div><div><div class="questions_correct col-sm-2"><span class="inline_pipe">|</span>&nbsp;&nbsp; <img src="./sap-04_files/tick.webp" alt="you got this question right">&nbsp;<strong>8 correct</strong></div><div class="questions_incorrect col-sm-2"><span class="inline_pipe"> | </span>&nbsp;&nbsp; <img src="./sap-04_files/cross.webp" alt="you got this question wrong">&nbsp;<strong>46 incorrect</strong></div><div class="questions_incorrect col-sm-3" style="margin:0;"><span class="inline_pipe"> | </span>&nbsp;&nbsp;<img src="./sap-04_files/icon_un_answered.webp" alt="you got this question unanswer">&nbsp;<strong>0 Unanswered</strong></div><div class="total_questions col-sm-3"><span class="inline_pipe"> | </span>&nbsp;&nbsp;<strong>54 questions attempted out of 54</strong></div></div></div><br class="clear"><hr style="clear:both"><br> <br><div style="margin-bottom: 10px;"> <b style="font-size: 14.5px;">Filter by</b> : <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219" class="label-default label">All</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219?sort=1">correct</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219?sort=0">incorrect</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219?sort=-1">Unanswered</a>&nbsp;|&nbsp; <a style="padding: 3px 5px 3px 5px;" href="https://www.braincert.com/test/reviewtest/AWS-Certified-Solutions-Architect-Professional-SAP-C01-Practice/145219?sort=2">Question feedback</a> </div><br><div class="" style="font-size: 18px;line-height: 25px;"><div class="question_info"><div class="question_no"><b>Question : 1 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249263"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company has an on-premises application that includes a hardware-based load balancer. Two Apache hosts terminate SSL and retrieve dynamic content from one of the four servers that run a Java/Tomcat application server. Data is stored on a MySQL server, which has read replicas that are used for month-end reporting only. A Solutions Architect must migrate the application to AWS. The solution must minimize changes to the application code, costs, and platform management. Which combination of actions should the Solutions Architect perform to migrate the application? (Select TWO.)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 16 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Migrate the database to Amazon RDS MySQL Multi-AZ DB instances.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Migrate the database to Amazon Aurora MySQL. Use Amazon CloudWatch Events to schedule AWS Lambda functions that add read replicas for month-end reporting and remove them afterward.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Migrate the Java/Tomcat servers to AWS Elastic Beanstalk.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Migrate the Java/Tomcat servers to Amazon EC2 instances behind an ELB Application Load Balancer. Configure an EC2 Auto Scaling group for the instances.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Migrate the database to Amazon RDS for MySQL with Auto Scaling for the read replicas. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Migrate the database to Amazon Aurora MySQL. Use Amazon CloudWatch Events to schedule AWS Lambda functions that add read replicas for month-end reporting and remove them afterward.<br><b>C</b>. Migrate the Java/Tomcat servers to AWS Elastic Beanstalk.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B &amp; C</strong> </p><p>Option B as Aurora MySQL will support MySQL without any code changes and <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html" target="_blank">Auto Auto Scaling Read replicas</a> can help cut costs. </p><p><em>To meet your connectivity and workload requirements, Aurora Auto Scaling dynamically adjusts the number of Aurora Replicas provisioned for an Aurora DB cluster. Aurora Auto Scaling is available for both Aurora MySQL and Aurora PostgreSQL. Aurora Auto Scaling enables your Aurora DB cluster to handle sudden increases in connectivity or workload. When the connectivity or workload decreases, Aurora Auto Scaling removes unnecessary Aurora Replicas so that you don't pay for unused provisioned DB instances.</em> </p><p><em></em> </p><p><em>You define and apply a scaling policy to an Aurora DB cluster. The scaling policy defines the minimum and maximum number of Aurora Replicas that Aurora Auto Scaling can manage. Based on the policy, Aurora Auto Scaling adjusts the number of Aurora Replicas up or down in response to actual workloads, determined by using Amazon CloudWatch metrics and target values.</em> </p><p>Option C as Elastic Beanstalk with help deploy applications on Java/Tomcat with minimal Platform Management. </p><p>Option A is wrong as Multi-AZ provides High Availability. Standby cannot be used for reporting. </p><p>Option D is wrong as hosting on ELB with Auto Scaling with EC2 instance would need platform management.<br> </p><p>Option E is wrong as RDS MySQL does not provide read replica Auto Scaling.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121067">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 2 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249264"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An AWS customer is deploying an application that is composed of an Auto Scaling group of EC2 Instances. The customer’s security policy requires that every outbound connection from these instances to any other service within the customers Virtual Private Cloud must be authenticated using a unique x 509 certificate that contains the specific instance-id. In addition an x 509 certificates must be designed by the customer’s Key management service in order to be trusted for authentication. Which of the following configurations will support these requirements?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure an IAM Role that grants access to an Amazon S3 object containing a signed certificate and configure the Auto Scaling group to launch instances with this role. Have the instances bootstrap get the certificate from Amazon S3 upon first boot.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Embed a certificate into the Amazon Machine Image that is used by the Auto Scaling group Have the launched instances generate a certificate signature request with the instance’s assigned instance-id to the Key management service for signature.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Configure the Auto Scaling group to send an SNS notification of the launch of a new instance to the trusted key management service. Have the Key management service generate a signed certificate and send it directly to the newly launched instance.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Configure the launched instances to generate a new certificate upon first boot Have the Key management service poll the Auto Scaling group for associated instances and send new instances a certificate signature that contains the specific instance-id. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Configure the Auto Scaling group to send an SNS notification of the launch of a new instance to the trusted key management service. Have the Key management service generate a signed certificate and send it directly to the newly launched instance.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as certificate must be signed by the customers key management service and this is the only option. Using S3 won't have it unique, embedding in AMI wont make it unique, Generating a new certificate by itself would defeat the requirement of getting it signed by customers key management service. </p><p>Option A is wrong as Accessing from S3 was fine but how can the file be unique when every time autoscaling generates different instances and instance-id.. Thats not predictable </p><p>Option B is wrong as Embedding a certificate in AMI cannot make the certificate unique. </p><p>Option D is wrong as As the EC2 instances must generate unique X.509 certificate and this must be specific to the instance id. The EC2 instance can generate the certificate itself BUT it is clearly mentioned that the certificate must be signed by the customers key management service and not self signed. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120428">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 3 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249265"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have just come from your Chief Information Security Officer's (CISO) office with the instructions to provide an audit report of all AWS network rules used by the organization's Amazon EC2 instances. You have discovered that a single Describe-Security-Groups API call will return all of an account's security groups and rules within a region. You create the following pseudo-code to create the required report: - Parse "aws ec2 describe-security-groups" output - For each security group - Create report of ingress and egress rules Which two additional pieces of logic should you include to meet the CISO's requirements? Choose 2 answers <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Parse security groups in each region. </span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Parse security groups in each Availability Zone and region. <br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Evaluate VPC network access control lists. <br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Evaluate AWS CloudTrail logs. <br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Evaluate Elastic Load Balancing access control lists. <br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Parse CloudFront access control lists. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Parse security groups in each region. <br><b>C</b>. Evaluate VPC network access control lists. <br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A &amp; C</strong> as the command describe-security-groups<span class="redactor-invisible-space"> would return results for a single region it needs to be execute for each region. Also, for network rules the NACLs should also be checked.</span> </p><p><span class="redactor-invisible-space">Refer AWS documentation - <a href="https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-security-groups.html" target="_blank">describe-security-groups</a></span> </p><p>Option B is wrong as the command describe-security-groups<span class="redactor-invisible-space"> returns security groups for entire region.</span> </p><p>Option D is wrong as CloudTrail logs provide access audit logs. </p><p>Option E is wrong as ELB ACLs do not exist. </p><p>Option F is wrong as CloudFront ACLs are different than the EC2 network rules. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120553">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 4 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249266"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You currently operate a web application In the AWS US-East region. The application runs on an auto-scaled layer of EC2 instances and an RDS Multi-AZ database. Your IT security compliance officer has tasked you to develop a reliable and durable logging solution to track changes made to your EC2, IAM and RDS resources. The solution must ensure the integrity and confidentiality of your log data. Which of these solutions would you recommend? <br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create a new CloudTrail trail with one new S3 bucket to store the logs and with the global services option selected. Use IAM roles, S3 bucket policies and Multi Factor Authentication (MFA) Delete on the S3 bucket that stores your logs.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a new CloudTrail with one new S3 bucket to store the logs. Configure SNS to send log file delivery notifications to your management system. Use IAM roles and S3 bucket policies on the S3 bucket that stores your logs.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a new CloudTrail trail with an existing S3 bucket to store the logs and with the global services option selected Use S3 ACLs and Multi Factor Authentication (MFA) Delete on the S3 bucket that stores your logs.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create three new CloudTrail trails with three new S3 buckets to store the logs one for the AWS Management console, one for AWS SDKs and one for command line tools. Use IAM roles and S3 bucket policies on the S3 buckets that store your logs. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Create a new CloudTrail trail with one new S3 bucket to store the logs and with the global services option selected. Use IAM roles, S3 bucket policies and Multi Factor Authentication (MFA) Delete on the S3 bucket that stores your logs.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as single new S3 bucket with global services option enabled for IAM and IAM, Bucket Policies &amp; MFA delete for confidentiality </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-concepts.html#cloudtrail-concepts-global-service-events" target="_blank">CloudTrail Global Service Events</a> </p><p><em>For most services, events are sent to the region where the action happened. For global services such as IAM, AWS STS, and Amazon CloudFront, events are delivered to any trail that includes global services</em><em></em><br> </p><p>Option B is wrong as it is missing Global Services which is required for tracking IAM </p><p>Option C is wrong as using existing bucket prevents confidentiality as it might be accessible to users already. </p><p>Option D is wrong as 3 buckets not needed, Missing Global services options. Also CloudTrail delivers logs are all the services and events into a single configured S3 bucket. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120528">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 5 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249267"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are building a large-scale confidential documentation web server on AWS and all of the documentation for it will be stored on S3. One of the requirements is that it cannot be publicly accessible from S3 directly, and you will need to use CloudFront to accomplish this. Which of the methods Listed below would satisfy the requirements as outlined? Choose an answer from the options below<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an Identity and Access Management (IAM) user for CloudFront and grant access to the objects in your S3 bucket to that IAM User.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create an Origin Access identity (OAI) for Cloud Front and grant access to the objects in your S3 bucket to that OAl.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create individual policies for each bucket the documents are stored in and in that policy grant access to only CloudFront.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an S3 bucket policy that lists the CloudFront distribution ID as the Principal and the target bucket as the Amazon Resource Name (ARN). <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create an Origin Access identity (OAI) for Cloud Front and grant access to the objects in your S3 bucket to that OAl.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Please refer to AWS <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html" target="_blank">CloudFront Restrict Access to S3</a> </p><p>Correct answer is <strong>B</strong> </p><p>Origin Access Identity is a special CloudFront user associated with the distribution. For web distribution, it is associated with S3. OAI allows exposing the content without making the S3 content public.<br> </p><p>Option A, C and D are wrong as they do allow S3 to allow exclusive access to CloudFront with CloudFront being able to distribute the contents. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120408">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 6 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249268"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your organization has two AWS accounts; one for development and the other for production. Each account has EC2 instances running as web servers, a load balancer, and an RDS database. Your security team has asked you to ensure that they can log all interactions with these AWS services and that users cannot tamper with logs. Which of the following steps should you take? (Choose three)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Create a new S3 bucket. Configure CloudTrail in both accounts to log to this bucket.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use the existing S3 buckets in each account. Configure CloudTrail in each account to log to its own S3 bucket.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Create a new IAM user policy to control access to the S3 bucket.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Create a new IAM role to control access to the S3 bucket.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Allow CloudTrail to perform PUT operations, explicitly deny GET operations, and explicitly allow the Security Team to perform GET operations.<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Allow CloudTrail to perform PUT operations. Allow the Security Team to perform GET operations.<br><b>G</b>. <input type="checkbox" disabled="">&nbsp;Create an S3 Bucket Policy to control access to the S3 bucket. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Create a new S3 bucket. Configure CloudTrail in both accounts to log to this bucket.<br><b>D</b>. Create a new IAM role to control access to the S3 bucket.<br><b>G</b>. Create an S3 Bucket Policy to control access to the S3 bucket.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to log all interactions for services and security of them not being tampered with. </p><p>Correct answer is <strong>A, D &amp; G</strong> </p><p>Refer AWS Blog about <a href="https://aws.amazon.com/blogs/security/sharing-aws-cloudtrail-log-files-between-accounts/" target="_blank">Sharing AWS CloudTrail log files between Accounts</a> </p><p>Use CloudTrail for logging into an S3 bucket which has only read permissions. </p><p>Configure Bucket policy on S3 for CloudTrail from AWS accounts to be able to log interactions in it. </p><p>Using a Cross Account role to control access to the S3 bucket. </p><p>Option B is wrong as using an existing S3 account would would allow others access to it. </p><p>Option C is wrong as IAM role is preferred as it can be used to delegate read permissions to security team </p><p>Option E is wrong as An explicit deny statement takes precedence over an allow statement so security team cannot perform GET operations </p><p>Option F is wrong as can be better achieve through Bucket Policy and IAM role. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120362">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 7 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249269"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are an IT administrator and you are responsible for managing several on-premises databases in VMware vSphere environments. The R&amp;D team has just created several RDS instances on VMware to utilize the latest AWS RDS on VMware feature. Then those new databases can be managed by using RDS console, API and CLI. Which activities does the Amazon RDS on VMware manage on your behalf? (Select THREE)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;The patching of the RDS on-premises operating systems and database engines.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Automated multi-availability zone (Multi-AZ) configurations for RDS instances in VMware<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Online backups based on retention policies of databases in RDS VMware.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Point-in-time restore from on-premises instances and cloud backups when needed<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;IP management such as a dedicated public IP has been allocated by AWS VPC. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. The patching of the RDS on-premises operating systems and database engines.<br><b>C</b>. Online backups based on retention policies of databases in RDS VMware.<br><b>D</b>. Point-in-time restore from on-premises instances and cloud backups when needed<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A, C &amp; D</strong> as RDS on VMware handles tasks like patching and backups. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/rds/vmware/" target="_blank">RDS on VMware</a> </p><p><em>Amazon Relational Database Service (RDS) on VMware lets you deploy managed databases in on-premises VMware environments using the <a href="https://aws.amazon.com/rds/">Amazon RDS</a> technology enjoyed by hundreds of thousands of AWS customers. Amazon RDS provides cost-efficient and resizable capacity while automating time-consuming administration tasks including hardware provisioning, database setup, patching, and backups, freeing you to focus on your applications. RDS on VMware brings these same benefits to your on-premises deployments, making it easy to set up, operate, and scale databases in VMware vSphere private data centers, or to migrate them to AWS.</em> </p><p><em>RDS on VMware allows you to utilize the same simple interface for managing databases in on-premises VMware environments as you would use in AWS. You can easily replicate RDS on VMware databases to RDS instances in AWS, enabling low-cost hybrid deployments for disaster recovery, read replica bursting, and optional long-term backup retention in Amazon Simple Storage Service (S3).</em> </p><p>Option B is wrong as RDS does not support Multi-AZ configurations for instance on VMware </p><p>Option E is wrong as RDS does not allocate IP address for the instance on VMware and communication happens using a dedicated VPN tunnel. </p><p><em>Amazon RDS on VMware reduces operational overhead for database management in your on-premises VMware data centers, by automating administrative tasks including software installation, patching, monitoring, and backups. The RDS Connector, a software appliance for your VMware vSphere environment, packages RDS technologies that provide highly available, scalable, and durable database management, enabled through a dedicated VPN tunnel.</em><em></em><br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120769">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 8 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249270"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A customer has established an AWS Direct Connect connection to AWS. The link is up and routes are being advertised from the customer’s end, however the customer is unable to connect from EC2 instances inside its VPC to servers residing in its datacenter. Which of the following options provide a viable solution to remedy this situation? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Add a route to the route table with an iPsec VPN connection as the target</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Enable route propagation to the virtual private gateway (VGW)<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Enable route propagation to the customer gateway (CGW)<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Modify the route table of all Instances using the ‘route’ command. <br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Modify the Instances VPC subnet route table by adding a route back to the customer’s on-premises environment. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Enable route propagation to the virtual private gateway (VGW)<br><b>E</b>. Modify the Instances VPC subnet route table by adding a route back to the customer’s on-premises environment.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B and E</strong> as VGW propagation is easier and automatic and route table can be easily modified </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/premiumsupport/knowledge-center/troubleshoot-vpc-route-table/" target="_blank">Troubleshooting VPC Route Table</a></p><p><em>Subnets using AWS Direct Connect</em></p><ol><li><em>Open the AWS Direct Connect console.</em></li><li><em>In the navigation pane, choose Virtual Interfaces, and then choose the private virtual interface.</em></li><li><em>Confirm that the BGP status is UP.</em></li><li><em>Note the virtual private gateway used for the private virtual interface.</em></li><li><em>Open the Amazon VPC console.</em></li><li><em>In the navigation pane, under Subnets, select the subnets of the Amazon VPC that you want to connect using AWS Direct Connect.</em></li><li><em>Choose the Route Table view, then confirm that there is a route with the destination of your network and a target of the virtual private gateway as noted in step 4.<br>Note: If you are using BGP, be sure that the routes are received by AWS. You can enable route propagation to confirm that the BGP routes are being propagated to the virtual private gateway.</em></li></ol><p>Option A is wrong as it deals with VPN connection and not Direct Connect </p><p>Option C is wrong as <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#EnableDisableRouteProp" target="_blank">route propagation is enabled on VGW</a> and not on CGW as CGW is the customer side end point for traffic coming out of the on-premises data centre </p><p>Option D is wrong as there is no route command available </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120238">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 9 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249271"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have been asked to virtually extend two existing data centers into AWS to support a highly available application that depends on existing, on-premises resources located in multiple data centers and static content that is served from an Amazon Simple Storage Service (S3) bucket. Your design currently includes a dual-tunnel VPN connection between your CGW and VGW. Which component of your architecture represents a potential single point of failure that you should consider changing to make the solution more highly available? <br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Add another VGW in a different Availability Zone and create another dual-tunnel VPN connection.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Add another CGW in a different data center and create another dual-tunnel VPN connection.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Add a second VGW in a different Availability Zone, and a CGW in a different data center, and create another dual-tunnel.<br><b>D</b>. <input type="radio" disabled="">&nbsp;No changes are necessary: the network architecture is currently highly available. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Add another CGW in a different data center and create another dual-tunnel VPN connection.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here to make architecture HA and prevent single point of failure </p><p>Refer AWS documentation for <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html" target="_blank">VPC with VPN</a> </p><p>Correct answer is B as CGW does have dual tunnels, but the dual tunnels are at the AWS side (VGW) and converge at the CGW side at the same point, thus if the hardware appliance on the customer side that is represented by the CGW goes down, then connectivity is lost. Thus the CGW is a single point of failure, so adding another CGW to connect to the VGW would eliminate that single point of failure. </p><p>Option A and C are wrong as VPC can only have 1 VGW </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120387">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 10 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249272"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing a file-sharing service. This service will have millions of files in it. Revenue for the service will come from fees based on how much storage a user is using. You also want to store metadata on each file, such as title, description and whether the object is public or private. How do you achieve all of these goals in a way that is economical and can scale to millions of users?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Store all files in Amazon Simple Storage Service (53). Create a bucket for each user. Store metadata in the filename of each object, and access it with LIST commands against the S3 API.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Store all files in Amazon S3. Create Amazon DynamoDB tables for the corresponding key-value pairs on the associated metadata, when objects are uploaded.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a striped set of 4000 IOPS Elastic Load Balancing volumes to store the data. Use a database running in Amazon Relational Database Service (RDS) to store the metadata.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a striped set of 4000 IOPS Elastic Load Balancing volumes to store the data. Create Amazon DynamoDB tables for the corresponding key-value pairs on the associated metadata, when objects are uploaded. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Store all files in Amazon S3. Create Amazon DynamoDB tables for the corresponding key-value pairs on the associated metadata, when objects are uploaded.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> to store all files in S3 and maintain the metadata in DynamoDB which would be economical and scalable as the key point here is to keep cost low and scale the solution to millions of users.<br></p><p>Refer AWS documentation - <a href="https://media.amazonwebservices.com/AWS_Storage_Options.pdf" target="_blank">Storage Options Whitepaper</a></p><p>Option A is wrong as it is expensive and slow as it returns limited items at a time. S3 is not suitable for querying operation but more for storage. </p><p>Option C is wrong as it not not economical at all using Striped set of volumes as well as scalable using RDS </p><p>Option D are wrong as it not not economical at all using Striped set of volumes and RDS </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120203">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 11 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249273"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An International company has deployed a multi-tier web application that relies on DynamoDB in a single region. For regulatory reasons they need disaster recovery capability in a separate region with a Recovery Time Objective of 2 hours and a Recovery Point Objective of 24 hours. They should synchronize their data on a regular basis and be able to provision the web application rapidly using CloudFormation. The objective is to minimize changes to the existing web application, control the throughput of DynamoDB used for the synchronization of data and synchronize only the modified elements. Which design would you choose to meet these requirements?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use AWS data Pipeline to schedule a DynamoDB cross region copy once a day. Create a ‘Lastupdated’ attribute in your DynamoDB tablee that would represent the timestamp of the last update and use it as a filter</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use EMR and write a custom script to retrieve data from DynamoDB in the current region using a SCAN operation and push it to DynamoDB in the second region.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use AWS data Pipeline to schedule an export of the DynamoDB tablee to S3 in the current region once a day then schedule another task immediately after it that will import data from S3 to DynamoDB in the other region.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Send each update into an SQS queue in the second region; use an auto-scaling group behind the SQS queue to replay the write in the second region. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Use AWS data Pipeline to schedule a DynamoDB cross region copy once a day. Create a ‘Lastupdated’ attribute in your DynamoDB tablee that would represent the timestamp of the last update and use it as a filter<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A </strong>as the key requirement here is DR with RTO of 2 hours and a RPO of 24 hours with only the changed items to be replicated. DynamoDB cross region copy would help for DR with required RPO and RTO with Lastupdated time would help replicate only updated items. </p><p>Refer AWS <a href="https://aws.amazon.com/blogs/aws/copy-dynamodb-data-between-regions-using-the-aws-data-pipeline/" target="_blank">DynamoDB Data Copy Between Regions Blog</a> </p><p>Option B is wrong the scan operation is expensive and time consuming and would not help meet RTO. Also, there is no handling for only updated data. </p><p>Option C is wrong is time consuming and would not help meet the RTO. Also, there is no handling for only updated data. </p><p>Option D is wrong as this needs update to the application to push data to DynamoDB as well the SQS in a reliable manner. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120826">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 12 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249274"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Amazon Aurora provides an on-demand, autoscaling serverless configuration, which automatically starts up, shuts down, and scales up or down capacity based on application's needs. Aurora Serverless provides a relatively simple, cost effective option. Which below scenarios are suitable for Aurora serverless to be used? Select THREE<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Start up company B is deploying a new application for online trading system, which needs a database to store customers’ transactions. It is a totally new application therefore the team is still unsure what the load may look like at first.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;For an internal project, a developer needs to use database during work hours but does not need it on nights or weekends. He decides to use Aurora to save some cost as required by the team lead.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;A middle size company C is considering migrating its legacy on-premise MariaDB database to AWS RDS. The database has dramatically higher workload on weekends than weekdays.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;A development team is running an IOT monitor system where there is database usage throughout the day, but also peaks of activity that are hard to predict. When the peaks happen, the total activities may reach at 10 times of the normal level.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;A company has EC2 applications on Sydney region. Due to the market increase in Singapore, it decides to add RDS database on Singapore region. Because of some security considerations, AWS VPN is needed for the database to talk with several on-premise applications. The workload is expected to be high and stable. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Start up company B is deploying a new application for online trading system, which needs a database to store customers’ transactions. It is a totally new application therefore the team is still unsure what the load may look like at first.<br><b>B</b>. For an internal project, a developer needs to use database during work hours but does not need it on nights or weekends. He decides to use Aurora to save some cost as required by the team lead.<br><b>D</b>. A development team is running an IOT monitor system where there is database usage throughout the day, but also peaks of activity that are hard to predict. When the peaks happen, the total activities may reach at 10 times of the normal level.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>A, B &amp; D</strong> </p><p>Option A as its a new application and the load is not known. </p><p>Option B as the usage is variable and Aurora can help save cost with its ability to start up, shutdown. </p><p>Option D as the load and peak is unpredictable. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/rds/aurora/serverless/" target="_blank">Aurora Serverless</a> </p><p><em>Amazon Aurora Serverless is an on-demand, auto-scaling configuration for <a href="https://aws.amazon.com/rds/aurora/">Amazon Aurora</a> (MySQL-compatible edition), where the database will automatically start up, shut down, and scale capacity up or down based on your application's needs. It enables you to run your database in the cloud without managing any database instances. It's a simple, cost-effective option for infrequent, intermittent, or unpredictable workloads.</em> </p><p><em><strong></strong></em> </p><p><em>Manually managing database capacity can take up valuable time and can lead to inefficient use of database resources. With Aurora Serverless, you simply create a database endpoint, optionally specify the desired database capacity range, and connect your applications. You pay on a per-second basis for the database capacity you use when the database is active, and migrate between standard and serverless configurations with a few clicks in the Amazon RDS Management Console.</em> </p><p><em></em>Option D is wrong as Aurora Serverless is suitable for unpredictable workloads. The database auto scales its capacity to meet the needs of the application's peak load and scales back down when the surge of activity is over. </p><p><span></span>Option E is wrong as one limitation for Aurora Serverless is that you can't access an Aurora Serverless DB cluster's endpoint through an AWS VPN connection or an inter-region VPC peering connection. Also the workload is stable so that a provisioned capacity works for this case. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120600">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 13 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249275"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your application consists of 10% writes and 90% reads. You currently service all requests through a Route53 Alias Record directed towards an AWS ELB, which sits in front of an EC2 Auto Scaling Group. Your system is getting very expensive when there are large traffic spikes during certain news events, during which many more people request to read similar data all at the same time. What is the simplest and cheapest way to reduce costs and scale with spikes like this?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an S3 bucket and asynchronously replicate common requests responses into S3 objects. When a request comes in for a precomputed response, redirect to AWS S3</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create another ELB and Auto Scaling Group layer mounted on top of the other system, adding a tier to the system. Serve most read requests out of the top layer<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a CloudFront Distribution and direct Route53 to the Distribution. Use the ELB as an Origin and specify Cache Behaviors to proxy cache requests, which can be served late<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a Memcached cluster in AWS ElastiCache. Create cache logic to serve requests, which can be served late from the in-memory cache for increased performance. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create a CloudFront Distribution and direct Route53 to the Distribution. Use the ELB as an Origin and specify Cache Behaviors to proxy cache requests, which can be served late<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point is to handle largely read requests with a simplest and cheapest way. </p><p>Correct answer is <strong>C</strong> as CloudFront can serve request from cache and <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesCacheBehavior" target="_blank">multiple cache behavior</a> can be defined based on rules for a given URL pattern based on file extensions, file names, or any portion of a URL. Each cache behavior can include the CloudFront configuration values: origin server name, viewer connection protocol, minimum expiration period, query string parameters, cookies, and trusted signers for private content. </p><p>Options A, B and D are not simple, easy to implement with minimal changes and not cheap as well </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120229">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 14 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249276"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are migrating a legacy client-server application to AWS. The application responds to a specific DNS domain (e.g. www.example.com) and has a 2-tier architecture, with multiple application servers and a database server. Remote clients use TCP to connect to the application servers. The application servers need to know the IP address of the clients in order to function properly and are currently taking that information from the TCP socket. A Multi-AZ RDS MySQL instance will be used for the database. During the migration you can change the application code but you have to file a change request. How would you implement the architecture on AWS in order to maximize scalability and high availability?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;File a change request to implement Proxy Protocol support in the application. Use an ELB with a TCP Listener and Proxy Protocol enabled to distribute load on two application servers in different AZs.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;File a change request to Implement Cross-Zone support in the application Use an ELB with a TCP Listener and Cross-Zone Load Balancing enabled, two application servers in different AZs.<br><b>C</b>. <input type="radio" disabled="">&nbsp;File a change request to implement Latency Based Routing support in the application Use Route 53 with Latency Based Routing enabled to distribute load on two application servers in different AZs.<br><b>D</b>. <input type="radio" disabled="">&nbsp;File a change request to implement Alias Resource support in the application Use Route 53 Alias Resource Record to distribute load on two application servers in different AZs. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. File a change request to implement Proxy Protocol support in the application. Use an ELB with a TCP Listener and Proxy Protocol enabled to distribute load on two application servers in different AZs.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct Answer is A - As ELB with TCP listener and proxy protocol will allow IP to be passed to the applications. ELB would also help distribute the traffic </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-proxy-protocol.html#proxy-protocol" target="_blank">Classic ELB Proxy Protocol</a></p><p><em>Proxy Protocol is an Internet protocol used to carry connection information from the source requesting the connection to the destination for which the connection was requested. Elastic Load Balancing uses Proxy Protocol version 1, which uses a human-readable header format.</em></p><p><em>By default, when you use Transmission Control Protocol (TCP) for both front-end and back-end connections, your Classic Load Balancer forwards requests to the instances without modifying the request headers. If you enable Proxy Protocol, a human-readable header is added to the request header with connection information such as the source IP address, destination IP address, and port numbers. The header is then sent to the instance as part of the request.</em></p><p><em>The Proxy Protocol header helps you identify the IP address of a client when you have a load balancer that uses TCP for back-end connections. Because load balancers intercept traffic between clients and your instances, the access logs from your instance contain the IP address of the load balancer instead of the originating client. You can parse the first line of the request to retrieve your client's IP address and the port number.<br></em></p><p>Option B is incorrect Cross Zone support would only allow even distribution of traffic across instances irrespective of the AZ. Also would not pass the IP. </p><p>Option C is incorrect as it would allow the latency based traffic only also no client IP available. </p><p>Option D is incorrect as Alias record is not needed and no IP support available </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120181">AWS SAP-C01 Question feedback</a></p></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 15 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249277"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Our company is getting ready to do a major public announcement of a social media site on AWS. The website is running on EC2 instances deployed across multiple Availability Zones with a Multi-AZ RDS MySQL Extra Large DB Instance. The site performs a high number of small reads and writes per second and relies on an eventual consistency model. After comprehensive tests you discover that there is read contention on RDS MySQL. Which are the best approaches to meet these requirements? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Deploy ElastiCache in-memory cache running in each availability zone</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Implement sharding to distribute load to multiple RDS MySQL instances <br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Increase the RDS MySQL Instance size and Implement provisioned IOPS <br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Add an RDS MySQL read replica in each availability zone <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Deploy ElastiCache in-memory cache running in each availability zone<br><b>D</b>. Add an RDS MySQL read replica in each availability zone<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is there is a read contention on MySQL and needs te solved. </p><p>Correct answer is <strong>A &amp; D</strong> as you need caching solution as its mainly read that needs to be handled. Read Replicas &amp; ElastiCache can help reduce the load on the master database as well as latency </p><p>Option B is wrong as sharding is mainly for improving write performance </p><p>Option C is wrong as there is a limit to which DB instances can be scaled up and would still be a bottleneck </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120244">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 16 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249278"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are setting up a video streaming service with the main components of the set up being S3, CloudFront and Transcoder. Your video content will be stored on AWS S3, and your first job is to upload 10 videos to S3 and make sure they are secure before you even begin to start thinking of streaming the videos. The 10 videos have just finished uploading to S3, so you now need to secure them with encryption at rest. Which of the following would be the best way to do this? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use AWS CloudHSM appliance with both physical and logical tamper detection and response mechanisms that trigger zeroization of the appliance.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Set an API flag, or check a box in the AWS Management Console, to have data encrypted in Amazon S3.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Use KMS to decrypt source data and encrypt resulting output. Also, use Origin Access Identity on your CloudFront distribution, so content is only able to be served via CloudFront, not S3 URLs.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Encrypt your data using AES-256. After the object is encrypted, the encryption key you used needs to be stored on AWS CloudFront. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use KMS to decrypt source data and encrypt resulting output. Also, use Origin Access Identity on your CloudFront distribution, so content is only able to be served via CloudFront, not S3 URLs.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C </strong>to user KMS for encrypting and decrypting the data in S3 and use OAI to prevent direct access to the S3 urls and control access from the CloudFront only. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html" target="_blank">S3 Using KMS Encryption</a> &amp; <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html" target="_blank">CloudFront OAI - Restrict S3 Access</a> </p><p><em>Server-side encryption is about protecting data at rest. AWS Key Management Service (AWS KMS) is a service that combines secure, highly available hardware and software to provide a key management system scaled for the cloud. AWS KMS uses customer master keys (CMKs) to encrypt your Amazon S3 objects. You use AWS KMS via the Encryption Keys section in the IAM console or via AWS KMS APIs to centrally create encryption keys, define the policies that control how keys can be used, and audit key usage to prove they are being used correctly. You can use these keys to protect your data in Amazon S3 buckets.</em> </p><p><em></em> </p><p><em>The first time you add an SSE-KMS–encrypted object to a bucket in a region, a default CMK is created for you automatically. This key is used for SSE-KMS encryption unless you select a CMK that you created separately using AWS Key Management Service. Creating your own CMK gives you more flexibility, including the ability to create, rotate, disable, and define access controls, and to audit the encryption keys used to protect your data.</em> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120523">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 17 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249279"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company runs a complex customer relations management system that consists of around 10 different software components all backed by the same Amazon Relational Database (RDS) database. You adopted AWS OpsWorks to simplify management and deployment of that application and created an AWS OpsWorks stack with layers for each of the individual components. An internal security policy requires that all instances should run on the latest Amazon Linux AMI and that instances must be replaced within one month after the latest Amazon Linux AMI has been released. AMI replacements should be done without incurring application downtime or capacity problems. You decide to write a script to be run as soon as a new Amazon Linux AMI is released. Which solutions support the security policy and meet your requirements? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Assign a custom recipe to each layer, which replaces the underlying AMI. Use AWS OpsWorks life-cycle events to incrementally execute this custom recipe and update the instances with the new AMI.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Create a new stack and layers with identical configuration, add instances with the latest Amazon Linux AMI specified as a custom AMI to the new layer, switch DNS to the new stack, and tear down the old stack.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Identify all Amazon Elastic Compute Cloud (EC2) instances of your AWS OpsWorks stack, stop each instance, replace the AMI ID property with the ID of the latest Amazon Linux AMI ID, and restart the instance. To avoid downtime, make sure not more than one instance is stopped at the same time.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Specify the latest Amazon Linux AMI as a custom AMI at the stack level, terminate instances of the stack and let AWS OpsWorks launch new instances with the new AMI.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Add new instances with the latest Amazon Linux AMI specified as a custom AMI to all AWS OpsWorks layers of your stack, and terminate the old ones. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create a new stack and layers with identical configuration, add instances with the latest Amazon Linux AMI specified as a custom AMI to the new layer, switch DNS to the new stack, and tear down the old stack.<br><b>E</b>. Add new instances with the latest Amazon Linux AMI specified as a custom AMI to all AWS OpsWorks layers of your stack, and terminate the old ones.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B &amp; E</strong> </p><p>Option B as Blue-Green Deployment with no downtime and a seamless switch over </p><p>Option E as more capacity is added, no downtime and you can terminates the old ones after the new ones are running </p><p>Option A is wrong as OpsWorks lifecycle event trigger Chef to perform tasks inside instance such as updating configuration and cannot be used to update instance itself. </p><p>Option D is wrong as it will lead to downtime </p><p>Option C is wrong as AMI ID of an instance cannot be modified once the instance is created. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120558">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 18 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249280"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have an application consisting of a stateless web server tier running on Amazon EC2 instances behind load balancer, and are using Amazon RDS with read replicas. Which of the following methods should you use to implement a self healing and cost-effective architecture? (Choose two.)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Set up a third-party monitoring solution on a cluster of Amazon EC2 instances in order to emit custom CloudWatch metrics to trigger the termination of unhealthy Amazon EC2 instances.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Set up scripts on each Amazon EC2 instance to frequently send ICMP pings to the load balancer in order to determine which instance is unhealthy and replace it.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Set up an Auto Scaling group for the web server tier along with an Auto Scaling policy that uses the Amazon RDS DB CPU utilization CloudWatch metric to scale the instances.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Set up an Auto Scaling group for the web server tier along with an Auto Scaling policy that uses the Amazon EC2 CPU utilization CloudWatch metric to scale the instances.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use a larger Amazon EC2 instance type for the web server tier and a larger DB instance type for the data storage layer to ensure that they don’t become unhealthy.<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Set up an Auto Scaling group for the database tier along with an Auto Scaling policy that uses the Amazon RDS read replica lag CloudWatch metric to scale out the Amazon RDS read replicas.<br><b>G</b>. <input type="checkbox" disabled="">&nbsp;Use an Amazon RDS Multi-AZ deployment. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Set up an Auto Scaling group for the web server tier along with an Auto Scaling policy that uses the Amazon EC2 CPU utilization CloudWatch metric to scale the instances.<br><b>G</b>. Use an Amazon RDS Multi-AZ deployment.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>D &amp; G </strong>as CloudWatch in combination with Auto Scaling will help build a cost effective, self healing architecture. CloudWatch can be configured with EC2 CPU utilization to scale in and out the EC2 instances and custom metrics to terminate the EC2 instance. Auto Scaling would launch a new instance and register is automatically with the load balancer. RDS Multi-AZ would provide HA </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/policy_creating.html" target="_blank">Auto Scaling based on Metrics</a> </p><p>Option A is wrong as you don't need third party tool for monitoring. </p><p><span class="redactor-invisible-space"></span> </p><p><span class="redactor-invisible-space">Option B is wrong as pinging load balancer cannot help determine if the instance is unhealthy</span> </p><p><span class="redactor-invisible-space">Option C is wrong as RDS CPU utilization is not a correct measure to scale EC2 instances</span> </p><p>Option E is wrong as larger instance is not cost effective and does not guarantee they won't become unhealthy. </p><p>Option F is wrong as Auto Scaling group cannot be set for the RDS. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120514">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 19 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249281"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company is getting ready to do a major public announcement of a social media site on AWS. The website is running on EC2 instances deployed across multiple Availability Zones with a Multi-AZ RDS MySQL Extra Large DB Instance. The site performs a high number of small reads and writes per second and relies on an eventual consistency model. After comprehensive tests you discover that there is read contention on RDS MySQL. Which are the best approaches to meet these requirements? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Deploy ElastiCache in-memory cache running in each availability zone</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Implement sharding to distribute load to multiple RDS MySQL instances<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Increase the RDS MySQL Instance size and Implement provisioned IOPS<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Add an RDS MySQL read replica in each availability zone <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Deploy ElastiCache in-memory cache running in each availability zone<br><b>D</b>. Add an RDS MySQL read replica in each availability zone<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is there is Read Contention </p><p>Correct answer is <strong>A &amp; D</strong> as either the RDS needs to be scaled out using Read Replica or using a Caching solution like ElastiCache. </p><p>Option B is wrong as this is only a read contention, the writes work fine and sharding would help improve writes </p><p>Option C is wrong as not scalable beyond a limit, this is only a read contention, the writes work fine </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120543">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 20 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249282"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> ABCD has hired a third-party security auditor, and the auditor needs read-only access to all AWS resources and logs of all VPC records and events that have occurred on AWS. How can ABCD meet the auditor's requirements without comprising security in the AWS environment? Choose the correct answer<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Enable CloudTrail logging and create an IAM user who has read-only permissions to the required AWS resources, including the bucket containing the CloudTrail logs.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create an SNS notification that sends the CloudTrail log files to the auditor's email when CloudTrail delivers the logs to S3, but do not allow the auditor access to the AWS environment.<br><b>C</b>. <input type="radio" disabled="">&nbsp;ABCD should contact AWS as part of the shared responsibility model, and AWS will grant required access to the third-party auditor.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a role that has the required permissions for the auditor. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Enable CloudTrail logging and create an IAM user who has read-only permissions to the required AWS resources, including the bucket containing the CloudTrail logs.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as CloudTrail would help capture the logs IAM user with read only access to required resources would follow the best practices. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/cloudtrail/faqs/" target="_blank">CloudTrail</a> </p><p><em>AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain events related to API calls across your AWS infrastructure. CloudTrail provides a history of AWS API calls for your account, including API calls made through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This history simplifies security analysis, resource change tracking, and troubleshooting.</em> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120533">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 21 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249283"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A Solutions Architect is designing a weather forecast application. Every hour, the application will receive a new set of raw data from weather stations. The application will analyze this data and produce a set of local weather forecasts available for users to download. The analysis takes 50 minutes to run on 2,000 vCPUs. The analysis must complete before the next set of data is available. Each local weather forecast is typically 10 GB in size. The forecasts are accessed heavily during the first hour they are available, with usage dropping rapidly as newer forecasts become available. Which combination of steps is the MOST cost-effective architecture? (Select TWO.)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Conduct the analysis on an Amazon EC2-based cluster using 1-hour Spot blocks in multiple AWS Regions.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Conduct the analysis on a cluster of Amazon EC2 instances using Reserved Instances in a single AWS Region.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Store weather forecast data in Amazon S3 Standard. Configure a lifecycle policy to transition the data to Amazon S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Store weather forecast data in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). Configure a lifecycle policy to transition the data to Amazon Glacier after 90 days.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Store weather forecast data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Configure a lifecycle policy to transition the data to Amazon Glacier after 90 days. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Conduct the analysis on a cluster of Amazon EC2 instances using Reserved Instances in a single AWS Region.<br><b>D</b>. Store weather forecast data in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). Configure a lifecycle policy to transition the data to Amazon Glacier after 90 days.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answers are <strong>B &amp; C</strong> </p><p>Option B as the job runs for 50 mins within an hour with a sustained usage of around 20 hours of the 24 hours. </p><p>Option D as the focus is on most cost effective architecture, S3 One Zone-IA would be an ideal option as the data is used only during the first hour. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/s3/storage-classes/" target="_blank">S3 Storage Classes</a> &amp; <a href="https://aws.amazon.com/s3/pricing/" target="_blank">Pricing</a> </p><p>Option A is wrong as the usage is sustained Reserved instances would be more reliable and cost effective as compared to Spot blocks. </p><p>Option C is wrong as Standard and S3 Standard-IA would not provide the most cost effective option. </p><p>Option E is wrong as Standard-IA would not provide the most cost effective option as compared to S3 One Zone-IA </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121041">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 22 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249284"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is running a web application that has a high amount of dynamic content. The company is looking to reduce load time by implementing a caching solution that will help reduce load times for clients requesting the application. What is the best possible solution and why? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Offload the DNS to Route 53; Route 53 has DNS servers all around the world and routes the request to the closest region which reduces DNS latency.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create an ElastiCache cluster, write code that caches the correct dynamic content and places it in front of the RDS dynamic content. This will reduce the amount of time it takes to request the dynamic content since it is cached.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a CloudFront distribution, enable query string forwarding, set the TTL to 0: This will keep TCP connections open from CloudFront to origin, reducing the time it takes for TCP handshake to occur<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a CloudFront distribution; disable query string forwarding, set the TTL to 0. This will keep TCP connections open from CloudFront to origin, reducing the time it takes for TCP handshake to occur <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create a CloudFront distribution, enable query string forwarding, set the TTL to 0: This will keep TCP connections open from CloudFront to origin, reducing the time it takes for TCP handshake to occur<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong><br></p><p>Refer to the AWS Blog for <a href="https://aws.amazon.com/blogs/aws/amazon-cloudfront-support-for-dynamic-content/" target="_blank">Dynamic Content with CloudFront</a> </p><p><em>1. Use persistent TCP connections </em></p><p><em>2. Enable Query String support to cache Dynamic Content. </em></p><p><em>3. If you set the TTL for a particular origin to 0, CloudFront will still cache the content from that origin. It will then make a GET request with an If-Modified-Since header, thereby giving the origin a chance to signal that CloudFront can continue to use the cached content if it hasn't changed at the origin.</em></p><p>Option A is wrong as Route 53 is only a DNS server and would help improve response time if multi region application or distributed load. </p><p>Option B is wrong as ElastiCache would help mostly on repeatable queries, while the request still has to be served from the web application </p><p>Option D is wrong as for Dynamic caching you need to enable query string support </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120403">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 23 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249285"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your fortune 500 company has under taken a TCO analysis evaluating the use of Amazon S3 versus acquiring more hardware. The outcome was that all employees would be granted access to use Amazon S3 for storage of their personal documents Which of the following will you need to consider so you can set up a solution that incorporates single sign-on from your corporate AD or LDAP directory and restricts access for each user to a designated user folder in a bucket? (Choose 3 Answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Setting up a federation proxy or identity provider</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Using AWS Security Token Service to generate temporary tokens<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Tagging each folder in the bucket <br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Configuring IAM role<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Setting up a matching IAM user for every user in your corporate directory that needs access to a folder in the bucket <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Setting up a federation proxy or identity provider<br><b>B</b>. Using AWS Security Token Service to generate temporary tokens<br><b>D</b>. Configuring IAM role<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is knowing <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html" target="_blank">IAM Identity Providers and Federation</a> </p><p>Correct answer are <strong>A, B and D</strong> as you would need to Create a IAM role with proper permissions, use a federation proxy or an identity provider to authenticate with the on premises corporate AD or LDAP and once authenticated call the STS to generate temporary tokens to access S3 </p><p><img src="./sap-04_files/screen-shot-2016-04-02-at-7-47-51-am.png"><br>Option C is wrong as you can tag a S3 bucket folder and it would not help </p><p>Option E is wrong as creating IAM user would not help leverage the SSO with corporate AD or LDAP directory </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120216">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 24 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249286"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company is preparing to give AWS Management Console access to developers Company policy mandates identity federation and role-based access control. Roles are currently assigned using groups in the corporate Active Directory. What combination of the following will give developers access to the AWS console? Choose 2 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 9 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;AWS Directory Service AD Connector</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;AWS Directory Service Simple AD<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;AWS Identity and Access Management groups<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;AWS identity and Access Management roles<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;AWS identity and Access Management users <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. AWS Directory Service AD Connector<br><b>D</b>. AWS identity and Access Management roles<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>A &amp; D</strong> as you would need AD connector to connect to the on premises Active directory and IAM roles for identity federation and role based access control. </p><p>Option B is wrong as Simple AD is a standalone active directory. </p><p>Option C &amp; E are wrong as users and groups do not allow identity federation. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120423">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 25 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249287"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have deployed a web application targeting a global audience across multiple AWS Regions under the domain name.example.com. You decide to use Route 53 Latency-Based Routing to serve web requests to users from the region closest to the user. To provide business continuity in the event of server downtime you configure weighted record sets associated with two web servers in separate Availability Zones per region. During a DR test you notice that when you disable all web servers in one of the regions Route 53 does not automatically direct all users to the other region. What could be happening? (Choose 2 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 5 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Latency resource record sets cannot be used in combination with weighted resource record sets.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;You did not setup an http health check for one or more of the weighted resource record sets associated with me disabled web servers<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;The value of the weight associated with the latency alias resource record set in the region with the disabled servers is higher than the weight for the other region.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;One of the two working web servers in the other region did not pass its HTTP health check<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;You did not set “Evaluate Target Health” to “Yes” on the latency alias resource record set associated with example com in the region where you disabled the servers. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. You did not setup an http health check for one or more of the weighted resource record sets associated with me disabled web servers<br><b>E</b>. You did not set “Evaluate Target Health” to “Yes” on the latency alias resource record set associated with example com in the region where you disabled the servers.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>B &amp; E</strong>. </p><p>Refer to the AWS documentation for <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html#dns-failover-complex-configs-hc-alias" target="_blank">DNS failover</a></p><p><em>For both latency alias resource record sets, you set the value of “Evaluate Target Health” to Yes. You use the Evaluate Target Health setting for each latency alias resource record set to make Amazon Route 53 evaluate the health of the alias targets—the weighted resource record sets—and respond accordingly.</em></p><p><em></em>Option A is wrong as latency resource record sets can be used with weighted resource record sets.</p><p>Refer AWS documentation for <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/TutorialLBRMultipleEC2InRegion.html" target="_blank">Latency + Weighted resource record sets</a> </p><p>Option C is wrong as if even the weight is higher the traffic would be distributed accordingly </p><p>Option D is wrong as both the servers are working, if one fails the other server should work. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120381">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 26 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249288"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are consulting for a company that runs their current application entirely all on-premise. However, they are expecting a big boost in traffic tomorrow and need to figure out a way to decrease the load to handle the scale. Unfortunately, they cannot migrate their application to AWS in the period required. What could they do with their current on-premise application to help offload some of the traffic and scale to meet the demand expected in 24 hours? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Deploy OpsWorks on-premise to manage the instance in order to configure on-premise auto scaling to meet the demand.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a CloudFront CDN, enable query string forwarding and TTL of zero on the origin. Offload the DNS to AWS to handle CloudFront CDN traffic but use on-premise load balancers as the origin.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Duplicate half your web infrastructure on AWS, offload the DNS to Route 53 and configure weighted based DNS routing to send half the traffic to AWS .<br><b>D</b>. <input type="radio" disabled="">&nbsp;Upload all static files to Amazon S3 and create a CloudFront distribution serving those static files. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Create a CloudFront CDN, enable query string forwarding and TTL of zero on the origin. Offload the DNS to AWS to handle CloudFront CDN traffic but use on-premise load balancers as the origin.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as CloudFront can be used with a custom on-premises origin. With CloudFront edge locations, persistent connections and caching for dynamic content. DNS changes should be quick to handle as well. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/cloudfront/details/#faq" target="_blank">CloudFront FAQs</a> &amp; <a href="https://aws.amazon.com/blogs/aws/amazon-cloudfront-support-for-dynamic-content/" target="_blank">Dynamic Content</a> </p><p><em>Persistent TCP Connections – Establishing a TCP connection takes some time because each new connection requires a <a href="http://www.inetdaemon.com/tutorials/internet/tcp/3-way_handshake.shtml" target="_self">three-way handshake</a> between the server and the client. Amazon CloudFront makes use of persistent connections to each origin for dynamic content. This obviates the connection setup time that would otherwise slow down each request. Reusing these “long-haul” connections back to the server can eliminate hundreds of milliseconds of connection setup time. The connection from the client to the CloudFront edge location is also kept open whenever possible.<br></em> </p><p><em>Variable Time-To-Live (TTL) – In many cases, dynamic content is either not cacheable or cacheable for a very short period of time, perhaps just a few seconds. In the past, CloudFront’s minimum TTL was 60 minutes since all content was considered static. The new minimum TTL value is 0 seconds. If you set the TTL for a particular origin to 0, CloudFront will still cache the content from that origin. It will then make a GET request with an If-Modified-Since header, thereby giving the origin a chance to signal that CloudFront can continue to use the cached content if it hasn’t changed at the origin.</em><em></em><br> </p><p>Option A &amp; C are wrong as they are not quick to implement and costly. </p><p>Option D is wrong as it would just help improve the static content rendering. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120440">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 27 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249289"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A customer is in the process of deploying multiple applications to AWS that are owned and operated by different development teams. Each development team maintains the authorization of its users independently from other teams. The customer’s information security team would like to be able to delegate user authorization to the individual development teams but independently apply restrictions to the users permissions based on factors such as the users device and location. For example, the information security team would like to grant read-only permissions to a user who is defined by the development team as read/write whenever the user is authenticating from outside the corporate network. What steps can the information security team take to implement this capability?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Operate an authentication service that generates AWS STS tokens with IAM policies from application-defined IAM roles.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Add additional IAM policies to the application IAM roles that deny user privileges based on information security policy.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Configure IAM policies that restrict modification of the application IAM roles only to the information security team.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Enable federation with the internal LDAP directory and grant the application teams permissions to modify users. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Add additional IAM policies to the application IAM roles that deny user privileges based on information security policy.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is the separation and control for the developer and security teams. </p><p>Correct answer is <strong>B</strong> as you can define different policies to the IAM role, one owned by the Application team and other owned by Information security team with them having over the policies. Application team policy can define proper permissions while information security policy can define policy with deny rules based on location, device and more restrictive wins </p><p>Option A is wrong as there is no user separation, the approach will just help generate temporary tokens for authentication </p><p>Option C is wrong as part of the Authorization should still be in developers control </p><p>Option D is wrong as there is no separation for the information security team and would just help application teams </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120209">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 28 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249290"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company host a social media website for storing and sharing documents. the web application allows users to upload large files while resuming and pausing the upload as needed. Currently, files are uploaded to your php front end backed by Elastic Load Balancing and an autoscaling fleet of amazon elastic compute cloud (EC2) instances that scale upon average of bytes received (NetworkIn) After a file has been uploaded. it is copied to amazon simple storage service(S3). Amazon Ec2 instances use an AWS Identity and Access Management (AMI) role that allows Amazon s3 uploads. Over the last six months, your user base and scale have increased significantly, forcing you to increase the auto scaling groups Max parameter a few times. Your CFO is concerned about the rising costs and has asked you to adjust the architecture where needed to better optimize costs. Which architecture change could you introduce to reduce cost and still keep your web application secure and scalable?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Replace the Autoscaling launch Configuration to include c3.8xlarge instances; those instances can potentially yield a network throughput of 10gbps.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Re-architect your ingest pattern, have the app authenticate against your identity provider as a broker fetching temporary AWS credentials from AWS Secure token service (GetFederationToken). Securely pass the credentials and s3 endpoint/prefix to your app. Implement client-side logic to directly upload the file to amazon s3 using the given credentials and S3 Prefix.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Re-architect your ingest pattern, and move your web application instances into a VPC public subnet. Attach a public IP address for each EC2 instance (using the auto scaling launch configuration settings). Use Amazon Route 53 round robin records set and http health check to DNS load balance the app request this approach will significantly reduce the cost by bypassing elastic load balancing.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Re-architect your ingest pattern, have the app authenticate against your identity provider as a broker fetching temporary AWS credentials from AWS Secure token service (GetFederationToken). Securely pass the credentials and s3 endpoint/prefix to your app. Implement client-side logic that used the S3 multipart upload API to directly upload the file to Amazon s3 using the given credentials and s3 Prefix. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Re-architect your ingest pattern, have the app authenticate against your identity provider as a broker fetching temporary AWS credentials from AWS Secure token service (GetFederationToken). Securely pass the credentials and s3 endpoint/prefix to your app. Implement client-side logic that used the S3 multipart upload API to directly upload the file to Amazon s3 using the given credentials and s3 Prefix.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as multipart allows one to start uploading directly to S3 before the actual size is known or complete data is downloaded </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html" target="_blank">S3 Multi-Part Upload</a></p><p><em>Multipart upload allows you to upload a single object as a set of parts. Each part is a contiguous portion of the object's data. You can upload these object parts independently and in any order. If transmission of any part fails, you can retransmit that part without affecting other parts. After all parts of your object are uploaded, Amazon S3 assembles these parts and creates the object. In general, when your object size reaches 100 MB, you should consider using multipart uploads instead of uploading the object in a single operation.</em></p><p><em>Using multipart upload provides the following advantages:</em></p><ul><li><em>Improved throughput - You can upload parts in parallel to improve throughput.</em></li><li><em>Quick recovery from any network issues - Smaller part size minimizes the impact of restarting a failed upload due to a network error.</em></li><li><em>Pause and resume object uploads - You can upload object parts over time. Once you initiate a multipart upload there is no expiry; you must explicitly complete or abort the multipart upload.</em></li><li><em>Begin an upload before you know the final object size - You can upload an object as you are creating it.</em></li></ul><p>Option A is wrong as there is no info of current size and including might c3.8xlarge instance would increase cost </p><p>Option B is wrong as it does not provide the ability to handle pause and restarts </p><p>Option C is wrong as ELB is not the bottleneck and scales automatically </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120186">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 29 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249291"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have a web application leveraging an Elastic Load Balancer (ELB) In front of the web servers deployed using an Auto Scaling Group Your database is running on Relational Database Service (RDS). The application serves out technical articles and responses to them in general there are more views of an article than there are responses to the article. On occasion, an article on the site becomes extremely popular resulting in significant traffic Increases that causes the site to go down. What could you do to help alleviate the pressure on the infrastructure while maintaining availability during these events? Choose 3 answers<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Leverage CloudFront for the delivery of the articles.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Add RDS read-replicas for the read traffic going to your relational database<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Leverage Elastic Cache for caching the most frequently used data.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use SQS to queue up the requests for the technical posts and deliver them out of the queue.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use Route 53 health checks to fail over to an S3 bucket for an error page. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Leverage CloudFront for the delivery of the articles.<br><b>B</b>. Add RDS read-replicas for the read traffic going to your relational database<br><b>C</b>. Leverage Elastic Cache for caching the most frequently used data.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A, B and C</strong> as there are more views to the articles, using CloudFront will help reduce load by caching the requests, RDS read replicas will help distribute the read load and Elastic Cache can help cache the frequently used data. </p><p>Refer AWS documentation - <a href="https://media.amazonwebservices.com/AWS_Storage_Options.pdf" target="_blank">Storage Options Whitepaper</a></p><p>Option D is wrong as SQS would make the process asynchronous and not be real time </p><p>Option E is wrong as it is more of an error handling then solving the availability issue </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120192">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 30 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249292"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A customer has a website which shows all the deals available across the market. The site experiences a load of 5 large EC2 instances generally. However, a week before Thanksgiving vacation they encounter a load of almost 20 large instances. The load during that period varies over the day based on the office timings. Which of the below mentioned solutions is cost effective as well as help the website achieve better performance?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Keep only 10 instances running and manually launch 10 instances every day during office hours.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Setup to run 10 instances during the pre-vacation period and only scale up during the office time by launching 10 more instances using the Auto Scaling schedule.<br><b>C</b>. <input type="radio" disabled="">&nbsp;During the pre-vacation period setup a scenario where the organization has 15 instances running and 5 instances to scale up and down using Auto Scaling based on the network I/O policy.<br><b>D</b>. <input type="radio" disabled="">&nbsp;During the pre-vacation period setup 20 instances to run continuously. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Setup to run 10 instances during the pre-vacation period and only scale up during the office time by launching 10 more instances using the Auto Scaling schedule.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as having 10 instances to server normal traffic and scale up as per Demand is the cost effective and would help achieve better performance </p><p>Option A is wrong as manual scaling would require manual intervention and would not guarantee performance as it can't react to demand. </p><p>Option C is wrong as it is less cost effective compared to Option B as well as the Auto Scaling based on network would not be ideal </p><p>Option D is an overkill to keep 20 running all the time and is not cost effective </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120519">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 31 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249293"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are in the process of implementing AWS Organizations for your company. At your previous company, you saw an Organizations implementation go bad when an SCP (Service Control Policy) was applied at the root of the organization before being thoroughly tested. In what way can an SCP be properly tested and implemented?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 11 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Back up your entire Organization to S3 and restore rollback and restore if something goes wrong</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;The SCP must be verified with AWS before it is implemented to avoid any problems.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Mirror your Organizational Unit in another region. Apply the SCP and test it. Once testing is complete, attach the SCP to the root of your organization.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an Organizational Unit (OU). Attach the SCP to this new OU. Move your accounts in one at a time to ensure that you don't inadvertently lock users out of key services. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Create an Organizational Unit (OU). Attach the SCP to this new OU. Move your accounts in one at a time to ensure that you don't inadvertently lock users out of key services.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as AWS recommends creating an OU and applying the SCP on the OU. Accounts can then be migrated slowly. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html" target="_blank">Organizations Manage Policies SCP</a> </p><p><em>AWS strongly recommends that you don't attach SCPs to the root of your organization without thoroughly testing the impact that the policy has on accounts. Instead, create an OU that you can move your accounts into one at a time, or at least in small numbers, to ensure that you don't inadvertently lock users out of key services. One way to determine whether a service is used by an account is to examine the <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_access-advisor.html">service last accessed data in IAM</a>. Another way is to <a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html">use AWS CloudTrail to log service usage at the API level</a>.</em><br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121102">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 32 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249294"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are migrating a security system into AWS. The system consists of a number of RFID and motion tracking devices around a number of facilities. The combination of devices enter a message on a queue whenever a tagged or untagged individual pass the area they monitor. At the backend - there is a ML process, which is attempting to poll the queue and identify any unusual activity. You have migrated this system into AWS and decided to use SQS as the queue mechanism. Your ML engineer has told you that the ML algorithm is having issues with the data sets because they appear to be out of order in certain situations. The system relies on ordered events being added to the queue and received from the queue. What options do you have?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Delete the Queue and recreate the Queue using FIFO</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use Step functions and state-based processing to ensure the ordered operation of the lambda queue.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Using the CLI/API or Console edit the queue properties and change the queue from LIFO to FIFO mode. Ensure the date &amp; time attribute is set to be the queue key for sharding.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Ensure the security system is using the AWS CLI/API correctly and adding a timestamp to messages as they are added to the queue. Use long polling to ensure that events are received in the same time ordered way they are added. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Delete the Queue and recreate the Queue using FIFO<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as Standard SQS Queue does not guarantee message ordering. To guarantee message ordering, you should migrated to SQS FIFO queue. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html" target="_blank">SQS FIFO Queue</a> </p><p><em>FIFO (First-In-First-Out) queues are designed to enhance messaging between applications when the order of operations and events is critical, or where duplicates can't be tolerated, for example:<br></em> </p><ul> <li><em>Ensure that user-entered commands are executed in the right order.</em></li> <li><em>Display the correct product price by sending price modifications in the right order.</em></li> <li><em>Prevent a student from enrolling in a course before registering for an account.</em></li> </ul><p>Options B, C &amp; D are wrong as they still would not ensure ordering of messages. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%204%20-%20%23121204">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 33 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249295"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A user has created a mobile application, which makes calls to DynamoDB to fetch certain data. The application is using the DynamoDB SDK and root account access/secret access key to connect to DynamoDB from mobile. Which of the below mentioned statements is true with respect to the best practice for security in this scenario?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;The user should create a separate IAM user for each mobile application and provide DynamoDB access with it</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;The user should create an IAM role with DynamoDB and EC2 access. Attach the role with EC2 and route all calls from the mobile through EC2<br><b>C</b>. <input type="radio" disabled="">&nbsp;The application should use an IAM role with web identity federation which validates calls to DynamoDB with identity providers, such as Google, Amazon, and Facebook<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create an IAM Role with DynamoDB access and attach it with the mobile application <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. The application should use an IAM role with web identity federation which validates calls to DynamoDB with identity providers, such as Google, Amazon, and Facebook<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as you can authenticate with any OpenID compliant identity provider and have a IAM role to use temporary credentials. </p><p>Option A is wrong as using IAM user which would need hard coding security credentials is not recommended. </p><p>Option B is wrong as using EC2 to redirect calls in unnecessary<br> </p><p>Option D is wrong as you cannot directly attach a role to the mobile application.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120563">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 34 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249296"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A developer is trying to get a new DevOps role and preparing for a technical task for the interview. The requirement is to build a simple pipeline within a week for a RESTful web service, which contains several endpoints. For the pipeline, he decides to use AWS CodePipeline. For the application, he wants to use T2 Micro EC2 instances as they belong to free tier. In order to show a breadth of skills, he would like to use orchestration tool such as OpsWorks or CloudFormation to deploy the App. He has used Chef for some open source projects before. What below option is the best for him to do in a short time?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use OpsWorks to hook up CodePipeline in the build stage. The artifacts can be put in a S3 bucket and OpsWorks will use the newest code in S3 to deploy the applications</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Firstly, configure an OpsWorks stack, layer and instance. Secondly, in CodePipeline, choose a S3 bucket as the source, which can be a zip file for the app and set up the existing OpsWorks stack as the deployment provider. Then the app can be deployed to your stack automatically.<br><b>C</b>. <input type="radio" disabled="">&nbsp;As CodePipeline does not support OpsWorks, CloudFormation template is required to build up EC2 instance with ELB and Auto Scaling. Configure CodePipeline to select CloudFormation as a deployment target in the deploy stage of the pipeline.<br><b>D</b>. <input type="radio" disabled="">&nbsp;For CodePipeline, configure a S3 bucket as the source provider and configure the OpsWorks as the deployment provider. Then OpsWorks is able to create stack/layers and deploy APPs using artifacts in S3 <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Firstly, configure an OpsWorks stack, layer and instance. Secondly, in CodePipeline, choose a S3 bucket as the source, which can be a zip file for the app and set up the existing OpsWorks stack as the deployment provider. Then the app can be deployed to your stack automatically.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as the developer already has an experience with Chef, it would be easy for him to get started with OpsWorks. CodePipeline allows using OpsWorks as a deployment provider. However, the stacks and layers should already exist and need to be specified during the pipeline configuration. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/blogs/devops/deploy-an-app-to-an-aws-opsworks-layer-using-aws-codepipeline/" target="_blank">Deploy App using OpsWorks and CodePipeline</a> </p><p><em>AWS CodePipeline lets you create continuous delivery pipelines that automatically track code changes from sources such as AWS CodeCommit, Amazon S3, or GitHub. Now, you can use AWS CodePipeline as a code change-management solution for apps, Chef cookbooks, and recipes that you want to deploy with AWS OpsWorks.</em><em></em><br> </p><p><em><img src="./sap-04_files/cp_integ_cpprovider.png"><br><br></em> </p><p>Option A is wrong as OpsWorks needs to be hooked in the Deploy stage and not the build stage. </p><p>Option C is wrong as CodePipeline does support OpsWorks as a deployment provider.<br> </p><p>Option D<del></del> is wrong as the OpsWorks stack and layers should be created before the pipeline is created.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120577">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 35 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249297"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have been briefed by your supervisor for a client who needs a web application setup on AWS. The most important requirement is that MySQL must be used as the database, and this database must not be hosted in the public cloud, but rather at the client's data center due to security risks. Which of the following solutions would be the best to assure that the client's requirements are met?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Build the application server on a public subnet and the database at the client's data center. Connect them with a VPN connection which uses IPsec</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use the public subnet for the application server and use RDS with a storage gateway to access and synchronize the data securely from the local data center.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Build the application server on a public subnet and the database on a private subnet with a NAT instance between them.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Build the application server on a public subnet and build the database in a private subnet with a secure SSH connection to the private subnet from the client's data center. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Build the application server on a public subnet and the database at the client's data center. Connect them with a VPN connection which uses IPsec<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>A</strong> as the requirement is to host the database on-premises, there needs to be a connectivity between VPC and the on-premises network using either VPN or Direct Connect. </p><p>Option B is wrong as Storage gateway is for backup and archival and will not allow help synchronize data. Also, if at all the data would be available on AWS which is against the requirement. </p><p>Option C is wrong as database cannot be on AWS<br> </p><p>Option D is wrong as the connectivity cannot be done using secure ssh<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120398">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 36 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249298"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company runs video analysis software, which is available in both Free and Paid plans. To support the Free and Paid versions effectively, your company is using a spot pricing framework which does the bidding as per the subscription plan to ensure the availability of the spot instances and also maintain the cost. The instances are running behind a load balancer created for the analysis job with the auto-scaling group attached to that. Paid subscription jobs are set to run into multiple availability zones to maintain the high availability. The application with the use of spot engine adds the desired instances based on active jobs and terminates instances when the processing is completed. By looking at the CloudWatch logs, you noticed that sometimes the auto scaling terminates the instances during the job processing and adds them back. What could be the potential issue?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Update the desired capacity of the Auto Scaling Group based on the number of active jobs</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Auto Scaling triggers the AZRebalance event, if the number of instances in availability zones are not matching after terminating instances. Suspend the AZRebalance process of auto-scaling to avoid the rebalancing.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Run all the instances into a single availability zone<br><b>D</b>. <input type="radio" disabled="">&nbsp;Adjust the min and max capacity of the Auto Scaling Group after the jobs are completed <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Auto Scaling triggers the AZRebalance event, if the number of instances in availability zones are not matching after terminating instances. Suspend the AZRebalance process of auto-scaling to avoid the rebalancing.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is B as suspending the AZRebalance will disable the instance balancing activity if the availability zones are having a different number of instances. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-suspend-resume-processes.html" target="_blank">Auto Scaling Suspend Resume Process</a> </p><p><em>Balances the number of EC2 instances in the group across the Availability Zones in the region. If you remove an Availability Zone from your Auto Scaling group or an Availability Zone otherwise becomes unhealthy or unavailable, the scaling process launches new instances in an unaffected Availability Zone before terminating the unhealthy or unavailable instances. When the unhealthy Availability Zone returns to a healthy state, the scaling process automatically redistributes the instances evenly across the Availability Zones for the group.</em> </p><p><em>If you suspend <code>AZRebalance</code> and a scale-out or scale-in event occurs, the scaling process still tries to balance the Availability Zones. For example, during scale out, it launches the instance in the Availability Zone with the fewest instances.</em> </p><p><em>If you suspend the <code>Launch</code> process, <code>AZRebalance</code> neither launches new instances nor terminates existing instances. This is because <code>AZRebalance</code> terminates instances only after launching the replacement instances. If you suspend the <code>Terminate</code> process, your Auto Scaling group can grow up to ten percent larger than its maximum size, because this is allowed temporarily during rebalancing activities. If the scaling process cannot terminate instances, your Auto Scaling group could remain above its maximum size until you resume the <code>Terminate</code> process.</em> </p><p>Option A is wrong as the desired capacity maintains a minimum number of instance in an Auto Scaling group </p><p>Option C is wrong as running in a single AZ would not be fault tolerant solution, in case an AZ fails. </p><p>Option D is wrong as the min/max count has no effect over the availability zone rebalance process. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120629">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 37 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249299"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your social media monitoring application uses a Python app running on AWS Elastic Beanstalk to inject tweets, Facebook updates and RSS feeds into an Amazon Kinesis stream. A second AWS Elastic Beanstalk app generates key performance indicators into an Amazon DynamoDB table and powers a dashboard application. What is the most efficient option to prevent any data loss for this application?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use AWS Data Pipeline to replicate your DynamoDB tables into another region.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use the second AWS Elastic Beanstalk app to store a backup of Kinesis data onto Amazon Elastic Block Store (EBS), and then create snapshots from your Amazon EBS volumes.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Add a second Amazon Kinesis stream in another Availability Zone and use AWS data pipeline to replicate data across Kinesis streams.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Add a third AWS Elastic Beanstalk app that uses the Amazon Kinesis S3 connector to archive data from Amazon Kinesis into Amazon S3. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Add a third AWS Elastic Beanstalk app that uses the Amazon Kinesis S3 connector to archive data from Amazon Kinesis into Amazon S3.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to prevent data loss and understanding limitations of Kinesis data retention </p><p>Correct answer is <strong>D</strong> as Kinesis data is limited to 24 hours and should be stored in a durable location. Adding a third EB to archive data to S3 would help prevent any data loss. </p><p>Option A is wrong as DynamoDB does not have all the data and only the key performance indicators. </p><p>Option B is wrong as EBS is not a efficient solution for storing this data </p><p>Option C Kinesis streams are still limited in data retention period and would not help prevent data loss </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120377">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 38 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249300"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> As part of your continuous deployment process, your application undergoes an I/O load performance test before it is deployed to production using new AMIs with volumes created from snapshots. The application uses one Amazon EBS PIOPS volume per instance and requires consistent I/O performance. Which of the following must be carried out to ensure that I/O load performance tests yield the correct results in a repeatable manner?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Ensure that the I/O block sizes for the test are randomly selected.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Ensure that the Amazon EBS volumes have been pre-warmed by reading all the blocks before the test.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Ensure that snapshots of the Amazon EBS volumes are created as a backup.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Ensure that the Amazon EBS volume is encrypted.<br><b>E</b>. <input type="radio" disabled="">&nbsp;Ensure that the Amazon EBS volume has been pre-warmed by creating a snapshot of the volume before the test <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Ensure that the Amazon EBS volumes have been pre-warmed by reading all the blocks before the test.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B </strong>as EBS volumes created from Snapshot needs to be pre-warmed. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html" target="_blank">EBS Initialize</a> </p><p><em>New EBS volumes receive their maximum performance the moment that they are available and do not require initialization (formerly known as pre-warming). However, storage blocks on volumes that were restored from snapshots must be initialized (pulled down from Amazon S3 and written to the volume) before you can access the block. This preliminary action takes time and can cause a significant increase in the latency of an I/O operation the first time each block is accessed. For most applications, amortizing this cost over the lifetime of the volume is acceptable. Performance is restored after the data is accessed once.</em> </p><p><em>You can avoid this performance hit in a production environment by reading from all of the blocks on your volume before you use it; this process is called initialization. For a new volume created from a snapshot, you should read all the blocks that have data before using the volume.</em> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120548">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 39 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249301"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company has a library of on-demand MP4 files needing to be streamed publicly on their new video webinar website. The video files are archived and are expected to be streamed globally, primarily on mobile devices. Given the requirements what would be the best architecture for the company to design?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 11 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Provision streaming EC2 instances which use S3 as the source for the HLS on-demand transcoding on the servers. Provision a new CloudFront streaming distribution with the streaming server as the origin.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Provision streaming EC2 instances which use S3 as the source for the HLS on-demand transcoding on the servers. Provision a new Cloud Front download distribution with the WOWZA streaming server as the origin.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Upload the MP4 files to S3 and create an Elastic Transcoder job that transcodes the MP4 source into HLS chunks. Store the HLS output in S3 and Configure the Amazon CloudFront distribution with a download option to stream the video contents.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Upload the MP4 files to S3 and create an Elastic Transcoder job that transcodes the MP4 source into HLS chunks. Store the HLS output in S3 and Configure the Amazon CloudFront distribution with a streaming option to stream the video contents. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Upload the MP4 files to S3 and create an Elastic Transcoder job that transcodes the MP4 source into HLS chunks. Store the HLS output in S3 and Configure the Amazon CloudFront distribution with a download option to stream the video contents.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as CloudFront download option can be used to stream on demand videos using HLS on any mobile with S3 as the origin keeping cost low. Elastic transcoder as a managed service can be used to transcode videos into multiple formats </p><p>Refer to the <a href="https://aws.amazon.com/blogs/aws/using-amazon-cloudfront-for-video-streaming/" target="_blank">AWS Blog</a> </p><p>Option A &amp; B are wrong as it is more of on-demand videos and not live streaming a streaming server is not required. </p><p>Option D is wrong as streaming option does not work on all platforms. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120413">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 40 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249302"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company has a logging microservice, which is used to generate logs when users have entered certain commands in another application. This logging service is implemented via a SQS standard queue that a lambda is listening to. However, you have found that on some occasions, the timestamps of some logs are in a wrong order. As a result, it becomes harder to use this service to trace users’ activities. How should you fix this issue in a simple way without any code changes?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Convert the existing standard queue into a FIFO queue. Add a deduplication ID for the messages that are sent to the queue.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Delete the existing standard queue and recreate it as a FIFO queue. As a result, the order for the messages to be received is ensured.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Migrate the lambda code into EC2 instance. Add a timestamp to every message in the queue and then in EC2 check the timestamp to ensure the correct order for the messages to be delivered.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Migrate the whole microservice application to SWF so that the operation sequence is guaranteed. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Delete the existing standard queue and recreate it as a FIFO queue. As a result, the order for the messages to be received is ensured.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B</strong> as SQS FIFO queue guarantees the order of the messages. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html">SQS FIFO Queue</a> </p><p><em>FIFO (First-In-First-Out) queues are designed to enhance messaging between applications when the order of operations and events is critical, or where duplicates can't be tolerated, for example:</em> </p><ul> <li><em>Ensure that user-entered commands are executed in the right order.</em></li> <li><em>Display the correct product price by sending price modifications in the right order.</em></li> <li><em>Prevent a student from enrolling in a course before registering for an account.</em></li> </ul><p><em></em> </p><p><em>FIFO queues also provide exactly-once processing but have a limited number of transactions per second (TPS)</em> </p><p>Option A is wrong as the existing queue cannot be changed once created </p><p>Option C &amp; D are wrong as they are not simple changes. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120837">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 41 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249303"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Repeated - You have been given a new brief from your supervisor for a client who needs a web application set up on AWS. The most important requirement is that MySQL must be used as the database, and this database must not be hosted in the public cloud, but rather at the client's data center due to security risks. Which of the following solutions would be the best to assure that the client’s requirements are met? Choose the correct answer:<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Build the application server on a public subnet and build the database in a private subnet with a secure ssh connection to the private subnet from the client's data center.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use the public subnet for the application server and use RDS with a storage gateway to access and synchronize the data securely from the local data center.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Build the application server on a public subnet and the database on a private subnet with a NAT instance between them.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Build the application server on a public subnet and the database at the client’s data center. Connect them with a VPN connection which uses IPsec. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Build the application server on a public subnet and the database at the client’s data center. Connect them with a VPN connection which uses IPsec.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as host the application server on AWS and let the database be on the clients datacenter and have a VPN connection setup for communication between the VPC and the On-premises data center. </p><p>Refer AWS documentation - <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html" target="_blank">VPC VPN</a> </p><p>Option A, B &amp; C is wrong as it fails for the requirement of the database being restricted to clients datacenter.<br> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120418">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 42 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249304"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You have just joined a new company and have been put in charge of EC2 instances and any other services that use EC2 instances. You notice that the company has been slow to take advantage of AWS per-second Billing, specifically in the area of EMR and Spot Instances. What immediate steps can you take on EMR with spot instances to improve cost saving and performance?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Use on-demand instances instead.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Run fewer instances for a shorter amount of time.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Run fewer instances for a longer amount of time.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Run more instances for a shorter amount of time. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Run more instances for a shorter amount of time.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as EMR now supports instances with per second billing, it would be more cost efficient and performant to use more instances for shorter amount of time. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/blogs/aws/new-per-second-billing-for-ec2-instances-and-ebs-volumes/" target="_blank">Per-Second Billing</a> </p><p><em>Amazon EMR – Our customers add capacity to their EMR clusters in order to get their results more quickly. With per-second billing for the EC2 instances in the clusters, adding nodes is more cost-effective than ever. To learn more, read <a href="https://aws.amazon.com/about-aws/whats-new/2017/10/amazon-emr-now-supports-per-second-billing/">Amazon EMR Now Supports Per-Second Billing</a>.</em><em></em><br> </p><p>Option A is wrong as On-demand instances would not be cost effective. </p><p>Options B &amp; C are wrong as they are not performant. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121107">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 43 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249305"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An AWS customer runs a public blogging website. The site users upload two million blog entries a month. The average blog entry size is 200 KB. The access rate to blog entries drops to negligible 6 months after publication and users rarely access a blog entry 1 year after publication. Additionally, blog entries have a high update rate during the first 3 months following publication; this drops to no updates after 6 months. The customer wants to use CloudFront to improve his user’s load times. Which of the following recommendations would you make to the customer?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Duplicate entries into two different buckets and create two separate CloudFront distributions where S3 access is restricted only to Cloud Front identity</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a CloudFront distribution with “US &amp; Europe” price class for US/Europe users and a different CloudFront distribution with All Edge Locations for the remaining users.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create a CloudFront distribution with S3 access restricted only to the CloudFront identity and partition the blog entry’s location in S3 according to the month it was uploaded to be used with CloudFront behaviors<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a CloudFront distribution with Restrict Viewer Access Forward Query string set to true and minimum TTL of 0. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create a CloudFront distribution with S3 access restricted only to the CloudFront identity and partition the blog entry’s location in S3 according to the month it was uploaded to be used with CloudFront behaviors<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is speed up using CloudFront with different behavior based on different access pattern. </p><p>Correct answer is <strong>C</strong> as CloudFront will allow <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesCacheBehavior" target="_blank">different caching behavior</a> as per the path pattern with access control using </p><p>Option A is wrong as it does not address the data storage and different access patterns need </p><p>Option B is wrong as it might be valid but does not address the data storage and different access patterns need </p><p>Option C is wrong as with minimum TTL of 0, CloudFront will never cache a request </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120223">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 44 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249306"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A large multi-national corporation has come to you and asked if you can provide a high availability and disaster recovery plan for their organization. Their primary concern is not to lose any data so they are fine if there is a longer recovery time as it will presumably save on cost. Which of the following options would be the best one for this corporation, given the concerns that they have outlined to you above? Choose the correct answer<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Make sure you have RDS set up as an asynchronous Multi-AZ deployment, which automatically provisions and maintains an asynchronous “standby” replica in a different Availability Zone.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Backup and restoring with S3 should be considered due to the low cost of S3 storage. Backup up frequently and the data can be sent to S3 using either Direct Connect or Storage Gateway, or over the Internet.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Set up a number of smaller instances in a different region, which all have Auto Scaling and Elastic Load Balancing enabled. If there is a network outage, then these instances will auto scale up. As long as spot instances are used and the instances are small this should remain a cost effective solution.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Set up pre-configured servers using Amazon Machine Images. Use an Elastic IP and Route 53 to quickly switch over to your new infrastructure if there are any problems when you run your health checks. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Backup and restoring with S3 should be considered due to the low cost of S3 storage. Backup up frequently and the data can be sent to S3 using either Direct Connect or Storage Gateway, or over the Internet.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>B </strong>as the best option is to have the backups taken frequently and stored in S3, which can then be restored. </p><p>Option A is wrong as RDS cannot be set up as an asynchronous Multi-AZ deployment<span class="redactor-invisible-space"></span> </p><p>Option C is wrong as targets on RTO which is not a concern and this would also increase the cost. </p><p>Option D is wrong as pre-configured AMIs would only help to get started quickly when needed to launch new instances. It will help in improving the RTO but does not address the RPO part. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120538">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 45 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249307"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A web design company currently runs several FTP servers that their 250 customers use to upload and download large graphic files. They wish to move this system to AWS to make it more scalable, but they wish to maintain customer privacy and keep costs to a minimum. What AWS architecture would you recommend?<br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Ask their customers to use an S3 client instead of an FTP client. Create a single S3 bucket. Create an IAM user for each customer. Put the IAM Users in a Group that has an IAM policy that permits access to subdirectories within the bucket via use of the ‘username’ Policy variable.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Create a single S3 bucket with Reduced Redundancy Storage turned on and ask their customers to use an S3 client instead of an FTP client. Create a bucket for each customer with a Bucket Policy that permits access only to that one customer.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an auto-scaling group of FTP servers with a scaling policy to automatically scale-in when minimum network traffic on the auto-scaling group is below a given threshold. Load a central list of ftp users from S3 as part of the user Data startup script on each Instance<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create a single S3 bucket with Requester Pays turned on and ask their customers to use an S3 client instead of an FTP client. Create a bucket tor each customer with a Bucket Policy that permits access only to that one customer. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Ask their customers to use an S3 client instead of an FTP client. Create a single S3 bucket. Create an IAM user for each customer. Put the IAM Users in a Group that has an IAM policy that permits access to subdirectories within the bucket via use of the ‘username’ Policy variable.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is customer privacy and cost. </p><p>Correct answer is <strong>A</strong> as a single bucket can be created with the aws:username policy variable for each user having access to its out subfolder. </p><p>Refer to the AWS Blog for <a href="https://aws.amazon.com/blogs/security/writing-iam-policies-grant-access-to-user-specific-folders-in-an-amazon-s3-bucket/" target="_blank">Writing IAM policies to gratn user specific folder access in S3</a> </p><p>Option B is wrong as S3 RRS is not durable and data is not reproducible. Creating bucket for each customer would hit the default limit and the policy needs to updated everytime </p><p>Option C is wrong as creating auto scaling with FTP servers would be expensive </p><p>Option D is wrong as Requester pays changes the payment model. Creating bucket for each customer would hit the default limit and the policy needs to updated everytime </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120355">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 46 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249308"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> You are designing a social media site and are considering how to mitigate distributed denial-of-service (DDoS) attacks. Which of the below are viable mitigation techniques? (Choose 3 answers)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Add multiple elastic network interfaces (ENIs) to each EC2 instance to increase the network bandwidth.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Use dedicated instances to ensure that each instance has the maximum performance possible.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Use an Amazon CloudFront distribution for both static and dynamic content.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Use an Elastic Load Balancer with auto scaling groups at the web app and Amazon Relational Database Service (RDS) tiers<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Add alert Amazon CloudWatch to look for high Network in and CPU utilization.<br><b>F</b>. <input type="checkbox" disabled="">&nbsp;Create processes and capabilities to quickly add and remove rules to the instance OS firewall. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Use an Amazon CloudFront distribution for both static and dynamic content.<br><b>D</b>. Use an Elastic Load Balancer with auto scaling groups at the web app and Amazon Relational Database Service (RDS) tiers<br><b>E</b>. Add alert Amazon CloudWatch to look for high Network in and CPU utilization.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to understand AWS DDOS Mitigation techniques<br> </p><p>Correct answer are <strong>C, D &amp; E</strong> </p><p>Refer to the <a href="https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf" target="_blank">DDOS mitigation whitepaper</a> (Highly Recommended) which mentions <br> </p><ul> <li><em>Minimize the Attack Surface Area</em> </li> <li><em>Be Ready to Scale and Absorb the Attack</em> </li> <li><em>Safeguard Exposed Resources</em> </li> <li><em>Learn Normal Behavior</em> </li> <li><em>Create a Plan for Attacks</em> </li> </ul><p>Option C as CloudFront would scale and help absorb the attack. CloudFront also helps setup restrictions on accessibility like geo restrictions. </p><p>Option D as ELB with auto scaling would help scale and absorb the attack </p><p>Option E as you can learn normal behaviour and use CloudWatch to provide and configure alerts and actions when crossed </p><p>Option A is wrong as <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html" target="_blank">ENI</a> do not help increase network bandwidth.</p><p><em>Attaching another network interface to an instance (for example, a NIC teaming configuration) cannot be used as a method to increase or double the network bandwidth to or from the dual-homed instance.</em><em></em></p><p>Option B as using dedicated instances is more for compliance and security </p><p>Option F is not a recommended approach as well needs to automated and as the attack is more multiple IPs it would not help mitigate. </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120251">AWS SAP-C01 Question feedback</a> </p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 47 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249309"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your must architect the migration of a web application to AWS. The application consists of Linux web servers running a custom web server. You are required to save the logs generated from the application to a durable location. What options could you select to migrate the application to AWS? (Choose 2)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Create an AWS Elastic Beanstalk application using the custom web server platform. Specify the web server executable and the application project and source files. Enable log file rotation to Amazon Simple Storage Service (S3).</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Create Dockerfile for the application. Create an AWS OpsWorks stack consisting of a custom layer. Create custom recipes to install Docker and to deploy your Docker container using the Dockerfile. Create custom recipes to install and configure the application to publish the logs to Amazon CloudWatch Logs<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Create Dockerfile for the application. Create an AWS OpsWorks stack consisting of a Docker layer that uses the Dockerfile. Create custom recipes to install and configure Amazon Kinesis to publish the logs into Amazon CloudWatch.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Create a Dockerfile for the application. Create an AWS Elastic Beanstalk application using the Docker platform and the Dockerfile. Enable logging the Docker configuration to automatically publish the application logs. Enable log file rotation to Amazon S3.<br><b>E</b>. <input type="checkbox" disabled="">&nbsp;Use VM import/Export to import a virtual machine image of the server into AWS as an AMI. Create an Amazon Elastic Compute Cloud (EC2) instance from AMI, and install and configure the Amazon CloudWatch Logs agent. Create a new AMI from the instance. Create an AWS Elastic Beanstalk application using the AMI platform and the new AMI. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Create a Dockerfile for the application. Create an AWS Elastic Beanstalk application using the Docker platform and the Dockerfile. Enable logging the Docker configuration to automatically publish the application logs. Enable log file rotation to Amazon S3.<br><b>E</b>. Use VM import/Export to import a virtual machine image of the server into AWS as an AMI. Create an Amazon Elastic Compute Cloud (EC2) instance from AMI, and install and configure the Amazon CloudWatch Logs agent. Create a new AMI from the instance. Create an AWS Elastic Beanstalk application using the AMI platform and the new AMI.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is migration and storing logs in durable location </p><p>Correct answer is <strong>D &amp; E</strong> as you can send logs to CloudWatch using <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html" target="_blank">CloudWatch log agent</a> or <a href="https://docs.docker.com/engine/admin/logging/awslogs/" target="_blank">awslogs</a> which can be configured with <a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html" target="_blank">docker</a> and both the approach do not need any change to the application. </p><p><a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html" target="_blank">CloudWatch can be used for long term log</a> storage same as S3 but is a bit expensive, but cost is not a factor in the question and Elastic Beanstalk supports Docker. </p><p>Also, this is a migration question, so no changes should be expected to the applications as not mentioned in the question </p><p>Option D as you can use Docker configuration with awslogs and Elastic Beanstalk with Docker </p><p>Option E as you can use VM Import/Export to create AMI and CloudWatch logs agent to log </p><p>Option A is wrong as Elastic Beanstalk does not work with Custom server executable </p><p>Option B is wrong as this can work as one of the option, the last sentence mentions configuring the application to push the logs to CloudWatch, which would need changes to application as it needs to use SDK or CLI. </p><p>Option C is wrong as Kinesis is not needed as you would need to make changes to push to Kinesis and then have Kinesis handlers to push to CloudWatch. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120259">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 48 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249310"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> An auditor needs access to logs that record all API events on AWS. The auditor only needs read-only access to the log files and does not need access to each AWS account. The company has multiple AWS accounts, and the auditor needs access to all the logs for all the accounts. What is the best way to configure access for the auditor to view event logs from all accounts? Choose the correct answer from the options below<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 10 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Configure the CloudTrail service in each AWS account, and have the logs delivered to an AWS bucket on each account, while granting the auditor permissions to the bucket via roles in the secondary accounts and a single primary IAM account that can assume a read-only role in the secondary AWS accounts.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Configure the CloudTrail service in the primary AWS account and configure consolidated billing for all the secondary accounts. Then grant the auditor access to the S3 bucket that receives the CloudTrail log files.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Configure the CloudTrail service in each AWS account and enable consolidated logging inside of CloudTrail.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWS bucket in the primary account and grant the auditor access to that single bucket in the primary account. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWS bucket in the primary account and grant the auditor access to that single bucket in the primary account.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>D</strong> as CloudTrail can be configured to log logs into a single S3 bucket which can act as a centralized location for controlling access and the auditor to look upon. </p><p>Option A is wrong as although possible the approach is cumbersome for both the auditor and the company to configure. </p><p>Option B is wrong as consolidated billing does not provide any other access to the primary account apart from costs incurred. </p><p>Option C is wrong as there is no such think as consolidated logging and the logging needs to be configured per account </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120393">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 49 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249311"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company’s on-premises content management system has the following architecture: Application Tier – Java code on a JBoss application server Database Tier – Oracle database regularly backed up to Amazon Simple Storage Service (S3) using the Oracle RMAN backup utility Static Content – stored on a 512GB gateway stored Storage Gateway volume attached to the application server via the iSCSI interface Which AWS based disaster recovery strategy will give you the best RTO? <br><div class="pull-left"><div class="label-success label" style="padding: .2em .6em .3em;"> Correct </div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 8 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Deploy the Oracle database and the JBoss app server on EC2. Restore the RMAN Oracle backups from Amazon S3. Generate an EBS volume of static content from the Storage Gateway and attach it to the JBoss EC2 server.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Deploy the Oracle database on RDS. Deploy the JBoss app server on EC2. Restore the RMAN Oracle backups from Amazon Glacier. Generate an EBS volume of static content from the Storage Gateway and attach it to the JBoss EC2 server.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Deploy the Oracle database and the JBoss app server on EC2. Restore the RMAN Oracle backups from Amazon S3. Restore the static content by attaching an AWS Storage Gateway running on Amazon EC2 as an iSCSI volume to the JBoss EC2 server.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Deploy the Oracle database and the JBoss app server on EC2. Restore the RMAN Oracle backups from Amazon S3. Restore the static content from an AWS Storage Gateway-VTL running on Amazon EC2 <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>A</b>. Deploy the Oracle database and the JBoss app server on EC2. Restore the RMAN Oracle backups from Amazon S3. Generate an EBS volume of static content from the Storage Gateway and attach it to the JBoss EC2 server.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Refer <a href="https://aws.amazon.com/storagegateway/faqs/" target="_blank">Storage gateway FAQs</a><br> </p><p>Correct answer is <strong>A</strong> as the S3 and creating EBS volumes from Storage gateway would provide the best RTO. </p><p><a href="https://aws.amazon.com/storagegateway/faqs/" target="_blank"></a> </p><p>Option B is wrong as Glacier does help to give best RTO which was 3-4 hours before. Does not take account the latest retrieval AWS enhancements </p><p>Option C is wrong as no need to attach the Storage Gateway as an iSCSI volume can just create a EBS volume </p><pre>You can take point-in-time snapshots of your volume gateway volumes in the form of 
Amazon EBS snapshots.You can use a snapshot of your volume as the starting point 
for a new Amazon EBS volume, which you can then attach to an Amazon EC2 instance. 
Using this approach, you can easily supply data from your on-premises applications 
to your applications running on Amazon EC2 if you require additional on-demand 
compute capacity for data processing or replacement capacity for disaster recovery purposes.
</pre><p>Option D is wrong as VTL is Virtual Tape library and doesn’t fit the RTO. <a href="https://aws.amazon.com/storagegateway/faqs/#tape" target="_blank">It takes up to 24 hours for the tape to be available in your tape gateway.</a> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120372">AWS SAP-C01 Question feedback</a></div><p><b>Points : </b> 5 out of 5 </p></div></div><div class="question_info"><div class="question_no"><b>Question : 50 of 54 </b><small>- Multiple Answer</small> <span style="float:right;" class="grad_5249312"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> ABCD is building out an AWS Cloud Environment for a financial regulatory firm. Part of the requirements are being able to monitor all changes in an environment and all traffic sent to and from the environment. What suggestions would you make to ensure all the requirements for monitoring the financial architecture are satisfied? (Choose Two)<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="checkbox" checked="true" disabled="">&nbsp;Configure an IPS/IDS in promiscuous mode, which will listen to all packet traffic and API changes.</span><br><b>B</b>. <input type="checkbox" disabled="">&nbsp;Configure an IPS/IDS system, such as Palo Alto Networks, that monitors, filters, and alerts of all potential hazard traffic entering and leaving the VPC.<br><b>C</b>. <input type="checkbox" disabled="">&nbsp;Configure an IPS/IDS to listen and block all suspected bad traffic coming into and out of the VPC. Configure CloudTrail with CloudWatch Logs to monitor all changes within an environment.<br><b>D</b>. <input type="checkbox" disabled="">&nbsp;Configure an IPS/IDS system, such as Palo Alto Networks, using promiscuous mode that monitors, filters, and alerts of all potential hazard traffic leaving the VPC. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>B</b>. Configure an IPS/IDS system, such as Palo Alto Networks, that monitors, filters, and alerts of all potential hazard traffic entering and leaving the VPC.<br><b>C</b>. Configure an IPS/IDS to listen and block all suspected bad traffic coming into and out of the VPC. Configure CloudTrail with CloudWatch Logs to monitor all changes within an environment.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer are <strong>B &amp; D </strong>as IDS/IPS can be placed in front to monitor, listen to all traffic and use CloudTrail with CloudWatch for monitoring activities on AWS. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/answers/networking/vpc-security-capabilities/" target="_blank">VPC Security</a> </p><p>Option A &amp; C are wrong as packet sniffing in promiscuous mode is not allowed. </p><p><strong><em>Packet Sniffing</em></strong><strong><em> - </em></strong><span></span><em>It is not possible for a virtual instance running in promiscuous mode to receive or <i>sniff</i> traffic that is intended for a different virtual instance. While customers can elect to place their interfaces into promiscuous mode, the hypervisor will not deliver any traffic to an instance that is not addressed to it. Even two virtual instances that are owned by the same customer located on the same physical host cannot listen to each other’s traffic. Additionally, attacks such as ARP cache poisoning do not work within Amazon EC2 and Amazon VPC. While Amazon EC2 does provide ample data protection between customers by default, as a standard practice it is best to always encrypt sensitive traffic.</em> </p><p><a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%204%20-%20%23120435">AWS SAP-C01 Question feedback</a></p></div></div></div><div class="question_info"><div class="question_no"><b>Question : 51 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249313"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> Your company runs a customer facing event registration site. This site is built with a 3-tier architecture with web and application tier servers and a MySQL database. The application requires 6 web tier servers and 6 application tier servers for normal operation, but can run on a minimum of 65% server capacity and a single MySQL database. When deploying this application in a region with three availability zones (AZs) which architecture provides high availability?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 4 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;A web tier deployed across 2 AZs with 3 EC2 (Elastic Compute Cloud) instances in each AZ inside an Auto Scaling Group behind an ELB (elastic load balancer), and an application tier deployed across 2 AZs with 3 EC2 instances in each AZ inside an Auto Scaling Group behind an ELB. and one RDS (Relational Database Service) instance deployed with read replicas in the other AZ.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;A web tier deployed across 3 AZs with 2 EC2 (Elastic Compute Cloud) instances in each AZ inside an Auto Scaling Group behind an ELB (elastic load balancer) and an application tier deployed across 3 AZs with 2 EC2 instances in each AZ inside an Auto Scaling Group behind an ELB and one RDS (Relational Database Service) Instance deployed with read replicas in the two other AZs.<br><b>C</b>. <input type="radio" disabled="">&nbsp;A web tier deployed across 2 AZs with 3 EC2 (Elastic Compute Cloud) instances in each AZ inside an Auto Scaling Group behind an ELB (elastic load balancer) and an application tier deployed across 2 AZs with 3 EC2 instances m each AZ inside an Auto Scaling Group behind an ELS and a Multi-AZ RDS (Relational Database Service) deployment.<br><b>D</b>. <input type="radio" disabled="">&nbsp;A web tier deployed across 3 AZs with 2 EC2 (Elastic Compute Cloud) instances in each AZ Inside an Auto Scaling Group behind an ELB (elastic load balancer). And an application tier deployed across 3 AZs with 2 EC2 instances in each AZ inside an Auto Scaling Group behind an ELB. And a Multi-AZ RDS (Relational Database services) deployment. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>D</b>. A web tier deployed across 3 AZs with 2 EC2 (Elastic Compute Cloud) instances in each AZ Inside an Auto Scaling Group behind an ELB (elastic load balancer). And an application tier deployed across 3 AZs with 2 EC2 instances in each AZ inside an Auto Scaling Group behind an ELB. And a Multi-AZ RDS (Relational Database services) deployment.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key point here is to design HA with 3 AZs and 6 web and application servers. </p><p>Correct answer is <strong>D</strong> as 2 instances in 3 AZs would be perfect with Multi-AZ for HA. </p><p>Option A and B are wrong as Read replicas are no HA solution but Scalability solution </p><p>Option A and C are wrong as it does not utilize the 3 AZs. So if an AZ goes down all 100% load would be on a single AZ. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120367">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 52 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249314"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A new client has asked you to streamline their AWS operations. The company has grown rapidly and has many EC2 instances in several different regions. One of the problems is that they are finding it very time consuming to perform updates on all of the instances, as well as patching, and opening and closing of ports. What steps can you take to streamline this process for them?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Pre-bake AMIs with the patches or updates, take the existing instances out of service and create new instances from the AMIs.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use CloudFormation and Auto Scaling Rolling Updates.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create Resource Groups for the instances in each region. Use Systems Manager to apply patches and updates on all of the instances at once.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Create Resource Groups for the instances in each region. Create python scripts, which apply updates and patches. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create Resource Groups for the instances in each region. Use Systems Manager to apply patches and updates on all of the instances at once.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as Systems Manager can help automate the patching process. </p><p>Refer AWS documentation - <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-patch.html" target="_blank">Systems Manager Patch</a> </p><p><em>AWS Systems Manager Patch Manager automates the process of patching managed instances with security-related updates. For Linux-based instances, you can also install patches for nonsecurity updates. You can patch fleets of Amazon EC2 instances or your on-premises servers and virtual machines (VMs) by operating system type. This includes supported versions of Windows Server, Ubuntu Server, Red Hat Enterprise Linux (RHEL), SUSE Linux Enterprise Server (SLES), CentOS, Amazon Linux, and Amazon Linux 2. You can scan instances to see only a report of missing patches, or you can scan and automatically install all missing patches.<br></em> </p><p><em>Patch Manager uses patch baselines, which include rules for auto-approving patches within days of their release, as well as a list of approved and rejected patches. You can install patches on a regular basis by scheduling patching to run as a Systems Manager Maintenance Window task. You can also install patches individually or to large groups of instances by using Amazon EC2 tags. (Tags are keys that help identify and sort your resources within your organization.) You can add tags to your patch baselines themselves when you create or update them.</em><em></em><br> </p><p>Option A is wrong as this is a cumbersome process and needs to be done manually. </p><p>Option B is wrong as CloudFormation and Rolling updates are usually for application updates.<br> </p><p>Option D is wrong as using python scripts is cumbersome.<br> </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%204%20-%20%23121203">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 53 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249315"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A company runs an ecommerce web application. The application runs on Amazon EC2 instances behind an ELB Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones. Users can submit an order with a list of items that may be from different departments throughout the company. For each item, the web application calls the internal order service for the associated department. The order services have the same architectural pattern as the ecommerce web application. Bugs in the order services periodically cause requests to these services to fail. These failures result in poor user experiences, as they cause the entire order to fail. Which architectural changes would make the purchase process more robust?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 7 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Create an Amazon API Gateway API in front of the web application's Elastic Load Balancer. Configure the API to throttle requests going to the web application. Set up Amazon ElastiCache for each order service to cache calls to the services. Change the web application to check the cache before calling the order services.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Increase the maximum capacity of the Auto Scaling group for the web application. Increase the size of the instance type in the Auto Scaling group launch configuration for the web application. Switch the load balancers for the order services to Network Load Balancers.<br><b>C</b>. <input type="radio" disabled="">&nbsp;Create an Amazon SQS queue for each order service (as order queues). Alter the web application to send all the data for a purchase to the appropriate order queue. Rewrite the services as AWS Lambda functions. Configure the order queues as event sources for the Lambda functions.<br><b>D</b>. <input type="radio" disabled="">&nbsp;Increase the maximum capacity of the Auto Scaling group. Switch to an EC2 instance family with burstable performance, and reduce the size of the instance type in the Auto Scaling group launch configuration. Switch the load balancers for the order services to Network Load Balancers. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Create an Amazon SQS queue for each order service (as order queues). Alter the web application to send all the data for a purchase to the appropriate order queue. Rewrite the services as AWS Lambda functions. Configure the order queues as event sources for the Lambda functions.<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Correct answer is <strong>C</strong> as SQS helps provide the loose coupling within the services and ability to be fault tolerant, scalable. Order can be processed asynchronously with the ability to recover. </p><p>Refer AWS documentation - <a href="https://aws.amazon.com/blogs/compute/building-loosely-coupled-scalable-c-applications-with-amazon-sqs-and-amazon-sns/" target="_blank">Loosely Coupled Architecture - SQS</a> </p><ul> <li>Reliable, durable, and fault-tolerant delivery of messages between application components</li> <li>Logical decomposition of systems and increased autonomy of components</li> <li>Creating unidirectional, non-blocking operations, temporarily decoupling system components at runtime</li> <li>Decreasing the dependencies that components have on each other through standard communication and network channels</li> </ul><p>(Can use Similar Architecture with Lambda instead of Auto Scaling Instances) </p><p><img src="./sap-04_files/CustomOrderQueue-1024x632.png"> </p><p>Option A is wrong as throttling would cause a bad user experience. </p><p>Options B &amp; C are wrong as increasing the capacity would not guarantee resolving the bug and would still have a synchronous tightly coupled architecture. </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23121083">AWS SAP-C01 Question feedback</a></div></div></div><div class="question_info"><div class="question_no"><b>Question : 54 of 54 </b><small>- Multiple Choice</small> <span style="float:right;" class="grad_5249316"> <span class="label label-success">Graded</span> </span> </div><div class="question_detail"> A large real-estate brokerage is exploring the option to adding a cost-effective location based alert to their existing mobile application. The application backend infrastructure currently runs on AWS. Users who opt in to this service will receive alerts on their mobile device regarding real-estate offers in proximity to their location. For the alerts to be relevant delivery time needs to be in the low minute count. The existing mobile app has 5 million users across the US. Which one of the following architectural suggestions would you make to the customer?<br><div class="pull-left"><div class="label-danger label" style="padding: .2em .6em .3em;">Incorrect</div></div><div class="pull-right"><b style="font-size: 15px;">Time spent : 6 sec </b></div><br><br> <b>Your answer</b><br><div style="font-size: 15px;"> <span class="bgcolor"><b>A</b>. <input type="radio" checked="true" disabled="">&nbsp;Mobile application will submit its location to a web service endpoint utilizing Elastic Load Balancing and EC2 instances. DynamoDB will be used to store and retrieve relevant offers. EC2 instances will communicate with mobile earners/device providers to push alerts back to mobile application.</span><br><b>B</b>. <input type="radio" disabled="">&nbsp;Use AWS Direct Connect or VPN to establish connectivity with mobile carriers EC2 instances will receive the mobile applications location through carrier connection: RDS will be used to store and relevant offers. EC2 instances will communicate with mobile carriers to push alerts back to the mobile application<br><b>C</b>. <input type="radio" disabled="">&nbsp;Mobile application will send device location using SQS. EC2 instances will retrieve the relevant offers from DynamoDB. AWS Mobile Push will be used to send offers to the mobile application<br><b>D</b>. <input type="radio" disabled="">&nbsp;Mobile application will send device location using AWS Mobile Push. EC2 instances will retrieve the relevant offers from DynamoDB. EC2 instances will communicate with mobile carriers/device providers to push alerts back to the mobile application. <br><br> </div> <b>Correct Answer</b><br><div style="font-size: 15px;"> <b>C</b>. Mobile application will send device location using SQS. EC2 instances will retrieve the relevant offers from DynamoDB. AWS Mobile Push will be used to send offers to the mobile application<br> <br> </div> <b>Explanation</b><br><div style="font-size: 15px;"><p>Key here is cost effective solution with large customer base and quick response time. Also, need to use <a href="http://docs.aws.amazon.com/sns/latest/dg/SNSMobilePush.html" target="_blank">AWS Mobile Push</a> to send notification </p><p>Correct answer is <strong>C</strong> to use SQS to scale, decouple and keep cost low. DynamoDB to store the offers. EC2 instances to retrieve offers and AWS Mobile Push to send offers. </p><p>Option A is wrong as Web service endpoint would not scale. Also, mobile earners/device providers is not feasible way to push alerts </p><p>Option B is wrong as it needs to be push model where Mobile application needs to send the location. Also, DynamoDB is better sutied for this application because of the scale and performance. </p><p>Option D is wrong a AWS Mobile Push is to send notification and cannot be used to send device location </p> <a href="mailto:certification.exam.tests@gmail.com?subject=AWS%20SAP-C01%20Practice%20Test%201%20-%20%23120197">AWS SAP-C01 Question feedback</a></div></div></div><div class="col-sm-12 well"><h4 class="sm" style="color:#333;">8/54 Questions right</h4></div></div><style type="text/css">
span.label.label-danger,span.label.label-success {
    padding: .2em .6em .3em;
}
.saved{color:red; }
.question_info{
  margin-bottom: 40px;
  border: solid 1px #ccc;
  border-radius: 5px;
  overflow: hidden;
}
.question_no {
    background: #f4f4f4;
    padding: 0 15px;
    line-height: 40px;
    border-bottom: solid 1px #ccc;
}

.question_detail {
    padding: 10px;
}
.hide{
  display: none;
}
input[type="radio"]{
  -webkit-appearance: radio;
}
input[type="checkbox"]{
  -webkit-appearance: checkbox;
}
span.bgcolor {
    background: yellow;
    padding: 5px;
    margin-left: -5px;
}
</style><link href="./sap-04_files/mcoursestyle.css" rel="stylesheet"></div> <script type="text/javascript" src="./sap-04_files/bc-course.min_031117.js.下载"></script> <div class="overlayForm" style=""></div></div></div></div></div></div><div class="overlayForm"></div></div><iframe style="position:absolute;left:-999px;top:-999px;visibility:hidden" src="./sap-04_files/saved_resource.html"></iframe><iframe style="display: none; visibility: hidden;" src="./sap-04_files/saved_resource(1).html"></iframe><iframe style="display: none; visibility: hidden;" src="./sap-04_files/saved_resource(2).html"></iframe></body></html>